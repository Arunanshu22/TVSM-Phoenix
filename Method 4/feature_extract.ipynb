{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO -\n",
    "# Load the audio clips\n",
    "# Create a df of audio vs user Name\n",
    "# Train model for that df\n",
    "# Repeat same for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Abhishek\n",
      "Word: Archives\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "input_string = \"Abhishek1Archives\"\n",
    "\n",
    "# Find the index where the numeric part starts\n",
    "index = next(i for i, char in enumerate(input_string) if char.isdigit())\n",
    "\n",
    "# Separate the name and word\n",
    "name = input_string[:index]\n",
    "word = input_string[index+1:]\n",
    "num = input_string[index]\n",
    "print(\"Name:\", name)\n",
    "print(\"Word:\", word)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_path = \"audio_files\"\n",
    "# List all files in the directory\n",
    "file_names = os.listdir(directory_path)\n",
    "# Iterate over the filenames\n",
    "for filename in file_names:\n",
    "    index = next(i for i, char in enumerate(filename) if char.isdigit())\n",
    "    # Separate the name and word\n",
    "    name = filename[:index]\n",
    "    word = filename[index+1:]\n",
    "    num = filename[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.2-cp310-cp310-win_amd64.whl (7.6 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.47.2-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-10.2.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.26.3)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-win_amd64.whl (186 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.47.2 kiwisolver-1.4.5 matplotlib-3.8.2 pillow-10.2.0 pyparsing-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'10Archives'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m mfccs \u001b[38;5;241m=\u001b[39m extract_mfcc(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory_path, filename))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Append a new row with the name and MFCC values to the corresponding DataFrame\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mword_dataframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m row_data \u001b[38;5;241m=\u001b[39m [name] \u001b[38;5;241m+\u001b[39m mfccs\n\u001b[0;32m     33\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m row_data  \u001b[38;5;66;03m# Assuming the numbering starts from 1\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: '10Archives'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    return mfccs.tolist()  # Convert to list for easier storage in DataFrame\n",
    "\n",
    "# Directory containing audio files\n",
    "directory_path = \"audio_files\"\n",
    "\n",
    "# List of words\n",
    "words = ['Environment', 'Archives', 'Pronounciation', 'Hour', 'Wednesday', 'Violence', 'Tomb', 'Suite', 'Iron', 'Reciept', 'Chores']\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each word\n",
    "word_dataframes = {word: pd.DataFrame(columns=[\"Name\"] + [f\"MFCC_{i+1}\" for i in range(10)]) for word in words}\n",
    "\n",
    "# Iterate over the filenames\n",
    "for filename in os.listdir(directory_path):\n",
    "    index = next(i for i, char in enumerate(filename) if char.isdigit())\n",
    "    name = filename[:index]\n",
    "    word = filename[index:-4]  # Assuming the file extension is always \".wav\"\n",
    "    num = int(filename[index])\n",
    "\n",
    "    # Extract MFCC features\n",
    "    mfccs = extract_mfcc(os.path.join(directory_path, filename))\n",
    "\n",
    "    # Append a new row with the name and MFCC values to the corresponding DataFrame\n",
    "    df = word_dataframes[word]\n",
    "    row_data = [name] + mfccs\n",
    "    df.loc[num - 1] = row_data  # Assuming the numbering starts from 1\n",
    "    word_dataframes[word] = df\n",
    "\n",
    "# Display or process the created DataFrames as needed\n",
    "for word, df in word_dataframes.items():\n",
    "    print(f\"DataFrame for word '{word}':\")\n",
    "    print(df)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for word 'Environment' saved to 'df\\Environment_dataframe.csv'\n",
      "DataFrame for word 'Archives' saved to 'df\\Archives_dataframe.csv'\n",
      "DataFrame for word 'Pronounciation' saved to 'df\\Pronounciation_dataframe.csv'\n",
      "DataFrame for word 'Hour' saved to 'df\\Hour_dataframe.csv'\n",
      "DataFrame for word 'Wednesday' saved to 'df\\Wednesday_dataframe.csv'\n",
      "DataFrame for word 'Violence' saved to 'df\\Violence_dataframe.csv'\n",
      "DataFrame for word 'Tomb' saved to 'df\\Tomb_dataframe.csv'\n",
      "DataFrame for word 'Suite' saved to 'df\\Suite_dataframe.csv'\n",
      "DataFrame for word 'Iron' saved to 'df\\Iron_dataframe.csv'\n",
      "DataFrame for word 'Reciept' saved to 'df\\Reciept_dataframe.csv'\n",
      "DataFrame for word 'Chores' saved to 'df\\Chores_dataframe.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import re\n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    return mfccs.tolist()  # Convert to list for easier storage in DataFrame\n",
    "\n",
    "# Directory containing audio files\n",
    "directory_path = \"audio_files\"\n",
    "\n",
    "# Target folder to save DataFrames as CSV files\n",
    "target_folder = \"df\"\n",
    "\n",
    "# Create the target folder if it doesn't exist\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# List of words\n",
    "words = ['Environment', 'Archives', 'Pronounciation', 'Hour', 'Wednesday', 'Violence', 'Tomb', 'Suite', 'Iron', 'Reciept', 'Chores']\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each word\n",
    "word_dataframes = {word: pd.DataFrame() for word in words}\n",
    "\n",
    "# Iterate over the filenames\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Use regular expression to extract name and word\n",
    "    match = re.match(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', filename)\n",
    "    if match:\n",
    "        name = match.group(1)\n",
    "        word = match.group(3)\n",
    "        num = int(match.group(2))\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = extract_mfcc(os.path.join(directory_path, filename))\n",
    "\n",
    "        # Create a DataFrame for each person\n",
    "        person_df = pd.DataFrame({\"Name\": [name], \"MFCC\": [mfccs]})\n",
    "        \n",
    "        # Concatenate with existing DataFrame for the word\n",
    "        word_dataframes[word] = pd.concat([word_dataframes[word], person_df], ignore_index=True)\n",
    "\n",
    "# Save each DataFrame to a separate CSV file in the target folder\n",
    "for word, df in word_dataframes.items():\n",
    "    output_file_path = os.path.join(target_folder, f\"{word}_dataframe.csv\")\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    print(f\"DataFrame for word '{word}' saved to '{output_file_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
