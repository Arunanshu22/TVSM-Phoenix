{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import random\n",
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import re\n",
    "import numpy as np\n",
    "import joblib\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronounciation Wednesday Iron Environment Tomb\n"
     ]
    }
   ],
   "source": [
    "# generate the random words\n",
    "words = ['Environment', 'Archives', 'Pronounciation', \n",
    "         'Hour', 'Wednesday', 'Violence', 'Tomb', 'Suite', \n",
    "         'Iron', 'Reciept', 'Chores']\n",
    "random_words = random.sample(words, 5)\n",
    "random_string = ' '.join(random_words)\n",
    "print(random_string)\n",
    "\n",
    "# Directory path to traverse\n",
    "directory_path = 'models/'\n",
    "models = []\n",
    "\n",
    "for word in random_words:\n",
    "    for file in os.listdir(directory_path):\n",
    "        if word in file:\n",
    "            models.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pronounciation_RandomForest_model.joblib',\n",
       " 'Wednesday_RandomForest_model.joblib',\n",
       " 'Iron_RandomForest_model.joblib',\n",
       " 'Environment_RandomForest_model.joblib',\n",
       " 'Tomb_RandomForest_model.joblib']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording file audio_files/test/Unknown1Pronounciation.wav\n",
      "Pronounciation - 1\n",
      "Recorded file audio_files/test/Unknown1Pronounciation.wav\n",
      "Recording file audio_files/test/Unknown1Wednesday.wav\n",
      "Wednesday - 1\n",
      "Recorded file audio_files/test/Unknown1Wednesday.wav\n",
      "Recording file audio_files/test/Unknown1Iron.wav\n",
      "Iron - 1\n",
      "Recorded file audio_files/test/Unknown1Iron.wav\n",
      "Recording file audio_files/test/Unknown1Environment.wav\n",
      "Environment - 1\n",
      "Recorded file audio_files/test/Unknown1Environment.wav\n",
      "Recording file audio_files/test/Unknown1Tomb.wav\n",
      "Tomb - 1\n",
      "Recorded file audio_files/test/Unknown1Tomb.wav\n"
     ]
    }
   ],
   "source": [
    "# collect audio samples\n",
    "name = 'Unknown'\n",
    "freq = 44100\n",
    "duration = 2\n",
    "\n",
    "def delete_old_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "delete_old_files(\"audio_files/test\")\n",
    "\n",
    "words = random_words\n",
    "\n",
    "for word in words:\n",
    "    for i in range(1):\n",
    "        file_name = \"audio_files/test/\" + name + str(i+1) + word + '.wav'\n",
    "        print(\"Recording file \" + file_name)\n",
    "        print(f'{word} - {i+1}')\n",
    "        recording = sd.rec(int(duration * freq), samplerate=freq, channels=2)\n",
    "        sd.wait()\n",
    "        write(file_name, freq, recording)\n",
    "        print(\"Recorded file \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for word 'Pronounciation' saved to 'df/test\\Pronounciation_dataframe.csv'\n",
      "DataFrame for word 'Wednesday' saved to 'df/test\\Wednesday_dataframe.csv'\n",
      "DataFrame for word 'Iron' saved to 'df/test\\Iron_dataframe.csv'\n",
      "DataFrame for word 'Environment' saved to 'df/test\\Environment_dataframe.csv'\n",
      "DataFrame for word 'Tomb' saved to 'df/test\\Tomb_dataframe.csv'\n"
     ]
    }
   ],
   "source": [
    "# generate df for test set\n",
    "# generate the MFCC from audio files - \n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    return mfccs.tolist()  # Convert to list for easier storage in DataFrame\n",
    "\n",
    "# Directory containing audio files\n",
    "directory_path = \"audio_files/test\"\n",
    "\n",
    "# Target folder to save DataFrames as CSV files\n",
    "target_folder = \"df/test\"\n",
    "\n",
    "# Create the target folder if it doesn't exist\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# List of words\n",
    "words = random_words\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each word\n",
    "word_dataframes = {word: pd.DataFrame() for word in words}\n",
    "\n",
    "# Iterate over the filenames\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Use regular expression to extract name and word\n",
    "    match = re.match(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', filename)\n",
    "    if match:\n",
    "        name = match.group(1)\n",
    "        word = match.group(3)\n",
    "        num = int(match.group(2))\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = extract_mfcc(os.path.join(directory_path, filename))\n",
    "\n",
    "        # Create a DataFrame for each person\n",
    "        person_df = pd.DataFrame({\"Name\": [name], \"MFCC\": [mfccs]})\n",
    "        \n",
    "        # Concatenate with existing DataFrame for the word\n",
    "        word_dataframes[word] = pd.concat([word_dataframes[word], person_df], ignore_index=True)\n",
    "\n",
    "# Save each DataFrame to a separate CSV file in the target folder\n",
    "for word, df in word_dataframes.items():\n",
    "    output_file_path = os.path.join(target_folder, f\"{word}_dataframe.csv\")\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    print(f\"DataFrame for word '{word}' saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Abhishek'], dtype=object),\n",
       " array(['Arun'], dtype=object),\n",
       " array(['Arun'], dtype=object),\n",
       " array(['Sunamdha'], dtype=object),\n",
       " array(['Abhishek'], dtype=object)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict from the df\n",
    "\n",
    "# List of words\n",
    "words = random_words\n",
    "\n",
    "model = models\n",
    "users = []\n",
    "\n",
    "for i in range(len(words)):\n",
    "    # Load the dataframe for the current word\n",
    "    df = pd.read_csv(\"df/test/\" + f\"{words[i]}_dataframe.csv\")\n",
    "    # Convert the string representation of MFCC values back to list of lists\n",
    "    df[\"MFCC\"] = df[\"MFCC\"].apply(ast.literal_eval)\n",
    "    # Flatten the MFCC values\n",
    "    df[\"MFCC\"] = df[\"MFCC\"].apply(lambda x: [item for sublist in x for item in sublist])\n",
    "    loaded_model = joblib.load(\"models/\" + model[i])\n",
    "    \n",
    "    X = np.array(df[\"MFCC\"].tolist())\n",
    "    user = loaded_model.predict(X)\n",
    "    users.append(user)\n",
    "\n",
    "users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
