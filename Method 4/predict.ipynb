{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciept Chores Suite Iron Violence\n"
     ]
    }
   ],
   "source": [
    "# generate the random words\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "words = ['Environment', 'Archives', 'Pronounciation', \n",
    "         'Hour', 'Wednesday', 'Violence', 'Tomb', 'Suite', \n",
    "         'Iron', 'Reciept', 'Chores']\n",
    "random_words = random.sample(words, 5)\n",
    "random_string = ' '.join(random_words)\n",
    "print(random_string)\n",
    "\n",
    "# Directory path to traverse\n",
    "directory_path = 'models/'\n",
    "models = []\n",
    "\n",
    "for word in random_words:\n",
    "    for file in os.listdir(directory_path):\n",
    "        if word in file:\n",
    "            models.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reciept_RandomForest_model.joblib',\n",
       " 'Chores_RandomForest_model.joblib',\n",
       " 'Suite_RandomForest_model.joblib',\n",
       " 'Iron_RandomForest_model.joblib',\n",
       " 'Violence_RandomForest_model.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording file audio_files/test/Unknown1Reciept.wav\n",
      "Reciept - 1\n",
      "Recorded file audio_files/test/Unknown1Reciept.wav\n",
      "Recording file audio_files/test/Unknown1Chores.wav\n",
      "Chores - 1\n",
      "Recorded file audio_files/test/Unknown1Chores.wav\n",
      "Recording file audio_files/test/Unknown1Suite.wav\n",
      "Suite - 1\n",
      "Recorded file audio_files/test/Unknown1Suite.wav\n",
      "Recording file audio_files/test/Unknown1Iron.wav\n",
      "Iron - 1\n",
      "Recorded file audio_files/test/Unknown1Iron.wav\n",
      "Recording file audio_files/test/Unknown1Violence.wav\n",
      "Violence - 1\n",
      "Recorded file audio_files/test/Unknown1Violence.wav\n"
     ]
    }
   ],
   "source": [
    "# collect audio samples\n",
    "\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "\n",
    "# name = input(\"Enter your name: \")\n",
    "name = 'Unknown'\n",
    "freq = 44100\n",
    "duration = 2\n",
    "\n",
    "def delete_old_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "delete_old_files(\"audio_files/test\")\n",
    "\n",
    "words = random_words\n",
    "\n",
    "for word in words:\n",
    "    for i in range(1):\n",
    "        file_name = \"audio_files/test/\" + name + str(i+1) + word + '.wav'\n",
    "        print(\"Recording file \" + file_name)\n",
    "        print(f'{word} - {i+1}')\n",
    "        recording = sd.rec(int(duration * freq), samplerate=freq, channels=2)\n",
    "        sd.wait()\n",
    "        write(file_name, freq, recording)\n",
    "        print(\"Recorded file \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for word 'Reciept' saved to 'df/test\\Reciept_dataframe.csv'\n",
      "DataFrame for word 'Chores' saved to 'df/test\\Chores_dataframe.csv'\n",
      "DataFrame for word 'Suite' saved to 'df/test\\Suite_dataframe.csv'\n",
      "DataFrame for word 'Iron' saved to 'df/test\\Iron_dataframe.csv'\n",
      "DataFrame for word 'Violence' saved to 'df/test\\Violence_dataframe.csv'\n"
     ]
    }
   ],
   "source": [
    "# generate df for test set\n",
    "# generate the MFCC from audio files - \n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import re\n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    return mfccs.tolist()  # Convert to list for easier storage in DataFrame\n",
    "\n",
    "# Directory containing audio files\n",
    "directory_path = \"audio_files/test\"\n",
    "\n",
    "# Target folder to save DataFrames as CSV files\n",
    "target_folder = \"df/test\"\n",
    "\n",
    "# Create the target folder if it doesn't exist\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# List of words\n",
    "words = random_words\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each word\n",
    "word_dataframes = {word: pd.DataFrame() for word in words}\n",
    "\n",
    "# Iterate over the filenames\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Use regular expression to extract name and word\n",
    "    match = re.match(r'([A-Za-z]+)(\\d+)([A-Za-z]+)', filename)\n",
    "    if match:\n",
    "        name = match.group(1)\n",
    "        word = match.group(3)\n",
    "        num = int(match.group(2))\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = extract_mfcc(os.path.join(directory_path, filename))\n",
    "\n",
    "        # Create a DataFrame for each person\n",
    "        person_df = pd.DataFrame({\"Name\": [name], \"MFCC\": [mfccs]})\n",
    "        \n",
    "        # Concatenate with existing DataFrame for the word\n",
    "        word_dataframes[word] = pd.concat([word_dataframes[word], person_df], ignore_index=True)\n",
    "\n",
    "# Save each DataFrame to a separate CSV file in the target folder\n",
    "for word, df in word_dataframes.items():\n",
    "    output_file_path = os.path.join(target_folder, f\"{word}_dataframe.csv\")\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    print(f\"DataFrame for word '{word}' saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arun']\n",
      "['Abhishek']\n",
      "['Sunamdha']\n",
      "['Arun']\n",
      "['Sunamdha']\n"
     ]
    }
   ],
   "source": [
    "# predict from the df\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import ast\n",
    "\n",
    "# Directory containing audio files\n",
    "# directory_path = \"audio_files\"\n",
    "\n",
    "# List of words\n",
    "words = random_words\n",
    "\n",
    "# Initialize a dictionary to store trained models\n",
    "trained_models = {}\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', C=1),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "model = models\n",
    "\n",
    "for i in range(len(words)):\n",
    "    # Load the dataframe for the current word\n",
    "    df = pd.read_csv(\"df/test/\" + f\"{words[i]}_dataframe.csv\")\n",
    "    # Convert the string representation of MFCC values back to list of lists\n",
    "    df[\"MFCC\"] = df[\"MFCC\"].apply(ast.literal_eval)\n",
    "    # Flatten the MFCC values\n",
    "    df[\"MFCC\"] = df[\"MFCC\"].apply(lambda x: [item for sublist in x for item in sublist])\n",
    "    loaded_model = joblib.load(\"models/\" + model[i])\n",
    "    \n",
    "    X = np.array(df[\"MFCC\"].tolist())\n",
    "    user = loaded_model.predict(X)\n",
    "    print(user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
