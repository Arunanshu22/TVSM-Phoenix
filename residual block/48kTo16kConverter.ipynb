{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes input file and breaks into 1 second clips of 16000 sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa attribute output",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/arun.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m \u001b[43maudio_to_clips\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36maudio_to_clips\u001b[1;34m(audio_file, output_folder, clip_duration, sr)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Save the clips in the output folder\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, clip \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clips):\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241m.\u001b[39mwrite_wav(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m), clip, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\lazy_loader\\__init__.py:89\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attr\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: No librosa attribute output"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def audio_to_clips(audio_file, output_folder, clip_duration=1, sr=16000):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=sr)\n",
    "    \n",
    "    # Calculate the number of samples per clip\n",
    "    samples_per_clip = int(sr * clip_duration)\n",
    "    \n",
    "    # Calculate the total number of clips\n",
    "    total_clips = len(y) // samples_per_clip\n",
    "    \n",
    "    clips = []\n",
    "    \n",
    "    # Extract 1-second clips\n",
    "    for i in range(total_clips):\n",
    "        start = i * samples_per_clip\n",
    "        end = (i + 1) * samples_per_clip\n",
    "        clip = y[start:end]\n",
    "        clips.append(clip)\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the clips in the output folder\n",
    "    for i, clip in enumerate(clips):\n",
    "        librosa.output.write_wav(os.path.join(output_folder, f\"clip_{i}.wav\"), clip, sr=16000)\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/arun.wav\"\n",
    "output_folder = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips\"\n",
    "audio_to_clips(audio_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def audio_to_clips(audio_file, output_folder, clip_duration=3, sr=16000):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=sr)\n",
    "    \n",
    "    # Calculate the number of samples per clip\n",
    "    samples_per_clip = int(sr * clip_duration)\n",
    "    \n",
    "    # Calculate the total number of clips\n",
    "    total_clips = len(y) // samples_per_clip\n",
    "    \n",
    "    clips = []\n",
    "    \n",
    "    # Extract 1-second clips\n",
    "    for i in range(total_clips):\n",
    "        start = i * samples_per_clip\n",
    "        end = (i + 1) * samples_per_clip\n",
    "        clip = y[start:end]\n",
    "        clips.append(clip)\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the clips in the output folder\n",
    "    for i, clip in enumerate(clips):\n",
    "        write(os.path.join(output_folder, f\"clip_{i}.wav\"), sr, clip)\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/arun.wav\"\n",
    "output_folder = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips\"\n",
    "audio_to_clips(audio_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def audio_to_clips(audio_file, output_folder, clip_duration=3, sr=16000):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=sr)\n",
    "    \n",
    "    # Calculate the number of samples per clip\n",
    "    samples_per_clip = int(sr * clip_duration)\n",
    "    \n",
    "    # Calculate the total number of clips\n",
    "    total_clips = len(y) // samples_per_clip\n",
    "    \n",
    "    clips = []\n",
    "    \n",
    "    # Extract clips\n",
    "    for i in range(total_clips):\n",
    "        start = i * samples_per_clip\n",
    "        end = (i + 1) * samples_per_clip\n",
    "        clip = y[start:end]\n",
    "        clips.append(clip)\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the clips in the output folder\n",
    "    for i, clip in enumerate(clips):\n",
    "        output_file = os.path.join(output_folder, f\"clip_{i}.wav\")\n",
    "        # Write the clip in PCM format\n",
    "        write(output_file, sr, (clip * 32767).astype(np.int16))  # Convert to 16-bit PCM\n",
    "        # Convert to PCM format if not already in PCM\n",
    "        if librosa.get_samplerate(output_file) != sr:\n",
    "            os.system(f\"ffmpeg -i {output_file} -acodec pcm_s16le -ar {sr} {output_file}.pcm\")\n",
    "            os.remove(output_file)\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/arun.wav\"\n",
    "output_folder = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips\"\n",
    "audio_to_clips(audio_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCM_16\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "def is_pcm_encoding(audio_file):\n",
    "    try:\n",
    "        with sf.SoundFile(audio_file, 'r') as f:\n",
    "            encoding = f.subtype\n",
    "            print(encoding)\n",
    "            return 'PCM' in encoding\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips/clip_55.wav\"\n",
    "print(is_pcm_encoding(audio_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCM_16\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "def get_encoding(audio_file):\n",
    "    try:\n",
    "        with sf.SoundFile(audio_file, 'r') as f:\n",
    "            encoding = f.subtype\n",
    "            return encoding\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips/clip_4.wav\"\n",
    "print(get_encoding(audio_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate of the audio file: 48000\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def get_sample_rate(audio_file):\n",
    "    # Load the audio file and get its sample rate\n",
    "    sr = librosa.get_samplerate(audio_file)\n",
    "    return sr\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/arun.wav\"\n",
    "sample_rate = get_sample_rate(audio_file)\n",
    "print(\"Sample rate of the audio file:\", sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def concatenate_clips(input_folder, output_file):\n",
    "    # Initialize an empty list to store the audio clips\n",
    "    clips = []\n",
    "    \n",
    "    # Iterate through each file in the input folder\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        # Check if the file is a WAV file\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            # Load the audio clip\n",
    "            clip, sr = librosa.load(os.path.join(input_folder, file_name), sr=None)\n",
    "            clips.append(clip)\n",
    "    \n",
    "    # Concatenate all clips into a single array\n",
    "    concatenated_clip = np.concatenate(clips)\n",
    "    \n",
    "    # Save the concatenated clip as a WAV file\n",
    "    write(output_file, sr, concatenated_clip)\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips\"\n",
    "output_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/final_clip.wav\"\n",
    "concatenate_clips(input_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def concatenate_clips(input_folder, output_file):\n",
    "    # Get the list of audio files in the input folder\n",
    "    audio_files = sorted([file_name for file_name in os.listdir(input_folder) if file_name.endswith(\".wav\")])\n",
    "    \n",
    "    # Initialize an empty list to store the audio clips\n",
    "    clips = []\n",
    "    \n",
    "    # Iterate through each file in the sorted list\n",
    "    for file_name in audio_files:\n",
    "        # Load the audio clip\n",
    "        clip, sr = librosa.load(os.path.join(input_folder, file_name), sr=None)\n",
    "        clips.append(clip)\n",
    "    \n",
    "    # Concatenate all clips into a single array\n",
    "    concatenated_clip = np.concatenate(clips)\n",
    "    \n",
    "    # Save the concatenated clip as a WAV file\n",
    "    write(output_file, sr, concatenated_clip)\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/clips\"\n",
    "output_file = \"D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Train/Arunanshu/final_clip_ordered.wav\"\n",
    "concatenate_clips(input_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def split_audio(input_file, output_folder):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(input_file)\n",
    "\n",
    "    # Calculate the duration of the audio in milliseconds\n",
    "    audio_duration = len(audio)\n",
    "\n",
    "    # Duration of each segment in milliseconds\n",
    "    segment_duration = 20 * 60 * 1000  # 20 minutes in milliseconds\n",
    "\n",
    "    # Calculate the number of segments\n",
    "    num_segments = audio_duration // segment_duration\n",
    "\n",
    "    # Split the audio into segments of 20 minutes and the remaining\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * segment_duration\n",
    "        end_time = start_time + segment_duration\n",
    "        segment = audio[start_time:end_time]\n",
    "        segment.export(os.path.join(output_folder, f\"20_min_part.wav\"), format=\"wav\")\n",
    "\n",
    "    # Remaining part after splitting\n",
    "    remaining_audio = audio[num_segments * segment_duration:]\n",
    "    if len(remaining_audio) > 0:\n",
    "        remaining_audio.export(os.path.join(output_folder, \"remaining_part.wav\"), format=\"wav\")\n",
    "\n",
    "# Example usage\n",
    "input_file = \"D:/Clones/Sunamdha/TVSM-Phoenix/residual block/arun.wav\"\n",
    "output_folder = \"20+5 split/\"  # Provide the path to the output folder\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "split_audio(input_file, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
