{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import os\n",
    "from python_speech_features import mfcc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Specify the folder path for KNN models\n",
    "models_folder = 'models/model.h5'\n",
    "\n",
    "def record_audio(duration=3, sr=22050):\n",
    "    print(\"Please read the word.\")\n",
    "    audio_data = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=np.float32)\n",
    "    sd.wait()\n",
    "    return audio_data.flatten(), sr\n",
    "\n",
    "# Initialize a dictionary to store user recordings\n",
    "user_recordings = {}\n",
    "\n",
    "# Record audio for each selected word\n",
    "for word_model in selected_words:\n",
    "    word = word_model.split('_')[0]\n",
    "    print(f\"\\nPlease read the word: {word.capitalize()}\")\n",
    "\n",
    "    # Record audio\n",
    "    audio_data, sr = record_audio()\n",
    "\n",
    "    # Extract MFCC features\n",
    "    features = extract_features(audio_data, sr)\n",
    "\n",
    "    # Store the user's recording and corresponding MFCC features\n",
    "    user_recordings[word] = {'Audio': audio_data, 'Vector': features}\n",
    "\n",
    "# Predict the speaker for each word using the corresponding KNN model\n",
    "for word, recording_data in user_recordings.items():\n",
    "    # Load the corresponding KNN model\n",
    "    model_path = os.path.join(models_folder, f'{word}_knn_model.joblib')\n",
    "    knn_model = joblib.load(model_path)\n",
    "    \n",
    "    # Retrieve the number of features expected by the KNN model\n",
    "    expected_num_features = knn_model._fit_X.shape[1]\n",
    "    \n",
    "    # Ensure the input data has the same number of features as the training data\n",
    "    num_features_recording = len(recording_data['Vector'])\n",
    "    \n",
    "    if num_features_recording != expected_num_features:\n",
    "        # Calculate the mean value of the features\n",
    "        mean_value = np.mean(recording_data['Vector'])\n",
    "        \n",
    "        # Calculate the difference between expected and actual number of features\n",
    "        num_features_diff = expected_num_features - num_features_recording\n",
    "        \n",
    "        if num_features_diff < 0:\n",
    "            # Truncate the features if the difference is negative\n",
    "            recording_data['Vector'] = recording_data['Vector'][:expected_num_features]\n",
    "        else:\n",
    "            # Pad the features with the mean value to match the expected dimensions\n",
    "            recording_data['Vector'] = np.pad(recording_data['Vector'], (0, num_features_diff), constant_values=mean_value)\n",
    "    \n",
    "    # Predict the speaker using MFCC features\n",
    "    user_prediction = knn_model.predict([recording_data['Vector']])\n",
    "    print(f\"\\nFor word '{word}', predicted speaker: {user_prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
