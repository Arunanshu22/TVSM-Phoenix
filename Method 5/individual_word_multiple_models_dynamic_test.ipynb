{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 'prononciation' files\n",
    "# generate the df with mfcc, vector, row mean\n",
    "# train all models from additional_features file\n",
    "# collect 5 test samples\n",
    "# augment to 5*7 = 35\n",
    "# predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pronounciation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['augmented_audio/Abhishek10Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_stretched.wav']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = []\n",
    "for filename in os.listdir(\"augmented_audio/\"):\n",
    "    if \"pronounciation\" in filename.lower():\n",
    "        files.append(\"augmented_audio/\" + filename)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating df of Pronounciation files - MFCC, Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word: Pronounciation\n",
      "         Name                                               MFCC  \\\n",
      "0    Abhishek  [-399.33517, -410.98068, -446.12094, -462.5722...   \n",
      "1    Abhishek  [-393.50916, -416.78497, -443.1696, -447.20905...   \n",
      "2    Abhishek  [-398.04355, -407.43915, -423.16266, -427.1824...   \n",
      "3    Abhishek  [-279.38562, -255.72926, -259.68298, -265.5101...   \n",
      "4    Abhishek  [-398.58353, -407.81512, -439.38373, -454.3276...   \n",
      "..        ...                                                ...   \n",
      "205  Sunamdha  [-454.1231, -468.5504, -485.27255, -494.31076,...   \n",
      "206  Sunamdha  [-304.044, -272.84253, -268.24622, -271.28018,...   \n",
      "207  Sunamdha  [-455.58807, -471.42218, -504.5795, -518.75836...   \n",
      "208  Sunamdha  [-445.229, -472.5361, -499.69522, -508.4312, -...   \n",
      "209  Sunamdha  [-453.48724, -471.49097, -492.32755, -502.4375...   \n",
      "\n",
      "                                                Vector  \n",
      "0    [1.4150455334195575, 0.9546512831353698, 0.366...  \n",
      "1    [0.747931590109873, 0.4648794312754385, 0.2183...  \n",
      "2    [0.35104955499818213, 0.8060239526847797, 0.11...  \n",
      "3    [0.008702108523313145, 0.83070381055796, 1.778...  \n",
      "4    [0.9068272101350625, 0.8688605322756997, 0.287...  \n",
      "..                                                 ...  \n",
      "205  [-0.5167410570874565, -0.4283380087267415, 0.3...  \n",
      "206  [-0.41733527759116845, -0.6118640605585646, -0...  \n",
      "207  [-0.20458474852108818, -0.3249366339081963, 0....  \n",
      "208  [-0.47416335629183765, -0.5520375781211978, 0....  \n",
      "209  [-0.207728415523001, -0.4549384943630632, 0.34...  \n",
      "\n",
      "[210 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>MFCC</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>[-399.33517, -410.98068, -446.12094, -462.5722...</td>\n",
       "      <td>[1.4150455334195575, 0.9546512831353698, 0.366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>[-393.50916, -416.78497, -443.1696, -447.20905...</td>\n",
       "      <td>[0.747931590109873, 0.4648794312754385, 0.2183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>[-398.04355, -407.43915, -423.16266, -427.1824...</td>\n",
       "      <td>[0.35104955499818213, 0.8060239526847797, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>[-279.38562, -255.72926, -259.68298, -265.5101...</td>\n",
       "      <td>[0.008702108523313145, 0.83070381055796, 1.778...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>[-398.58353, -407.81512, -439.38373, -454.3276...</td>\n",
       "      <td>[0.9068272101350625, 0.8688605322756997, 0.287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>[-454.1231, -468.5504, -485.27255, -494.31076,...</td>\n",
       "      <td>[-0.5167410570874565, -0.4283380087267415, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>[-304.044, -272.84253, -268.24622, -271.28018,...</td>\n",
       "      <td>[-0.41733527759116845, -0.6118640605585646, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>[-455.58807, -471.42218, -504.5795, -518.75836...</td>\n",
       "      <td>[-0.20458474852108818, -0.3249366339081963, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>[-445.229, -472.5361, -499.69522, -508.4312, -...</td>\n",
       "      <td>[-0.47416335629183765, -0.5520375781211978, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>[-453.48724, -471.49097, -492.32755, -502.4375...</td>\n",
       "      <td>[-0.207728415523001, -0.4549384943630632, 0.34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name                                               MFCC  \\\n",
       "0    Abhishek  [-399.33517, -410.98068, -446.12094, -462.5722...   \n",
       "1    Abhishek  [-393.50916, -416.78497, -443.1696, -447.20905...   \n",
       "2    Abhishek  [-398.04355, -407.43915, -423.16266, -427.1824...   \n",
       "3    Abhishek  [-279.38562, -255.72926, -259.68298, -265.5101...   \n",
       "4    Abhishek  [-398.58353, -407.81512, -439.38373, -454.3276...   \n",
       "..        ...                                                ...   \n",
       "205  Sunamdha  [-454.1231, -468.5504, -485.27255, -494.31076,...   \n",
       "206  Sunamdha  [-304.044, -272.84253, -268.24622, -271.28018,...   \n",
       "207  Sunamdha  [-455.58807, -471.42218, -504.5795, -518.75836...   \n",
       "208  Sunamdha  [-445.229, -472.5361, -499.69522, -508.4312, -...   \n",
       "209  Sunamdha  [-453.48724, -471.49097, -492.32755, -502.4375...   \n",
       "\n",
       "                                                Vector  \n",
       "0    [1.4150455334195575, 0.9546512831353698, 0.366...  \n",
       "1    [0.747931590109873, 0.4648794312754385, 0.2183...  \n",
       "2    [0.35104955499818213, 0.8060239526847797, 0.11...  \n",
       "3    [0.008702108523313145, 0.83070381055796, 1.778...  \n",
       "4    [0.9068272101350625, 0.8688605322756997, 0.287...  \n",
       "..                                                 ...  \n",
       "205  [-0.5167410570874565, -0.4283380087267415, 0.3...  \n",
       "206  [-0.41733527759116845, -0.6118640605585646, -0...  \n",
       "207  [-0.20458474852108818, -0.3249366339081963, 0....  \n",
       "208  [-0.47416335629183765, -0.5520375781211978, 0....  \n",
       "209  [-0.207728415523001, -0.4549384943630632, 0.34...  \n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=25):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs.flatten()\n",
    "\n",
    "# Function to extract features (MFCC and delta coefficients)\n",
    "def extract_features(audio, rate):\n",
    "    mfcc_feature = mfcc.mfcc(audio, rate, 0.025, 0.01, 20, nfft=1200, appendEnergy=True)\n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature, delta))\n",
    "    return combined.flatten()\n",
    "\n",
    "# Function to calculate delta coefficients\n",
    "def calculate_delta(array):\n",
    "    rows, cols = array.shape\n",
    "    deltas = np.zeros((rows, 20))\n",
    "    n = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= n:\n",
    "            if i - j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i - j\n",
    "            if i + j > rows - 1:\n",
    "                second = rows - 1\n",
    "            else:\n",
    "                second = i + j\n",
    "            index.append((second, first))\n",
    "            j += 1\n",
    "        deltas[i] = (array[index[0][0]] - array[index[0][1]] + (2 * (array[index[1][0]] - array[index[1][1]]))) / 10\n",
    "    return deltas\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = \"augmented_audio/\"\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Create a dictionary to store data for each word\n",
    "word_data = {}\n",
    "\n",
    "# Traverse through each file\n",
    "for file_name in files:\n",
    "    if \"pronounciation\" in file_name.lower():\n",
    "        if file_name.lower().endswith(\".wav\"):\n",
    "            # Parse the file name to extract information\n",
    "            pattern = r'([A-Za-z]+)\\d+([A-Za-z]+)'\n",
    "            # Use re.match to find the pattern in the file name\n",
    "            match = re.match(pattern, file_name)\n",
    "            if match:\n",
    "                # Extract the name and word from the matched groups\n",
    "                name = match.group(1)\n",
    "                word = match.group(2)\n",
    "            \n",
    "            # Check if the word is already in the dictionary\n",
    "            if word not in word_data:\n",
    "                word_data[word] = {'Name': [], 'MFCC': [], 'Vector': []}\n",
    "\n",
    "            # Load the original audio and extract MFCC\n",
    "            input_file_path = os.path.join(folder_path, file_name)\n",
    "            mfccs = extract_mfcc(input_file_path)\n",
    "            \n",
    "            # Load the original audio\n",
    "            sr, audio = read(os.path.join(folder_path, file_name))\n",
    "            \n",
    "            # Extract features (MFCC and delta coefficients)\n",
    "            features = extract_features(audio, sr)\n",
    "            \n",
    "            # Add data to the dictionary\n",
    "            word_data[word]['Name'].append(name)\n",
    "            word_data[word]['MFCC'].append(mfccs)\n",
    "            word_data[word]['Vector'].append(features)  # Add the vector values\n",
    "\n",
    "# Create DataFrames for each word\n",
    "word_dfs = {}\n",
    "for word, data in word_data.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    word_dfs[word] = df\n",
    "\n",
    "# Display DataFrames for each word\n",
    "for word, df in word_dfs.items():\n",
    "    print(f\"\\nWord: {word}\")\n",
    "    print(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training all models on Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating Logistic Regression...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating Decision Tree...\n",
      "Accuracy: 0.83\n",
      "Confusion Matrix:\n",
      "[[10  2  0]\n",
      " [ 3 12  0]\n",
      " [ 2  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.67      0.83      0.74        12\n",
      "        Arun       0.86      0.80      0.83        15\n",
      "    Sunamdha       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.84      0.83      0.83        42\n",
      "weighted avg       0.85      0.83      0.84        42\n",
      "\n",
      "\n",
      "Training and evaluating Random Forest...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating Gradient Boosting...\n",
      "Accuracy: 0.93\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 1 14  0]\n",
      " [ 2  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.80      1.00      0.89        12\n",
      "        Arun       1.00      0.93      0.97        15\n",
      "    Sunamdha       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.93      0.93      0.93        42\n",
      "weighted avg       0.94      0.93      0.93        42\n",
      "\n",
      "\n",
      "Training and evaluating Support Vector Machine...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating K-Nearest Neighbors...\n",
      "Accuracy: 0.98\n",
      "Confusion Matrix:\n",
      "[[11  1  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      0.92      0.96        12\n",
      "        Arun       0.94      1.00      0.97        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.98        42\n",
      "   macro avg       0.98      0.97      0.97        42\n",
      "weighted avg       0.98      0.98      0.98        42\n",
      "\n",
      "\n",
      "Training and evaluating Naive Bayes...\n",
      "Accuracy: 0.95\n",
      "Confusion Matrix:\n",
      "[[11  1  0]\n",
      " [ 0 15  0]\n",
      " [ 1  0 14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.92      0.92      0.92        12\n",
      "        Arun       0.94      1.00      0.97        15\n",
      "    Sunamdha       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.95      0.95      0.95        42\n",
      "weighted avg       0.95      0.95      0.95        42\n",
      "\n",
      "\n",
      "Training and evaluating MLP Classifier...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating AdaBoost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 6  9  0]\n",
      " [ 1  0 14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.63      1.00      0.77        12\n",
      "        Arun       1.00      0.60      0.75        15\n",
      "    Sunamdha       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.88      0.84      0.83        42\n",
      "weighted avg       0.89      0.83      0.83        42\n",
      "\n",
      "\n",
      "Training and evaluating Bagging Classifier...\n",
      "Accuracy: 0.93\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 3 12  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.80      1.00      0.89        12\n",
      "        Arun       1.00      0.80      0.89        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.93      0.93      0.93        42\n",
      "weighted avg       0.94      0.93      0.93        42\n",
      "\n",
      "\n",
      "Training and evaluating Extra Trees Classifier...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating Quadratic Discriminant Analysis...\n",
      "Accuracy: 0.69\n",
      "Confusion Matrix:\n",
      "[[ 8  1  3]\n",
      " [ 5 10  0]\n",
      " [ 2  2 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.53      0.67      0.59        12\n",
      "        Arun       0.77      0.67      0.71        15\n",
      "    Sunamdha       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.69        42\n",
      "   macro avg       0.70      0.69      0.69        42\n",
      "weighted avg       0.71      0.69      0.70        42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "df_vector = df.copy()\n",
    "\n",
    "# Assuming df is your DataFrame with 'Vector' and 'Label' columns\n",
    "X = df_vector['Vector'].values\n",
    "y = df_vector['Name']\n",
    "\n",
    "# Define a custom padding function\n",
    "def pad_sequences_with_mean(sequences, max_length):\n",
    "    padded_sequences = np.zeros((len(sequences), max_length))\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        seq_len = len(seq)\n",
    "        if seq_len > 0:\n",
    "            mean_value = np.mean(seq)\n",
    "            padded_sequences[i, :seq_len] = seq\n",
    "            padded_sequences[i, seq_len:] = mean_value\n",
    "    \n",
    "    return padded_sequences\n",
    "\n",
    "# Find the maximum length of sequences\n",
    "max_length = max(len(seq) for seq in X)\n",
    "\n",
    "# Pad the sequences with the mean value\n",
    "X_padded = pad_sequences_with_mean(X, max_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=22)\n",
    "\n",
    "# Initialize various classifiers and create a dictionary to store trained models\n",
    "trained_models = {}\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'MLP Classifier': MLPClassifier(),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "    'Bagging Classifier': BaggingClassifier(),\n",
    "    'Extra Trees Classifier': ExtraTreesClassifier(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"\\nTraining and evaluating {name}...\")\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Save the trained model in the dictionary\n",
    "    trained_models[name] = classifier\n",
    "    \n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': LogisticRegression(),\n",
       " 'Decision Tree': DecisionTreeClassifier(),\n",
       " 'Random Forest': RandomForestClassifier(),\n",
       " 'Gradient Boosting': GradientBoostingClassifier(),\n",
       " 'Support Vector Machine': SVC(),\n",
       " 'K-Nearest Neighbors': KNeighborsClassifier(),\n",
       " 'Naive Bayes': GaussianNB(),\n",
       " 'MLP Classifier': MLPClassifier(),\n",
       " 'AdaBoost Classifier': AdaBoostClassifier(),\n",
       " 'Bagging Classifier': BaggingClassifier(),\n",
       " 'Extra Trees Classifier': ExtraTreesClassifier(),\n",
       " 'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis()}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict live audio clip with all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording file audio_files/test/Arun1Pronounciation.wav\n",
      "Pronounciation - 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'write' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     recording \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(\u001b[38;5;28mint\u001b[39m(duration \u001b[38;5;241m*\u001b[39m freq), samplerate\u001b[38;5;241m=\u001b[39mfreq, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m     sd\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mwrite\u001b[49m(file_name, freq, recording)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecorded file \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file_name)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'write' is not defined"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "name = input(\"Enter your name: \")\n",
    "freq = 44100\n",
    "duration = 2\n",
    "word = \"Pronounciation\"\n",
    "for i in range(5):\n",
    "    file_name = \"audio_files/test/\" + name + str(i+1) + word + '.wav'\n",
    "    print(\"Recording file \" + file_name)\n",
    "    print(f'{word} - {i+1}')\n",
    "    recording = sd.rec(int(duration * freq), samplerate=freq, channels=2)\n",
    "    sd.wait()\n",
    "    write(file_name, freq, recording)\n",
    "    print(\"Recorded file \" + file_name)\n",
    "\n",
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame with 'Vector' and 'Label' columns\n",
    "folder_path = '/path/to/your/folder'\n",
    "\n",
    "# Function to extract features and make predictions for a given audio file\n",
    "def predict_for_audio_file(file_path, trained_models, max_length):\n",
    "    # Load the original audio\n",
    "    sr, audio = read(file_path)\n",
    "\n",
    "    # Extract features (MFCC and delta coefficients)\n",
    "    features = extract_features(audio, sr)\n",
    "\n",
    "    # Make predictions using the saved models\n",
    "    predictions = {}\n",
    "    for name, model in trained_models.items():\n",
    "        # Ensure the test_vector has the same shape as the training data\n",
    "        # For example, you may need to pad or reshape it\n",
    "        test_vector_padded = pad_sequences_with_mean([features], max_length)\n",
    "\n",
    "        # Make the prediction\n",
    "        prediction = model.predict(test_vector_padded)\n",
    "        predictions[name] = prediction\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Get a list of all WAV files in the folder\n",
    "wav_files = [file for file in os.listdir(folder_path) if file.endswith('.wav')]\n",
    "\n",
    "# Loop through all WAV files and make predictions\n",
    "for wav_file in wav_files:\n",
    "    wav_file_path = os.path.join(folder_path, wav_file)\n",
    "    \n",
    "    # Make predictions for the current audio file\n",
    "    predictions = predict_for_audio_file(wav_file_path, trained_models, max_length)\n",
    "    \n",
    "    # Print predictions for each model\n",
    "    print(f\"\\nPredictions for {wav_file}:\")\n",
    "    for name, prediction in predictions.items():\n",
    "        print(f\"{name} Prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdjustedPythonVirtEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
