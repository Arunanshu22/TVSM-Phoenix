{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 'prononciation' files\n",
    "# generate the df with mfcc, vector, row mean\n",
    "# train all models from additional_features file\n",
    "# collect 5 test samples\n",
    "# augment to 5*7 = 35\n",
    "# predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pronounciation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['augmented_audio/Abhishek10Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek10Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek1Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek2Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek3Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek4Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek5Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek6Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek7Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek8Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Abhishek9Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun10Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun1Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun2Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun3Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun4Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun5Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun6Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun7Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun8Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Arun9Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha10Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha1Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha2Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha3Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha4Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha5Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha6Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha7Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha8Pronounciation.wavoutput_stretched.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_augmented.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_compressed.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_cropped.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_noisy.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_pitch_shifted.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_speed_changed.wav',\n",
       " 'augmented_audio/Sunamdha9Pronounciation.wavoutput_stretched.wav']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = []\n",
    "for filename in os.listdir(\"augmented_audio/\"):\n",
    "    if \"pronounciation\" in filename.lower():\n",
    "        files.append(\"augmented_audio/\" + filename)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating df of Pronounciation files - MFCC, Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Load the original audio and extract MFCC\u001b[39;00m\n\u001b[0;32m     72\u001b[0m input_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file_name)\n\u001b[1;32m---> 73\u001b[0m mfccs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_mfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Load the original audio\u001b[39;00m\n\u001b[0;32m     76\u001b[0m sr, audio \u001b[38;5;241m=\u001b[39m read(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file_name))\n",
      "Cell \u001b[1;32mIn[45], line 11\u001b[0m, in \u001b[0;36mextract_mfcc\u001b[1;34m(file_path, n_mfcc)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_mfcc\u001b[39m(file_path, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39mn_mfcc)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mfccs\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32md:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32md:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    205\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[0;32m    211\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32md:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\soundfile.py:1193\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the appropriate sf_open*() function from libsndfile.\"\"\"\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, (_unicode, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m-> 1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_os\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile exists: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "File \u001b[1;32m<frozen genericpath>:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=25):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs.flatten()\n",
    "\n",
    "# Function to extract features (MFCC and delta coefficients)\n",
    "def extract_features(audio, rate):\n",
    "    mfcc_feature = mfcc.mfcc(audio, rate, 0.025, 0.01, 20, nfft=1200, appendEnergy=True)\n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature, delta))\n",
    "    return combined.flatten()\n",
    "\n",
    "# Function to calculate delta coefficients\n",
    "def calculate_delta(array):\n",
    "    rows, cols = array.shape\n",
    "    deltas = np.zeros((rows, 20))\n",
    "    n = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= n:\n",
    "            if i - j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i - j\n",
    "            if i + j > rows - 1:\n",
    "                second = rows - 1\n",
    "            else:\n",
    "                second = i + j\n",
    "            index.append((second, first))\n",
    "            j += 1\n",
    "        deltas[i] = (array[index[0][0]] - array[index[0][1]] + (2 * (array[index[1][0]] - array[index[1][1]]))) / 10\n",
    "    return deltas\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = \"augmented_audio/\"\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Create a dictionary to store data for each word\n",
    "word_data = {}\n",
    "\n",
    "# Traverse through each file\n",
    "for file_name in files:\n",
    "    if \"pronounciation\" in file_name.lower():\n",
    "        if file_name.lower().endswith(\".wav\"):\n",
    "            # Parse the file name to extract information\n",
    "            pattern = r'([A-Za-z]+)\\d+([A-Za-z]+)'\n",
    "            # Use re.match to find the pattern in the file name\n",
    "            match = re.match(pattern, file_name)\n",
    "            if match:\n",
    "                # Extract the name and word from the matched groups\n",
    "                name = match.group(1)\n",
    "                word = match.group(2)\n",
    "            \n",
    "            # Check if the word is already in the dictionary\n",
    "            if word not in word_data:\n",
    "                word_data[word] = {'Name': [], 'MFCC': [], 'Vector': []}\n",
    "\n",
    "            # Load the original audio and extract MFCC\n",
    "            input_file_path = os.path.join(folder_path, file_name)\n",
    "            mfccs = extract_mfcc(input_file_path)\n",
    "            \n",
    "            # Load the original audio\n",
    "            sr, audio = read(os.path.join(folder_path, file_name))\n",
    "            \n",
    "            # Extract features (MFCC and delta coefficients)\n",
    "            features = extract_features(audio, sr)\n",
    "            \n",
    "            # Add data to the dictionary\n",
    "            word_data[word]['Name'].append(name)\n",
    "            word_data[word]['MFCC'].append(mfccs)\n",
    "            word_data[word]['Vector'].append(features)  # Add the vector values\n",
    "\n",
    "# Create DataFrames for each word\n",
    "word_dfs = {}\n",
    "for word, data in word_data.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    word_dfs[word] = df\n",
    "\n",
    "# Display DataFrames for each word\n",
    "for word, df in word_dfs.items():\n",
    "    print(f\"\\nWord: {word}\")\n",
    "    print(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training all models on Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "Training and evaluating Logistic Regression...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating Decision Tree...\n",
      "Accuracy: 0.88\n",
      "Confusion Matrix:\n",
      "[[10  1  1]\n",
      " [ 2 13  0]\n",
      " [ 1  0 14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.77      0.83      0.80        12\n",
      "        Arun       0.93      0.87      0.90        15\n",
      "    Sunamdha       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.88      0.88      0.88        42\n",
      "weighted avg       0.88      0.88      0.88        42\n",
      "\n",
      "\n",
      "Training and evaluating Random Forest...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating Gradient Boosting...\n",
      "Accuracy: 0.95\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 2  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.86      1.00      0.92        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.95      0.96      0.95        42\n",
      "weighted avg       0.96      0.95      0.95        42\n",
      "\n",
      "\n",
      "Training and evaluating Support Vector Machine...\n",
      "Accuracy: 0.64\n",
      "Confusion Matrix:\n",
      "[[ 8  1  3]\n",
      " [ 0  8  7]\n",
      " [ 1  3 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.89      0.67      0.76        12\n",
      "        Arun       0.67      0.53      0.59        15\n",
      "    Sunamdha       0.52      0.73      0.61        15\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.69      0.64      0.66        42\n",
      "weighted avg       0.68      0.64      0.65        42\n",
      "\n",
      "\n",
      "Training and evaluating K-Nearest Neighbors...\n",
      "Accuracy: 0.93\n",
      "Confusion Matrix:\n",
      "[[11  0  1]\n",
      " [ 0 15  0]\n",
      " [ 2  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.85      0.92      0.88        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.92      0.93      0.93        42\n",
      "weighted avg       0.93      0.93      0.93        42\n",
      "\n",
      "\n",
      "Training and evaluating Naive Bayes...\n",
      "Accuracy: 0.81\n",
      "Confusion Matrix:\n",
      "[[10  0  2]\n",
      " [ 0 11  4]\n",
      " [ 2  0 13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.83      0.83      0.83        12\n",
      "        Arun       1.00      0.73      0.85        15\n",
      "    Sunamdha       0.68      0.87      0.76        15\n",
      "\n",
      "    accuracy                           0.81        42\n",
      "   macro avg       0.84      0.81      0.81        42\n",
      "weighted avg       0.84      0.81      0.81        42\n",
      "\n",
      "\n",
      "Training and evaluating MLP Classifier...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating AdaBoost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 3 11  1]\n",
      " [13  0  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.43      1.00      0.60        12\n",
      "        Arun       1.00      0.73      0.85        15\n",
      "    Sunamdha       0.67      0.13      0.22        15\n",
      "\n",
      "    accuracy                           0.60        42\n",
      "   macro avg       0.70      0.62      0.56        42\n",
      "weighted avg       0.72      0.60      0.55        42\n",
      "\n",
      "\n",
      "Training and evaluating Bagging Classifier...\n",
      "Accuracy: 0.95\n",
      "Confusion Matrix:\n",
      "[[11  1  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.92      0.92      0.92        12\n",
      "        Arun       0.93      0.93      0.93        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.95      0.95      0.95        42\n",
      "weighted avg       0.95      0.95      0.95        42\n",
      "\n",
      "\n",
      "Training and evaluating Extra Trees Classifier...\n",
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       1.00      1.00      1.00        12\n",
      "        Arun       1.00      1.00      1.00        15\n",
      "    Sunamdha       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "\n",
      "Training and evaluating Quadratic Discriminant Analysis...\n",
      "Accuracy: 0.64\n",
      "Confusion Matrix:\n",
      "[[10  0  2]\n",
      " [ 2  7  6]\n",
      " [ 4  1 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abhishek       0.62      0.83      0.71        12\n",
      "        Arun       0.88      0.47      0.61        15\n",
      "    Sunamdha       0.56      0.67      0.61        15\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.69      0.66      0.64        42\n",
      "weighted avg       0.69      0.64      0.64        42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AdjustedPythonVirtEnv\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "df_vector = df.copy()\n",
    "\n",
    "# Assuming df is your DataFrame with 'Vector' and 'Label' columns\n",
    "X = df_vector['MFCC'].values\n",
    "y = df_vector['Name']\n",
    "\n",
    "# Define a custom padding function\n",
    "def pad_sequences_with_mean(sequences, max_length):\n",
    "    padded_sequences = np.zeros((len(sequences), max_length))\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        seq_len = len(seq)\n",
    "        if seq_len > 0:\n",
    "            mean_value = np.mean(seq)\n",
    "            padded_sequences[i, :seq_len] = seq\n",
    "            padded_sequences[i, seq_len:] = mean_value\n",
    "    \n",
    "    return padded_sequences\n",
    "\n",
    "# Find the maximum length of sequences\n",
    "max_length = max(len(seq) for seq in X)\n",
    "\n",
    "# Pad the sequences with the mean value\n",
    "X_padded = pad_sequences_with_mean(X, max_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=22)\n",
    "\n",
    "# Initialize various classifiers and create a dictionary to store trained models\n",
    "trained_models = {}\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'MLP Classifier': MLPClassifier(),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "    'Bagging Classifier': BaggingClassifier(),\n",
    "    'Extra Trees Classifier': ExtraTreesClassifier(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"\\nTraining and evaluating {name}...\")\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Save the trained model in the dictionary\n",
    "    trained_models[name] = classifier\n",
    "    \n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4325"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': LogisticRegression(),\n",
       " 'Decision Tree': DecisionTreeClassifier(),\n",
       " 'Random Forest': RandomForestClassifier(),\n",
       " 'Gradient Boosting': GradientBoostingClassifier(),\n",
       " 'Support Vector Machine': SVC(),\n",
       " 'K-Nearest Neighbors': KNeighborsClassifier(),\n",
       " 'Naive Bayes': GaussianNB(),\n",
       " 'MLP Classifier': MLPClassifier(),\n",
       " 'AdaBoost Classifier': AdaBoostClassifier(),\n",
       " 'Bagging Classifier': BaggingClassifier(),\n",
       " 'Extra Trees Classifier': ExtraTreesClassifier(),\n",
       " 'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis()}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect test sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "\n",
    "name = \"Sunamdha\"\n",
    "freq = 44100\n",
    "duration = 2\n",
    "\n",
    "words = ['Pronounciation'] \n",
    "\n",
    "for i in range(10):\n",
    "    file_name = \"audio_files/test/pronounciationTest/\" + name + str(i+1) + word + '.wav'\n",
    "    print(\"Recording file \" + file_name)\n",
    "    print(f'{word} - {i+1}')\n",
    "    recording = sd.rec(int(duration * freq), samplerate=freq, channels=1)\n",
    "    sd.wait()\n",
    "    write(file_name, freq, recording)\n",
    "    print(\"Recorded file \" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict live audio clip with all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=25):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs.flatten()\n",
    "\n",
    "# Function to extract features (MFCC and delta coefficients)\n",
    "def extract_features(audio, rate):\n",
    "    mfcc_feature = mfcc.mfcc(audio, rate, 0.025, 0.01, 20, nfft=1200, appendEnergy=True)\n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature, delta))\n",
    "    return combined.flatten()\n",
    "\n",
    "# Function to calculate delta coefficients\n",
    "def calculate_delta(array):\n",
    "    rows, cols = array.shape\n",
    "    deltas = np.zeros((rows, 20))\n",
    "    n = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= n:\n",
    "            if i - j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i - j\n",
    "            if i + j > rows - 1:\n",
    "                second = rows - 1\n",
    "            else:\n",
    "                second = i + j\n",
    "            index.append((second, first))\n",
    "            j += 1\n",
    "        deltas[i] = (array[index[0][0]] - array[index[0][1]] + (2 * (array[index[1][0]] - array[index[1][1]]))) / 10\n",
    "    return deltas\n",
    "\n",
    "def create_df_test_vec(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    # vector_data = {'Vector': []}\n",
    "    mfcc_data = {'MFCC': []}\n",
    "\n",
    "    for file_name in files:\n",
    "        if file_name.lower().endswith(\".wav\"):\n",
    "            # MFCC Dataset\n",
    "            input_file_path = os.path.join(folder_path, file_name)\n",
    "            mfccs = extract_mfcc(input_file_path)\n",
    "            mfcc_data['MFCC'].append(mfccs)\n",
    "\n",
    "            # Vector Dataset\n",
    "            # Load the original audio\n",
    "            # sr, audio = read(os.path.join(folder_path, file_name))\n",
    "            # # Extract features (MFCC and delta coefficients)\n",
    "            # features = extract_features(audio, sr)\n",
    "            # # Add vector to the dictionary\n",
    "            # vector_data['Vector'].append(features)  # Add the vector values\n",
    "\n",
    "    # Create DataFrame\n",
    "    df_test_mfcc = pd.DataFrame(mfcc_data)\n",
    "\n",
    "    return df_test_mfcc\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = \"audio_files/test/pronounciationTest/\"\n",
    "\n",
    "# Create DataFrame\n",
    "df_test_mfcc = create_df_test_vec(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4325,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_mfcc['MFCC'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4325"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec = df_test_mfcc['MFCC'].values\n",
    "\n",
    "max_length_test = max(len(seq) for seq in X_test_vec)\n",
    "max_length_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>MLP Classifier</th>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <th>Extra Trees Classifier</th>\n",
       "      <th>Quadratic Discriminant Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Sunamdha</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>Abhishek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Logistic Regression Decision Tree Random Forest Gradient Boosting  \\\n",
       "0            Abhishek          Arun          Arun              Arun   \n",
       "1            Abhishek          Arun          Arun              Arun   \n",
       "2            Abhishek      Sunamdha      Sunamdha          Abhishek   \n",
       "3            Abhishek          Arun          Arun              Arun   \n",
       "4            Abhishek          Arun          Arun              Arun   \n",
       "5            Abhishek          Arun          Arun              Arun   \n",
       "6            Abhishek          Arun          Arun              Arun   \n",
       "7            Abhishek          Arun          Arun              Arun   \n",
       "8            Abhishek          Arun      Sunamdha          Abhishek   \n",
       "9                Arun          Arun      Sunamdha              Arun   \n",
       "\n",
       "  Support Vector Machine K-Nearest Neighbors Naive Bayes MLP Classifier  \\\n",
       "0               Abhishek            Abhishek        Arun       Abhishek   \n",
       "1               Sunamdha            Sunamdha        Arun       Abhishek   \n",
       "2               Sunamdha            Sunamdha        Arun       Abhishek   \n",
       "3               Sunamdha            Sunamdha        Arun       Abhishek   \n",
       "4               Sunamdha            Sunamdha        Arun       Abhishek   \n",
       "5               Abhishek            Abhishek        Arun       Abhishek   \n",
       "6               Abhishek            Abhishek        Arun       Abhishek   \n",
       "7               Abhishek            Abhishek        Arun       Abhishek   \n",
       "8               Sunamdha            Sunamdha        Arun       Abhishek   \n",
       "9               Sunamdha            Sunamdha        Arun       Abhishek   \n",
       "\n",
       "  AdaBoost Classifier Bagging Classifier Extra Trees Classifier  \\\n",
       "0                Arun               Arun                   Arun   \n",
       "1                Arun               Arun                   Arun   \n",
       "2                Arun           Sunamdha                   Arun   \n",
       "3                Arun               Arun               Abhishek   \n",
       "4                Arun               Arun               Abhishek   \n",
       "5                Arun               Arun                   Arun   \n",
       "6                Arun               Arun                   Arun   \n",
       "7                Arun               Arun                   Arun   \n",
       "8                Arun               Arun               Abhishek   \n",
       "9                Arun               Arun               Abhishek   \n",
       "\n",
       "  Quadratic Discriminant Analysis  \n",
       "0                        Abhishek  \n",
       "1                        Abhishek  \n",
       "2                        Abhishek  \n",
       "3                        Abhishek  \n",
       "4                        Abhishek  \n",
       "5                        Abhishek  \n",
       "6                        Abhishek  \n",
       "7                        Sunamdha  \n",
       "8                        Abhishek  \n",
       "9                        Abhishek  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming df_test_vec is your DataFrame with the 'Vector' column\n",
    "X_test_vec = df_test_mfcc['MFCC'].values\n",
    "\n",
    "# Find the maximum length of sequences for the test data\n",
    "max_length_test = max(len(seq) for seq in X_test_vec)\n",
    "\n",
    "# Pad or truncate the test sequences to match the training data's max_length\n",
    "X_test_padded = pad_sequences_with_mean(X_test_vec, max_length_test)\n",
    "\n",
    "# Initialize a dictionary to store predictions\n",
    "predictions = {}\n",
    "\n",
    "# Make predictions using the trained models\n",
    "for name, model in trained_models.items():\n",
    "    # Ensure the test_vector has the same shape as the training data\n",
    "    # For example, you may need to pad or reshape it\n",
    "    # test_vector_padded = pad_sequences_with_mean(X_test_vec, max_length_test)\n",
    "    \n",
    "    # Make the prediction\n",
    "    y_pred = model.predict(X_test_padded)\n",
    "    \n",
    "    # Store the predictions in the dictionary\n",
    "    predictions[name] = y_pred\n",
    "\n",
    "# Create a DataFrame from the predictions\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Display the predicted usernames\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording file audio_files/test/pronounciationTest/Sunamdha1Pronounciation.wav\n",
      "Pronounciation - 1\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha1Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha2Pronounciation.wav\n",
      "Pronounciation - 2\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha2Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha3Pronounciation.wav\n",
      "Pronounciation - 3\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha3Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha4Pronounciation.wav\n",
      "Pronounciation - 4\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha4Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha5Pronounciation.wav\n",
      "Pronounciation - 5\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha5Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha6Pronounciation.wav\n",
      "Pronounciation - 6\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha6Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha7Pronounciation.wav\n",
      "Pronounciation - 7\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha7Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha8Pronounciation.wav\n",
      "Pronounciation - 8\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha8Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha9Pronounciation.wav\n",
      "Pronounciation - 9\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha9Pronounciation.wav\n",
      "Recording file audio_files/test/pronounciationTest/Sunamdha10Pronounciation.wav\n",
      "Pronounciation - 10\n",
      "Recorded file audio_files/test/pronounciationTest/Sunamdha10Pronounciation.wav\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdjustedPythonVirtEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
