{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = 'fourUser25min.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>MFCC_1</th>\n",
       "      <th>MFCC_2</th>\n",
       "      <th>MFCC_3</th>\n",
       "      <th>MFCC_4</th>\n",
       "      <th>MFCC_5</th>\n",
       "      <th>MFCC_6</th>\n",
       "      <th>MFCC_7</th>\n",
       "      <th>MFCC_8</th>\n",
       "      <th>MFCC_9</th>\n",
       "      <th>...</th>\n",
       "      <th>LogMelFilterbank_22</th>\n",
       "      <th>LogMelFilterbank_23</th>\n",
       "      <th>LogMelFilterbank_24</th>\n",
       "      <th>LogMelFilterbank_25</th>\n",
       "      <th>LogMelFilterbank_26</th>\n",
       "      <th>LogMelFilterbank_27</th>\n",
       "      <th>LogMelFilterbank_28</th>\n",
       "      <th>LogMelFilterbank_29</th>\n",
       "      <th>LogMelFilterbank_30</th>\n",
       "      <th>RASTA-PLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-398.515503</td>\n",
       "      <td>95.550636</td>\n",
       "      <td>5.952597</td>\n",
       "      <td>-5.154275</td>\n",
       "      <td>5.881031</td>\n",
       "      <td>-3.027374</td>\n",
       "      <td>-7.761910</td>\n",
       "      <td>-10.212845</td>\n",
       "      <td>-14.519335</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.774456</td>\n",
       "      <td>-50.957180</td>\n",
       "      <td>-51.288067</td>\n",
       "      <td>-51.290344</td>\n",
       "      <td>-51.292488</td>\n",
       "      <td>-51.294460</td>\n",
       "      <td>-51.296204</td>\n",
       "      <td>-51.297623</td>\n",
       "      <td>-51.298595</td>\n",
       "      <td>0.642121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-317.800323</td>\n",
       "      <td>171.617676</td>\n",
       "      <td>19.697014</td>\n",
       "      <td>-20.370554</td>\n",
       "      <td>-5.757511</td>\n",
       "      <td>-5.969464</td>\n",
       "      <td>-11.277127</td>\n",
       "      <td>-18.355204</td>\n",
       "      <td>-21.422365</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.427387</td>\n",
       "      <td>-48.540958</td>\n",
       "      <td>-49.163948</td>\n",
       "      <td>-49.203705</td>\n",
       "      <td>-49.248993</td>\n",
       "      <td>-49.248413</td>\n",
       "      <td>-49.263485</td>\n",
       "      <td>-49.271469</td>\n",
       "      <td>-49.274387</td>\n",
       "      <td>0.496999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-324.595490</td>\n",
       "      <td>157.516998</td>\n",
       "      <td>22.634710</td>\n",
       "      <td>-20.010984</td>\n",
       "      <td>-9.555398</td>\n",
       "      <td>-7.517561</td>\n",
       "      <td>-12.459773</td>\n",
       "      <td>-16.917850</td>\n",
       "      <td>-19.326172</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.045940</td>\n",
       "      <td>-48.755985</td>\n",
       "      <td>-48.908695</td>\n",
       "      <td>-49.024067</td>\n",
       "      <td>-49.160210</td>\n",
       "      <td>-49.273827</td>\n",
       "      <td>-49.335701</td>\n",
       "      <td>-49.433483</td>\n",
       "      <td>-49.478497</td>\n",
       "      <td>0.499368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-320.546265</td>\n",
       "      <td>156.666412</td>\n",
       "      <td>17.499743</td>\n",
       "      <td>-14.465985</td>\n",
       "      <td>1.115923</td>\n",
       "      <td>-3.048698</td>\n",
       "      <td>-9.033537</td>\n",
       "      <td>-14.968829</td>\n",
       "      <td>-23.260252</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.934559</td>\n",
       "      <td>-49.155994</td>\n",
       "      <td>-49.536232</td>\n",
       "      <td>-49.582375</td>\n",
       "      <td>-49.664959</td>\n",
       "      <td>-49.695789</td>\n",
       "      <td>-49.687527</td>\n",
       "      <td>-49.702763</td>\n",
       "      <td>-49.704502</td>\n",
       "      <td>0.540353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-359.157013</td>\n",
       "      <td>136.366379</td>\n",
       "      <td>15.336736</td>\n",
       "      <td>-6.177477</td>\n",
       "      <td>-1.002159</td>\n",
       "      <td>-11.322202</td>\n",
       "      <td>-10.241114</td>\n",
       "      <td>-8.933396</td>\n",
       "      <td>-14.962830</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.878162</td>\n",
       "      <td>-49.499832</td>\n",
       "      <td>-50.128464</td>\n",
       "      <td>-50.226109</td>\n",
       "      <td>-50.330399</td>\n",
       "      <td>-50.397057</td>\n",
       "      <td>-50.485462</td>\n",
       "      <td>-50.518032</td>\n",
       "      <td>-50.578228</td>\n",
       "      <td>0.540744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-437.668182</td>\n",
       "      <td>140.687393</td>\n",
       "      <td>20.285200</td>\n",
       "      <td>5.345737</td>\n",
       "      <td>37.238930</td>\n",
       "      <td>7.116364</td>\n",
       "      <td>-15.066447</td>\n",
       "      <td>-0.308156</td>\n",
       "      <td>0.775279</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.153004</td>\n",
       "      <td>-54.442097</td>\n",
       "      <td>-52.966938</td>\n",
       "      <td>-54.177467</td>\n",
       "      <td>-53.483814</td>\n",
       "      <td>-54.444508</td>\n",
       "      <td>-51.976086</td>\n",
       "      <td>-51.075298</td>\n",
       "      <td>-52.778458</td>\n",
       "      <td>0.936796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-449.798920</td>\n",
       "      <td>83.161926</td>\n",
       "      <td>14.831575</td>\n",
       "      <td>15.308598</td>\n",
       "      <td>32.816296</td>\n",
       "      <td>13.900643</td>\n",
       "      <td>-1.714774</td>\n",
       "      <td>-0.983646</td>\n",
       "      <td>-4.377119</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.619720</td>\n",
       "      <td>-49.312302</td>\n",
       "      <td>-47.790913</td>\n",
       "      <td>-49.173557</td>\n",
       "      <td>-49.138584</td>\n",
       "      <td>-51.341240</td>\n",
       "      <td>-48.446667</td>\n",
       "      <td>-47.292278</td>\n",
       "      <td>-48.953869</td>\n",
       "      <td>0.905650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-478.835052</td>\n",
       "      <td>82.240067</td>\n",
       "      <td>17.422600</td>\n",
       "      <td>25.251034</td>\n",
       "      <td>41.910275</td>\n",
       "      <td>18.777891</td>\n",
       "      <td>-2.398127</td>\n",
       "      <td>-1.575871</td>\n",
       "      <td>0.771020</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.021606</td>\n",
       "      <td>-52.317413</td>\n",
       "      <td>-50.059422</td>\n",
       "      <td>-52.731140</td>\n",
       "      <td>-52.850262</td>\n",
       "      <td>-54.234467</td>\n",
       "      <td>-52.153831</td>\n",
       "      <td>-51.468510</td>\n",
       "      <td>-51.733887</td>\n",
       "      <td>0.954063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-468.360596</td>\n",
       "      <td>72.639534</td>\n",
       "      <td>19.577122</td>\n",
       "      <td>21.420576</td>\n",
       "      <td>37.741058</td>\n",
       "      <td>15.400746</td>\n",
       "      <td>-2.917547</td>\n",
       "      <td>3.897957</td>\n",
       "      <td>3.778859</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.817699</td>\n",
       "      <td>-51.025829</td>\n",
       "      <td>-48.338863</td>\n",
       "      <td>-49.721741</td>\n",
       "      <td>-49.137714</td>\n",
       "      <td>-51.282089</td>\n",
       "      <td>-48.444160</td>\n",
       "      <td>-48.352722</td>\n",
       "      <td>-49.665852</td>\n",
       "      <td>0.942050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-488.891846</td>\n",
       "      <td>113.399849</td>\n",
       "      <td>28.112869</td>\n",
       "      <td>23.015976</td>\n",
       "      <td>46.513409</td>\n",
       "      <td>17.945587</td>\n",
       "      <td>-6.016304</td>\n",
       "      <td>-2.544933</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.068630</td>\n",
       "      <td>-56.126949</td>\n",
       "      <td>-53.122452</td>\n",
       "      <td>-54.311874</td>\n",
       "      <td>-54.267719</td>\n",
       "      <td>-55.702690</td>\n",
       "      <td>-52.628300</td>\n",
       "      <td>-52.511940</td>\n",
       "      <td>-53.038296</td>\n",
       "      <td>0.973527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names      MFCC_1      MFCC_2     MFCC_3     MFCC_4     MFCC_5  \\\n",
       "0     Arunanshu -398.515503   95.550636   5.952597  -5.154275   5.881031   \n",
       "1     Arunanshu -317.800323  171.617676  19.697014 -20.370554  -5.757511   \n",
       "2     Arunanshu -324.595490  157.516998  22.634710 -20.010984  -9.555398   \n",
       "3     Arunanshu -320.546265  156.666412  17.499743 -14.465985   1.115923   \n",
       "4     Arunanshu -359.157013  136.366379  15.336736  -6.177477  -1.002159   \n",
       "...         ...         ...         ...        ...        ...        ...   \n",
       "1190    Pratham -437.668182  140.687393  20.285200   5.345737  37.238930   \n",
       "1191    Pratham -449.798920   83.161926  14.831575  15.308598  32.816296   \n",
       "1192    Pratham -478.835052   82.240067  17.422600  25.251034  41.910275   \n",
       "1193    Pratham -468.360596   72.639534  19.577122  21.420576  37.741058   \n",
       "1194    Pratham -488.891846  113.399849  28.112869  23.015976  46.513409   \n",
       "\n",
       "         MFCC_6     MFCC_7     MFCC_8     MFCC_9  ...  LogMelFilterbank_22  \\\n",
       "0     -3.027374  -7.761910 -10.212845 -14.519335  ...           -49.774456   \n",
       "1     -5.969464 -11.277127 -18.355204 -21.422365  ...           -47.427387   \n",
       "2     -7.517561 -12.459773 -16.917850 -19.326172  ...           -48.045940   \n",
       "3     -3.048698  -9.033537 -14.968829 -23.260252  ...           -47.934559   \n",
       "4    -11.322202 -10.241114  -8.933396 -14.962830  ...           -47.878162   \n",
       "...         ...        ...        ...        ...  ...                  ...   \n",
       "1190   7.116364 -15.066447  -0.308156   0.775279  ...           -58.153004   \n",
       "1191  13.900643  -1.714774  -0.983646  -4.377119  ...           -51.619720   \n",
       "1192  18.777891  -2.398127  -1.575871   0.771020  ...           -54.021606   \n",
       "1193  15.400746  -2.917547   3.897957   3.778859  ...           -51.817699   \n",
       "1194  17.945587  -6.016304  -2.544933   0.547084  ...           -56.068630   \n",
       "\n",
       "      LogMelFilterbank_23  LogMelFilterbank_24  LogMelFilterbank_25  \\\n",
       "0              -50.957180           -51.288067           -51.290344   \n",
       "1              -48.540958           -49.163948           -49.203705   \n",
       "2              -48.755985           -48.908695           -49.024067   \n",
       "3              -49.155994           -49.536232           -49.582375   \n",
       "4              -49.499832           -50.128464           -50.226109   \n",
       "...                   ...                  ...                  ...   \n",
       "1190           -54.442097           -52.966938           -54.177467   \n",
       "1191           -49.312302           -47.790913           -49.173557   \n",
       "1192           -52.317413           -50.059422           -52.731140   \n",
       "1193           -51.025829           -48.338863           -49.721741   \n",
       "1194           -56.126949           -53.122452           -54.311874   \n",
       "\n",
       "      LogMelFilterbank_26  LogMelFilterbank_27  LogMelFilterbank_28  \\\n",
       "0              -51.292488           -51.294460           -51.296204   \n",
       "1              -49.248993           -49.248413           -49.263485   \n",
       "2              -49.160210           -49.273827           -49.335701   \n",
       "3              -49.664959           -49.695789           -49.687527   \n",
       "4              -50.330399           -50.397057           -50.485462   \n",
       "...                   ...                  ...                  ...   \n",
       "1190           -53.483814           -54.444508           -51.976086   \n",
       "1191           -49.138584           -51.341240           -48.446667   \n",
       "1192           -52.850262           -54.234467           -52.153831   \n",
       "1193           -49.137714           -51.282089           -48.444160   \n",
       "1194           -54.267719           -55.702690           -52.628300   \n",
       "\n",
       "      LogMelFilterbank_29  LogMelFilterbank_30  RASTA-PLP  \n",
       "0              -51.297623           -51.298595   0.642121  \n",
       "1              -49.271469           -49.274387   0.496999  \n",
       "2              -49.433483           -49.478497   0.499368  \n",
       "3              -49.702763           -49.704502   0.540353  \n",
       "4              -50.518032           -50.578228   0.540744  \n",
       "...                   ...                  ...        ...  \n",
       "1190           -51.075298           -52.778458   0.936796  \n",
       "1191           -47.292278           -48.953869   0.905650  \n",
       "1192           -51.468510           -51.733887   0.954063  \n",
       "1193           -48.352722           -49.665852   0.942050  \n",
       "1194           -52.511940           -53.038296   0.973527  \n",
       "\n",
       "[1195 rows x 50 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "\n",
    "# label_encoder object knows \n",
    "# how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Encode labels in column 'species'. \n",
    "df['Names']= label_encoder.fit_transform(df['Names']) \n",
    "\n",
    "df['Names'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are your feature and target variable DataFrames\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA for dimensionality reduction to 2D\n",
    "n_components = 30\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "\n",
    "# Transform the test data using the same PCA model\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "\n",
    "# Plot the 2D representation for training data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label in range(24):  # Assuming four classes\n",
    "#     plt.scatter(X_train_pca[y_train == label, 0], X_train_pca[y_train == label, 1], label=f'Class {label}')\n",
    "\n",
    "# plt.title('PCA - Training Data')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the 2D representation for test data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label in range(24):  # Assuming four classes\n",
    "#     plt.scatter(X_test_pca[y_test == label, 0], X_test_pca[y_test == label, 1], label=f'Class {label}')\n",
    "\n",
    "# plt.title('PCA - Test Data')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is final and useful Best for GMM supervector linear kernel GMM-UBM-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: X_a=(956, 30), X_b=(956, 30)\n",
      "Shapes: X_a=(956, 30), X_b=(956, 30)\n",
      "Shapes: X_a=(956, 30), X_b=(956, 30)\n",
      "Shapes: X_a=(956, 30), X_b=(956, 30)\n",
      "Shapes: X_a=(239, 30), X_b=(956, 30)\n",
      "Shapes: X_a=(239, 30), X_b=(956, 30)\n",
      "Shapes: X_a=(239, 30), X_b=(956, 30)\n",
      "Shapes: X_a=(239, 30), X_b=(956, 30)\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Assuming you have X_train_pca, X_test_pca, y_train, y_test available\n",
    "\n",
    "# Function to train the UBM\n",
    "def train_ubm(X_train_pca, n_components=4):\n",
    "    ubm = GaussianMixture(n_components=n_components, init_params='k-means++', random_state=42)\n",
    "    ubm.fit(X_train_pca)\n",
    "    return ubm\n",
    "\n",
    "# Function to adapt speaker model using GMM-UBM\n",
    "def adapt_speaker_model(speaker_data, ubm):\n",
    "    # Bayesian adaptation\n",
    "    weights = ubm.weights_\n",
    "    means = ubm.means_\n",
    "    covariances = ubm.covariances_\n",
    "\n",
    "    # Reshape the means array to ensure it is treated as a 1D array\n",
    "    supervector = means.flatten()\n",
    "\n",
    "    # Adapt the speaker model\n",
    "    adapted_model = GaussianMixture(n_components=1, init_params='k-means++', random_state=42)\n",
    "    adapted_model.weights_ = weights\n",
    "    adapted_model.means_ = np.array([supervector])  # Use the reshaped supervector\n",
    "    adapted_model.covariances_ = covariances\n",
    "\n",
    "    # Train the adapted model with speaker data\n",
    "    adapted_model.fit(speaker_data)\n",
    "\n",
    "    return adapted_model\n",
    "\n",
    "# Function to compute the supervector linear kernel\n",
    "def supervector_linear_kernel(models, X_a, X_b):\n",
    "    kernel_matrix = np.zeros((X_a.shape[0], X_b.shape[0]))\n",
    "    for model in models:\n",
    "        weights = model.weights_\n",
    "        means = model.means_\n",
    "        covariances = model.covariances_\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            covariances_inv = np.linalg.inv(covariances[i])\n",
    "\n",
    "            # Check if the number of features matches\n",
    "            if X_a.shape[1] == X_b.shape[1]:\n",
    "                print(f\"Shapes: X_a={X_a.shape}, X_b={X_b.shape}\")\n",
    "                kernel_matrix += weights[i] * np.outer(X_a @ covariances_inv @ means[i].T, X_b @ covariances_inv @ means[i].T)\n",
    "            else:\n",
    "                raise ValueError(\"Number of features in X_a and X_b must be the same.\")\n",
    "\n",
    "    return kernel_matrix\n",
    "\n",
    "# Train the UBM\n",
    "ubm = train_ubm(X_train_pca)\n",
    "\n",
    "# Adapt individual speaker models\n",
    "speaker_models = []\n",
    "for speaker_label in y_train.unique():\n",
    "    speaker_data = X_train_pca[y_train == speaker_label]\n",
    "    adapted_model = adapt_speaker_model(speaker_data, ubm)\n",
    "    speaker_models.append(adapted_model)\n",
    "\n",
    "# Create a 'model/' directory if it doesn't exist\n",
    "model_folder = 'model/'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save the UBM and speaker models\n",
    "ubm_file = os.path.join(model_folder, 'ubm_model.joblib')\n",
    "joblib.dump(ubm, ubm_file)\n",
    "\n",
    "for i, speaker_model in enumerate(speaker_models):\n",
    "    speaker_model_file = os.path.join(model_folder, f'speaker_model_{i}.joblib')\n",
    "    joblib.dump(speaker_model, speaker_model_file)\n",
    "\n",
    "# Compute the kernel matrix for training and testing data\n",
    "train_kernel_matrix = supervector_linear_kernel(speaker_models, X_train_pca, X_train_pca)\n",
    "test_kernel_matrix = supervector_linear_kernel(speaker_models, X_test_pca, X_train_pca)\n",
    "\n",
    "# Train your classifier (e.g., SVM) using the kernel matrix\n",
    "svm_classifier = SVC(kernel='precomputed')\n",
    "svm_classifier.fit(train_kernel_matrix, y_train)\n",
    "\n",
    "# Save the SVM classifier\n",
    "svm_classifier_file = os.path.join(model_folder, 'svm_classifier_model.joblib')\n",
    "joblib.dump(svm_classifier, svm_classifier_file)\n",
    "\n",
    "# Predict speaker labels for test data\n",
    "predicted_labels = svm_classifier.predict(test_kernel_matrix)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply Bark scale\n",
    "def apply_bark_scale(power_spectrum):\n",
    "    # Perform Bark scale transformation on the power spectrum\n",
    "    # You need to implement the specific Bark scale transformation\n",
    "    # For simplicity, let's use a linear transformation as a placeholder\n",
    "    bark_scale_spectrum = np.sqrt(power_spectrum)\n",
    "    return bark_scale_spectrum\n",
    "\n",
    "# Function for critical-band analysis\n",
    "\n",
    "\n",
    "def apply_critical_band_analysis(bark_scale_spectrum):\n",
    "    \"\"\"\n",
    "    Apply critical-band analysis to the Bark scale spectrum.\n",
    "\n",
    "    Parameters:\n",
    "    - bark_scale_spectrum: numpy array, the input Bark scale spectrum.\n",
    "\n",
    "    Returns:\n",
    "    - critical_band_result: numpy array, the result after critical-band analysis.\n",
    "    \"\"\"\n",
    "    omega_values = np.arange(-1.3, 2.6, 0.1)\n",
    "    critical_band_result = np.zeros_like(bark_scale_spectrum)\n",
    "\n",
    "    # Apply the critical-band curve to the Bark scale spectrum\n",
    "    for i in range(len(omega_values) - 1):\n",
    "        mask = (omega_values[i] <= bark_scale_spectrum) & (bark_scale_spectrum <= omega_values[i+1])\n",
    "        if omega_values[i] < -0.5:\n",
    "            critical_band_result[mask] = 10**(2.5 * (bark_scale_spectrum[mask] + 0.5))\n",
    "        elif -0.5 < omega_values[i] < 0.5:\n",
    "            critical_band_result[mask] = 1\n",
    "        elif 0.5 <= omega_values[i] <= 2.5:\n",
    "            critical_band_result[mask] = 10**(-1.0 * (bark_scale_spectrum[mask] - 0.5))\n",
    "\n",
    "    return critical_band_result\n",
    "\n",
    "\n",
    "# Function for equal-loudness preemphasis\n",
    "def equal_loudness_preemphasis(bark_scale_spectrum):\n",
    "    # Implement equal-loudness preemphasis\n",
    "    # You might need to adjust the parameters according to your needs\n",
    "    # For simplicity, let's use a linear transformation as a placeholder\n",
    "    return bark_scale_spectrum\n",
    "\n",
    "# Function for power-law intensity transformation\n",
    "def power_law_intensity_transformation(bark_scale_spectrum):\n",
    "    # Apply power-law transformation (y = x^(1/3))\n",
    "    return bark_scale_spectrum**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasta_plp_feature_extraction(signal, sr):\n",
    "    # Perform RASTA-PLP feature extraction\n",
    "    # Add the RASTA-PLP steps here\n",
    "    \n",
    "    # Set frame size to 20 ms\n",
    "    frame_size_ms = 20\n",
    "    frame_size_samples = int((frame_size_ms / 1000) * sr)\n",
    "\n",
    "    # Set hop length to half of the frame size (50% overlap)\n",
    "    hop_length = frame_size_samples // 2\n",
    "\n",
    "    # Manually perform framing and windowing\n",
    "    num_frames = 1 + (len(signal) - frame_size_samples) // hop_length\n",
    "    frames = np.stack([signal[i * hop_length:i * hop_length + frame_size_samples] * np.hamming(frame_size_samples) for i in range(num_frames)])\n",
    "\n",
    "    # Continue with the remaining RASTA-PLP steps\n",
    "    power_spectrum = np.abs(np.fft.fft(frames, axis=0))**2\n",
    "    bark_scale_spectrum = apply_bark_scale(power_spectrum)\n",
    "    critical_band_result = apply_critical_band_analysis(bark_scale_spectrum)\n",
    "    preemphasis_result = equal_loudness_preemphasis(critical_band_result)\n",
    "    intensity_transformed = power_law_intensity_transformation(preemphasis_result)\n",
    "    \n",
    "    # For simplicity, let's use the mean as a summary statistic for each feature\n",
    "    rasta_plp_features = np.mean(intensity_transformed, axis=1)\n",
    "    \n",
    "    return rasta_plp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # collect audio files for test\n",
    "# import sounddevice as sd\n",
    "# from scipy.io.wavfile import write\n",
    "# import wavio as wv\n",
    "\n",
    "# name = \"Unknown\"\n",
    "# freq = 44100\n",
    "# duration = 5\n",
    "\n",
    "# # words = ['Environment', 'Archives', 'Pronounciation', 'Hour', 'Wednesday', 'Violence', 'Tomb', \n",
    "# #          'Suite', 'Iron', 'Reciept', 'Chores'] \n",
    "\n",
    "# for i in range(5):\n",
    "#     file_name = \"testVoice/\" + name + str(i+1)+ '.wav'\n",
    "#     print(\"Recording file \" + file_name)\n",
    "#     # print(f'{word} - {i+1}')\n",
    "#     recording = sd.rec(int(duration * freq), samplerate=freq, channels=2)\n",
    "#     sd.wait()\n",
    "#     write(file_name, freq, recording)\n",
    "#     print(\"Recorded file \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_23384\\4217078096.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_23384\\4217078096.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, df_temp], ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_23384\\4217078096.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_23384\\4217078096.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_23384\\4217078096.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Names      MFCC_1      MFCC_2     MFCC_3     MFCC_4     MFCC_5  \\\n",
      "0  Unknown1.wav         NaN         NaN        NaN        NaN        NaN   \n",
      "1  Unknown1.wav -681.880920   94.195984  28.298031  12.374207  11.150973   \n",
      "2  Unknown2.wav         NaN         NaN        NaN        NaN        NaN   \n",
      "3  Unknown2.wav -553.257629  114.635406  34.989910  19.774725  23.673628   \n",
      "4  Unknown3.wav         NaN         NaN        NaN        NaN        NaN   \n",
      "5  Unknown3.wav -762.091431  117.671295  26.574636   8.749350   9.322863   \n",
      "6  Unknown4.wav         NaN         NaN        NaN        NaN        NaN   \n",
      "7  Unknown4.wav -822.723694   96.840652  27.521198   7.137115   6.640210   \n",
      "8  Unknown5.wav         NaN         NaN        NaN        NaN        NaN   \n",
      "9  Unknown5.wav -565.859985  139.045059  25.531235  15.373220  21.071526   \n",
      "\n",
      "     MFCC_6    MFCC_7    MFCC_8    MFCC_9  ...  LogMelFilterbank_22  \\\n",
      "0       NaN       NaN       NaN       NaN  ...                  NaN   \n",
      "1 -0.471950 -6.896591 -4.838930 -1.013391  ...           -71.131508   \n",
      "2       NaN       NaN       NaN       NaN  ...                  NaN   \n",
      "3  5.934775 -9.243794 -6.791627 -0.749043  ...           -62.537277   \n",
      "4       NaN       NaN       NaN       NaN  ...                  NaN   \n",
      "5  3.997693 -1.836680 -8.481596 -2.369446  ...           -77.393005   \n",
      "6       NaN       NaN       NaN       NaN  ...                  NaN   \n",
      "7  2.330118 -4.402487 -7.756093 -0.527433  ...           -81.027313   \n",
      "8       NaN       NaN       NaN       NaN  ...                  NaN   \n",
      "9  4.035025 -8.164565 -8.290065  2.258997  ...           -61.682487   \n",
      "\n",
      "   LogMelFilterbank_23  LogMelFilterbank_24  LogMelFilterbank_25  \\\n",
      "0                  NaN                  NaN                  NaN   \n",
      "1           -72.142326           -73.414612           -73.414612   \n",
      "2                  NaN                  NaN                  NaN   \n",
      "3           -64.130219           -65.218956           -65.224098   \n",
      "4                  NaN                  NaN                  NaN   \n",
      "5           -79.308945           -83.454552           -83.560471   \n",
      "6                  NaN                  NaN                  NaN   \n",
      "7           -82.052002           -83.905128           -83.781990   \n",
      "8                  NaN                  NaN                  NaN   \n",
      "9           -63.923485           -68.603783           -68.603783   \n",
      "\n",
      "   LogMelFilterbank_26  LogMelFilterbank_27  LogMelFilterbank_28  \\\n",
      "0                  NaN                  NaN                  NaN   \n",
      "1           -73.414612           -73.414612           -73.412422   \n",
      "2                  NaN                  NaN                  NaN   \n",
      "3           -65.228432           -65.230560           -65.230026   \n",
      "4                  NaN                  NaN                  NaN   \n",
      "5           -83.612694           -83.603714           -83.515877   \n",
      "6                  NaN                  NaN                  NaN   \n",
      "7           -83.937004           -84.016205           -83.845184   \n",
      "8                  NaN                  NaN                  NaN   \n",
      "9           -68.603783           -68.603783           -68.597023   \n",
      "\n",
      "   LogMelFilterbank_29  LogMelFilterbank_30  RASTA-PLP  \n",
      "0                  NaN                  NaN        NaN  \n",
      "1           -73.414612           -73.414612   1.000000  \n",
      "2                  NaN                  NaN        NaN  \n",
      "3           -65.231209           -65.234703   0.992836  \n",
      "4                  NaN                  NaN        NaN  \n",
      "5           -83.473137           -83.629227   1.000000  \n",
      "6                  NaN                  NaN        NaN  \n",
      "7           -83.801590           -83.924393   1.000000  \n",
      "8                  NaN                  NaN        NaN  \n",
      "9           -68.601692           -68.603783   0.985622  \n",
      "\n",
      "[10 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_23384\\4217078096.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Directory containing the .wav files\n",
    "directory = \"testVoice/\"\n",
    "\n",
    "# Create an empty DataFrame\n",
    "columns = [\"Names\"] + [f\"MFCC_{i+1}\" for i in range(13)] + [\"Chroma\", \"SpectralContrast\", \"Tonnetz\", \"ZeroCrossingRate\", \"RMSEnergy\"] + [f\"LogMelFilterbank_{i+1}\" for i in range(30)] + [\"RASTA-PLP\"]\n",
    "df_combined = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Iterate through each .wav file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Load the audio file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        audio, sr = librosa.load(file_path, sr=44100)\n",
    "        sr = int(sr)\n",
    "        \n",
    "        # Calculate the total number of clips\n",
    "        clip_duration = 5\n",
    "        clip_samples = int(sr * clip_duration)\n",
    "        total_clips = len(audio) // clip_samples\n",
    "\n",
    "        # Create a temporary DataFrame for the current file\n",
    "        df_temp = pd.DataFrame(columns=columns)\n",
    "        df_temp[\"Names\"] = [filename.split(\"_\")[0]] * total_clips\n",
    "\n",
    "        # Split the audio into clips and extract features for each clip\n",
    "        for i in range(total_clips):\n",
    "            clip_start = i * clip_samples\n",
    "            clip_end = (i + 1) * clip_samples\n",
    "            clip = audio[clip_start:clip_end]\n",
    "\n",
    "            # Extract features similar to the Arunanshu code\n",
    "            mfccs = librosa.feature.mfcc(y=clip, sr=sr, n_mfcc=13, hop_length=512, n_fft=2048)\n",
    "            mfccs_flattened = mfccs.mean(axis=1)\n",
    "\n",
    "            chroma = librosa.feature.chroma_stft(y=clip, sr=sr)\n",
    "            contrast = librosa.feature.spectral_contrast(y=clip, sr=sr)\n",
    "            tonnetz = librosa.feature.tonnetz(y=clip, sr=sr)\n",
    "            zero_crossings = librosa.feature.zero_crossing_rate(y=clip)\n",
    "            rms_energy = librosa.feature.rms(y=clip)\n",
    "            mel_filterbank_energies = librosa.feature.melspectrogram(y=clip, sr=sr, n_mels=30)\n",
    "            log_mel_filterbank_energies = librosa.power_to_db(mel_filterbank_energies)\n",
    "            log_mel_filterbank_energies_flattened = log_mel_filterbank_energies.mean(axis=1).tolist()\n",
    "            rasta_plp_features = rasta_plp_feature_extraction(clip, sr)\n",
    "\n",
    "            # Concatenate features into a single row\n",
    "            row_values = [filename.split(\"_\")[0]] + mfccs_flattened.tolist() + [chroma.mean(), contrast.mean(), tonnetz.mean(), zero_crossings.mean(), rms_energy.mean()] + log_mel_filterbank_energies_flattened + [np.mean(rasta_plp_features.tolist())]\n",
    "\n",
    "            # Append the row to the temporary DataFrame\n",
    "            df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
    "\n",
    "        # Append the temporary DataFrame to the main DataFrame\n",
    "        df_combined = pd.concat([df_combined, df_temp], ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>MFCC_1</th>\n",
       "      <th>MFCC_2</th>\n",
       "      <th>MFCC_3</th>\n",
       "      <th>MFCC_4</th>\n",
       "      <th>MFCC_5</th>\n",
       "      <th>MFCC_6</th>\n",
       "      <th>MFCC_7</th>\n",
       "      <th>MFCC_8</th>\n",
       "      <th>MFCC_9</th>\n",
       "      <th>...</th>\n",
       "      <th>LogMelFilterbank_22</th>\n",
       "      <th>LogMelFilterbank_23</th>\n",
       "      <th>LogMelFilterbank_24</th>\n",
       "      <th>LogMelFilterbank_25</th>\n",
       "      <th>LogMelFilterbank_26</th>\n",
       "      <th>LogMelFilterbank_27</th>\n",
       "      <th>LogMelFilterbank_28</th>\n",
       "      <th>LogMelFilterbank_29</th>\n",
       "      <th>LogMelFilterbank_30</th>\n",
       "      <th>RASTA-PLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown1.wav</td>\n",
       "      <td>-681.880920</td>\n",
       "      <td>94.195984</td>\n",
       "      <td>28.298031</td>\n",
       "      <td>12.374207</td>\n",
       "      <td>11.150973</td>\n",
       "      <td>-0.471950</td>\n",
       "      <td>-6.896591</td>\n",
       "      <td>-4.838930</td>\n",
       "      <td>-1.013391</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.131508</td>\n",
       "      <td>-72.142326</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.412422</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown2.wav</td>\n",
       "      <td>-553.257629</td>\n",
       "      <td>114.635406</td>\n",
       "      <td>34.989910</td>\n",
       "      <td>19.774725</td>\n",
       "      <td>23.673628</td>\n",
       "      <td>5.934775</td>\n",
       "      <td>-9.243794</td>\n",
       "      <td>-6.791627</td>\n",
       "      <td>-0.749043</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.537277</td>\n",
       "      <td>-64.130219</td>\n",
       "      <td>-65.218956</td>\n",
       "      <td>-65.224098</td>\n",
       "      <td>-65.228432</td>\n",
       "      <td>-65.230560</td>\n",
       "      <td>-65.230026</td>\n",
       "      <td>-65.231209</td>\n",
       "      <td>-65.234703</td>\n",
       "      <td>0.992836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown3.wav</td>\n",
       "      <td>-762.091431</td>\n",
       "      <td>117.671295</td>\n",
       "      <td>26.574636</td>\n",
       "      <td>8.749350</td>\n",
       "      <td>9.322863</td>\n",
       "      <td>3.997693</td>\n",
       "      <td>-1.836680</td>\n",
       "      <td>-8.481596</td>\n",
       "      <td>-2.369446</td>\n",
       "      <td>...</td>\n",
       "      <td>-77.393005</td>\n",
       "      <td>-79.308945</td>\n",
       "      <td>-83.454552</td>\n",
       "      <td>-83.560471</td>\n",
       "      <td>-83.612694</td>\n",
       "      <td>-83.603714</td>\n",
       "      <td>-83.515877</td>\n",
       "      <td>-83.473137</td>\n",
       "      <td>-83.629227</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown4.wav</td>\n",
       "      <td>-822.723694</td>\n",
       "      <td>96.840652</td>\n",
       "      <td>27.521198</td>\n",
       "      <td>7.137115</td>\n",
       "      <td>6.640210</td>\n",
       "      <td>2.330118</td>\n",
       "      <td>-4.402487</td>\n",
       "      <td>-7.756093</td>\n",
       "      <td>-0.527433</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.027313</td>\n",
       "      <td>-82.052002</td>\n",
       "      <td>-83.905128</td>\n",
       "      <td>-83.781990</td>\n",
       "      <td>-83.937004</td>\n",
       "      <td>-84.016205</td>\n",
       "      <td>-83.845184</td>\n",
       "      <td>-83.801590</td>\n",
       "      <td>-83.924393</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown5.wav</td>\n",
       "      <td>-565.859985</td>\n",
       "      <td>139.045059</td>\n",
       "      <td>25.531235</td>\n",
       "      <td>15.373220</td>\n",
       "      <td>21.071526</td>\n",
       "      <td>4.035025</td>\n",
       "      <td>-8.164565</td>\n",
       "      <td>-8.290065</td>\n",
       "      <td>2.258997</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.682487</td>\n",
       "      <td>-63.923485</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.597023</td>\n",
       "      <td>-68.601692</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>0.985622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names      MFCC_1      MFCC_2     MFCC_3     MFCC_4     MFCC_5  \\\n",
       "0  Unknown1.wav -681.880920   94.195984  28.298031  12.374207  11.150973   \n",
       "1  Unknown2.wav -553.257629  114.635406  34.989910  19.774725  23.673628   \n",
       "2  Unknown3.wav -762.091431  117.671295  26.574636   8.749350   9.322863   \n",
       "3  Unknown4.wav -822.723694   96.840652  27.521198   7.137115   6.640210   \n",
       "4  Unknown5.wav -565.859985  139.045059  25.531235  15.373220  21.071526   \n",
       "\n",
       "     MFCC_6    MFCC_7    MFCC_8    MFCC_9  ...  LogMelFilterbank_22  \\\n",
       "0 -0.471950 -6.896591 -4.838930 -1.013391  ...           -71.131508   \n",
       "1  5.934775 -9.243794 -6.791627 -0.749043  ...           -62.537277   \n",
       "2  3.997693 -1.836680 -8.481596 -2.369446  ...           -77.393005   \n",
       "3  2.330118 -4.402487 -7.756093 -0.527433  ...           -81.027313   \n",
       "4  4.035025 -8.164565 -8.290065  2.258997  ...           -61.682487   \n",
       "\n",
       "   LogMelFilterbank_23  LogMelFilterbank_24  LogMelFilterbank_25  \\\n",
       "0           -72.142326           -73.414612           -73.414612   \n",
       "1           -64.130219           -65.218956           -65.224098   \n",
       "2           -79.308945           -83.454552           -83.560471   \n",
       "3           -82.052002           -83.905128           -83.781990   \n",
       "4           -63.923485           -68.603783           -68.603783   \n",
       "\n",
       "   LogMelFilterbank_26  LogMelFilterbank_27  LogMelFilterbank_28  \\\n",
       "0           -73.414612           -73.414612           -73.412422   \n",
       "1           -65.228432           -65.230560           -65.230026   \n",
       "2           -83.612694           -83.603714           -83.515877   \n",
       "3           -83.937004           -84.016205           -83.845184   \n",
       "4           -68.603783           -68.603783           -68.597023   \n",
       "\n",
       "   LogMelFilterbank_29  LogMelFilterbank_30  RASTA-PLP  \n",
       "0           -73.414612           -73.414612   1.000000  \n",
       "1           -65.231209           -65.234703   0.992836  \n",
       "2           -83.473137           -83.629227   1.000000  \n",
       "3           -83.801590           -83.924393   1.000000  \n",
       "4           -68.601692           -68.603783   0.985622  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_clean=df_combined.dropna()\n",
    "df_combined_clean=df_combined_clean.reset_index(drop=True)\n",
    "df_combined_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 30)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f=df_combined_clean.iloc[:,1:]\n",
    "y_f=df_combined_clean.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCC_1</th>\n",
       "      <th>MFCC_2</th>\n",
       "      <th>MFCC_3</th>\n",
       "      <th>MFCC_4</th>\n",
       "      <th>MFCC_5</th>\n",
       "      <th>MFCC_6</th>\n",
       "      <th>MFCC_7</th>\n",
       "      <th>MFCC_8</th>\n",
       "      <th>MFCC_9</th>\n",
       "      <th>MFCC_10</th>\n",
       "      <th>...</th>\n",
       "      <th>LogMelFilterbank_22</th>\n",
       "      <th>LogMelFilterbank_23</th>\n",
       "      <th>LogMelFilterbank_24</th>\n",
       "      <th>LogMelFilterbank_25</th>\n",
       "      <th>LogMelFilterbank_26</th>\n",
       "      <th>LogMelFilterbank_27</th>\n",
       "      <th>LogMelFilterbank_28</th>\n",
       "      <th>LogMelFilterbank_29</th>\n",
       "      <th>LogMelFilterbank_30</th>\n",
       "      <th>RASTA-PLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-681.880920</td>\n",
       "      <td>94.195984</td>\n",
       "      <td>28.298031</td>\n",
       "      <td>12.374207</td>\n",
       "      <td>11.150973</td>\n",
       "      <td>-0.471950</td>\n",
       "      <td>-6.896591</td>\n",
       "      <td>-4.838930</td>\n",
       "      <td>-1.013391</td>\n",
       "      <td>-1.418769</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.131508</td>\n",
       "      <td>-72.142326</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.412422</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>-73.414612</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-553.257629</td>\n",
       "      <td>114.635406</td>\n",
       "      <td>34.989910</td>\n",
       "      <td>19.774725</td>\n",
       "      <td>23.673628</td>\n",
       "      <td>5.934775</td>\n",
       "      <td>-9.243794</td>\n",
       "      <td>-6.791627</td>\n",
       "      <td>-0.749043</td>\n",
       "      <td>-3.386630</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.537277</td>\n",
       "      <td>-64.130219</td>\n",
       "      <td>-65.218956</td>\n",
       "      <td>-65.224098</td>\n",
       "      <td>-65.228432</td>\n",
       "      <td>-65.230560</td>\n",
       "      <td>-65.230026</td>\n",
       "      <td>-65.231209</td>\n",
       "      <td>-65.234703</td>\n",
       "      <td>0.992836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-762.091431</td>\n",
       "      <td>117.671295</td>\n",
       "      <td>26.574636</td>\n",
       "      <td>8.749350</td>\n",
       "      <td>9.322863</td>\n",
       "      <td>3.997693</td>\n",
       "      <td>-1.836680</td>\n",
       "      <td>-8.481596</td>\n",
       "      <td>-2.369446</td>\n",
       "      <td>1.738226</td>\n",
       "      <td>...</td>\n",
       "      <td>-77.393005</td>\n",
       "      <td>-79.308945</td>\n",
       "      <td>-83.454552</td>\n",
       "      <td>-83.560471</td>\n",
       "      <td>-83.612694</td>\n",
       "      <td>-83.603714</td>\n",
       "      <td>-83.515877</td>\n",
       "      <td>-83.473137</td>\n",
       "      <td>-83.629227</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-822.723694</td>\n",
       "      <td>96.840652</td>\n",
       "      <td>27.521198</td>\n",
       "      <td>7.137115</td>\n",
       "      <td>6.640210</td>\n",
       "      <td>2.330118</td>\n",
       "      <td>-4.402487</td>\n",
       "      <td>-7.756093</td>\n",
       "      <td>-0.527433</td>\n",
       "      <td>2.585047</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.027313</td>\n",
       "      <td>-82.052002</td>\n",
       "      <td>-83.905128</td>\n",
       "      <td>-83.781990</td>\n",
       "      <td>-83.937004</td>\n",
       "      <td>-84.016205</td>\n",
       "      <td>-83.845184</td>\n",
       "      <td>-83.801590</td>\n",
       "      <td>-83.924393</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-565.859985</td>\n",
       "      <td>139.045059</td>\n",
       "      <td>25.531235</td>\n",
       "      <td>15.373220</td>\n",
       "      <td>21.071526</td>\n",
       "      <td>4.035025</td>\n",
       "      <td>-8.164565</td>\n",
       "      <td>-8.290065</td>\n",
       "      <td>2.258997</td>\n",
       "      <td>0.286934</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.682487</td>\n",
       "      <td>-63.923485</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>-68.597023</td>\n",
       "      <td>-68.601692</td>\n",
       "      <td>-68.603783</td>\n",
       "      <td>0.985622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MFCC_1      MFCC_2     MFCC_3     MFCC_4     MFCC_5    MFCC_6  \\\n",
       "0 -681.880920   94.195984  28.298031  12.374207  11.150973 -0.471950   \n",
       "1 -553.257629  114.635406  34.989910  19.774725  23.673628  5.934775   \n",
       "2 -762.091431  117.671295  26.574636   8.749350   9.322863  3.997693   \n",
       "3 -822.723694   96.840652  27.521198   7.137115   6.640210  2.330118   \n",
       "4 -565.859985  139.045059  25.531235  15.373220  21.071526  4.035025   \n",
       "\n",
       "     MFCC_7    MFCC_8    MFCC_9   MFCC_10  ...  LogMelFilterbank_22  \\\n",
       "0 -6.896591 -4.838930 -1.013391 -1.418769  ...           -71.131508   \n",
       "1 -9.243794 -6.791627 -0.749043 -3.386630  ...           -62.537277   \n",
       "2 -1.836680 -8.481596 -2.369446  1.738226  ...           -77.393005   \n",
       "3 -4.402487 -7.756093 -0.527433  2.585047  ...           -81.027313   \n",
       "4 -8.164565 -8.290065  2.258997  0.286934  ...           -61.682487   \n",
       "\n",
       "   LogMelFilterbank_23  LogMelFilterbank_24  LogMelFilterbank_25  \\\n",
       "0           -72.142326           -73.414612           -73.414612   \n",
       "1           -64.130219           -65.218956           -65.224098   \n",
       "2           -79.308945           -83.454552           -83.560471   \n",
       "3           -82.052002           -83.905128           -83.781990   \n",
       "4           -63.923485           -68.603783           -68.603783   \n",
       "\n",
       "   LogMelFilterbank_26  LogMelFilterbank_27  LogMelFilterbank_28  \\\n",
       "0           -73.414612           -73.414612           -73.412422   \n",
       "1           -65.228432           -65.230560           -65.230026   \n",
       "2           -83.612694           -83.603714           -83.515877   \n",
       "3           -83.937004           -84.016205           -83.845184   \n",
       "4           -68.603783           -68.603783           -68.597023   \n",
       "\n",
       "   LogMelFilterbank_29  LogMelFilterbank_30  RASTA-PLP  \n",
       "0           -73.414612           -73.414612   1.000000  \n",
       "1           -65.231209           -65.234703   0.992836  \n",
       "2           -83.473137           -83.629227   1.000000  \n",
       "3           -83.801590           -83.924393   1.000000  \n",
       "4           -68.601692           -68.603783   0.985622  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# X_train_normalized = scaler.fit_transform(X_train)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m X_f \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Apply PCA for dimensionality reduction to 2D\u001b[39;00m\n\u001b[0;32m     13\u001b[0m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1040\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m        Transformed array.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m     copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m   1043\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1044\u001b[0m         X,\n\u001b[0;32m   1045\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m     )\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\utils\\validation.py:1544\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_f = scaler.transform(X_f)\n",
    "\n",
    "# Apply PCA for dimensionality reduction to 2D\n",
    "n_components = 30\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the training data\n",
    "# X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "\n",
    "# Transform the test data using the same PCA model\n",
    "X_f_pca = pca.transform(X_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test_pca: (5, 49)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features in X_a and X_b must be the same.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m df_combined_clean\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNames\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Assuming 'user' is the target variable\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_test_pca:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test_pca\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 22\u001b[0m test_kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[43msupervector_linear_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_pca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Compute the kernel matrix for testing data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# test_kernel_matrix = supervector_linear_kernel(speaker_models, X_test_pca, X_train_pca)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Predict speaker labels for test data using the SVM classifier\u001b[39;00m\n\u001b[0;32m     29\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m svm_classifier\u001b[38;5;241m.\u001b[39mpredict(test_kernel_matrix)\n",
      "Cell \u001b[1;32mIn[73], line 54\u001b[0m, in \u001b[0;36msupervector_linear_kernel\u001b[1;34m(models, X_a, X_b)\u001b[0m\n\u001b[0;32m     52\u001b[0m             kernel_matrix \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weights[i] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(X_a \u001b[38;5;241m@\u001b[39m covariances_inv \u001b[38;5;241m@\u001b[39m means[i]\u001b[38;5;241m.\u001b[39mT, X_b \u001b[38;5;241m@\u001b[39m covariances_inv \u001b[38;5;241m@\u001b[39m means[i]\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features in X_a and X_b must be the same.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kernel_matrix\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features in X_a and X_b must be the same."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame 'test_df' with the same features as the training data\n",
    "\n",
    "# Load the UBM model\n",
    "ubm_model = joblib.load('model/ubm_model.joblib')\n",
    "\n",
    "# Load individual speaker models\n",
    "speaker_models = []\n",
    "for i in range(len(y_train.unique())):\n",
    "    speaker_model_file = os.path.join('model', f'speaker_model_{i}.joblib')\n",
    "    speaker_model = joblib.load(speaker_model_file)\n",
    "    speaker_models.append(speaker_model)\n",
    "\n",
    "# Load the SVM classifier\n",
    "svm_classifier = joblib.load('model/svm_classifier_model.joblib')\n",
    "\n",
    "# Assuming you have a DataFrame 'test_df' with the same features as the training data\n",
    "X_test_pca = df_combined_clean.drop('Names', axis=1).values  # Assuming 'user' is the target variable\n",
    "\n",
    "print(\"Shape of X_test_pca:\", X_test_pca.shape)\n",
    "test_kernel_matrix = supervector_linear_kernel(speaker_models, X_test_pca, X_train_pca)\n",
    "\n",
    "\n",
    "# Compute the kernel matrix for testing data\n",
    "# test_kernel_matrix = supervector_linear_kernel(speaker_models, X_test_pca, X_train_pca)\n",
    "\n",
    "# Predict speaker labels for test data using the SVM classifier\n",
    "predicted_labels = svm_classifier.predict(test_kernel_matrix)\n",
    "\n",
    "# Map predicted labels to user names\n",
    "predicted_user_names = [y_train.unique()[label] for label in predicted_labels]\n",
    "\n",
    "# Add the predicted user names to the test DataFrame\n",
    "df_combined_clean['predicted_user'] = predicted_user_names\n",
    "\n",
    "# Display the predicted user names\n",
    "print(df_combined_clean[['user', 'predicted_user']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Clones\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 50 features, but StandardScaler is expecting 49 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m X_test \u001b[38;5;241m=\u001b[39m df_combined_clean\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNames\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Assuming 'user' is the target variable\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Use the transform_data function to transform the test data\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Print the shape of X_test_pca for verification\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_test_pca:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test_pca\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[86], line 9\u001b[0m, in \u001b[0;36mtransform_data\u001b[1;34m(train_data, test_data, scaler, pca)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_data\u001b[39m(train_data, test_data, scaler, pca):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Transform the test data using the same scaler and PCA model as used for training\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     test_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     test_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(test_normalized)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_pca\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 50 features, but StandardScaler is expecting 49 features as input."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_data(train_data, test_data, scaler, pca):\n",
    "    # Transform the test data using the same scaler and PCA model as used for training\n",
    "    test_normalized = scaler.transform(test_data)\n",
    "    test_pca = pca.transform(test_normalized)\n",
    "    \n",
    "    return test_pca\n",
    "\n",
    "# Load the UBM model\n",
    "ubm_model = joblib.load('model/ubm_model.joblib')\n",
    "\n",
    "# Load individual speaker models\n",
    "speaker_models = []\n",
    "for i in range(len(y_train.unique())):\n",
    "    speaker_model_file = os.path.join('model', f'speaker_model_{i}.joblib')\n",
    "    speaker_model = joblib.load(speaker_model_file)\n",
    "    speaker_models.append(speaker_model)\n",
    "\n",
    "# Load the SVM classifier\n",
    "svm_classifier = joblib.load('model/svm_classifier_model.joblib')\n",
    "\n",
    "# Assuming you have a DataFrame 'test_df' with the same features as the training data\n",
    "X_test = df_combined_clean.drop('Names', axis=1).values  # Assuming 'user' is the target variable\n",
    "\n",
    "# Use the transform_data function to transform the test data\n",
    "X_test_pca = transform_data(X_train, X_test, scaler, pca)\n",
    "\n",
    "# Print the shape of X_test_pca for verification\n",
    "print(\"Shape of X_test_pca:\", X_test_pca.shape)\n",
    "\n",
    "# Compute the kernel matrix for testing data\n",
    "test_kernel_matrix = supervector_linear_kernel(speaker_models, X_test_pca, X_train_pca)\n",
    "\n",
    "# Predict speaker labels for test data using the SVM classifier\n",
    "predicted_labels = svm_classifier.predict(test_kernel_matrix)\n",
    "\n",
    "# Map predicted labels to user names\n",
    "predicted_user_names = [y_train.unique()[label] for label in predicted_labels]\n",
    "\n",
    "# Add the predicted user names to the test DataFrame\n",
    "df_combined_clean['predicted_user'] = predicted_user_names\n",
    "\n",
    "# Display the predicted user names\n",
    "print(df_combined_clean[['Names', 'predicted_user']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
