{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\947935003.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = 'fourUser25min.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>MFCC_1</th>\n",
       "      <th>MFCC_2</th>\n",
       "      <th>MFCC_3</th>\n",
       "      <th>MFCC_4</th>\n",
       "      <th>MFCC_5</th>\n",
       "      <th>MFCC_6</th>\n",
       "      <th>MFCC_7</th>\n",
       "      <th>MFCC_8</th>\n",
       "      <th>MFCC_9</th>\n",
       "      <th>...</th>\n",
       "      <th>LogMelFilterbank_22</th>\n",
       "      <th>LogMelFilterbank_23</th>\n",
       "      <th>LogMelFilterbank_24</th>\n",
       "      <th>LogMelFilterbank_25</th>\n",
       "      <th>LogMelFilterbank_26</th>\n",
       "      <th>LogMelFilterbank_27</th>\n",
       "      <th>LogMelFilterbank_28</th>\n",
       "      <th>LogMelFilterbank_29</th>\n",
       "      <th>LogMelFilterbank_30</th>\n",
       "      <th>RASTA-PLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-398.515503</td>\n",
       "      <td>95.550636</td>\n",
       "      <td>5.952597</td>\n",
       "      <td>-5.154275</td>\n",
       "      <td>5.881031</td>\n",
       "      <td>-3.027374</td>\n",
       "      <td>-7.761910</td>\n",
       "      <td>-10.212845</td>\n",
       "      <td>-14.519335</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.774456</td>\n",
       "      <td>-50.957180</td>\n",
       "      <td>-51.288067</td>\n",
       "      <td>-51.290344</td>\n",
       "      <td>-51.292488</td>\n",
       "      <td>-51.294460</td>\n",
       "      <td>-51.296204</td>\n",
       "      <td>-51.297623</td>\n",
       "      <td>-51.298595</td>\n",
       "      <td>0.642121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-317.800323</td>\n",
       "      <td>171.617676</td>\n",
       "      <td>19.697014</td>\n",
       "      <td>-20.370554</td>\n",
       "      <td>-5.757511</td>\n",
       "      <td>-5.969464</td>\n",
       "      <td>-11.277127</td>\n",
       "      <td>-18.355204</td>\n",
       "      <td>-21.422365</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.427387</td>\n",
       "      <td>-48.540958</td>\n",
       "      <td>-49.163948</td>\n",
       "      <td>-49.203705</td>\n",
       "      <td>-49.248993</td>\n",
       "      <td>-49.248413</td>\n",
       "      <td>-49.263485</td>\n",
       "      <td>-49.271469</td>\n",
       "      <td>-49.274387</td>\n",
       "      <td>0.496999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-324.595490</td>\n",
       "      <td>157.516998</td>\n",
       "      <td>22.634710</td>\n",
       "      <td>-20.010984</td>\n",
       "      <td>-9.555398</td>\n",
       "      <td>-7.517561</td>\n",
       "      <td>-12.459773</td>\n",
       "      <td>-16.917850</td>\n",
       "      <td>-19.326172</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.045940</td>\n",
       "      <td>-48.755985</td>\n",
       "      <td>-48.908695</td>\n",
       "      <td>-49.024067</td>\n",
       "      <td>-49.160210</td>\n",
       "      <td>-49.273827</td>\n",
       "      <td>-49.335701</td>\n",
       "      <td>-49.433483</td>\n",
       "      <td>-49.478497</td>\n",
       "      <td>0.499368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-320.546265</td>\n",
       "      <td>156.666412</td>\n",
       "      <td>17.499743</td>\n",
       "      <td>-14.465985</td>\n",
       "      <td>1.115923</td>\n",
       "      <td>-3.048698</td>\n",
       "      <td>-9.033537</td>\n",
       "      <td>-14.968829</td>\n",
       "      <td>-23.260252</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.934559</td>\n",
       "      <td>-49.155994</td>\n",
       "      <td>-49.536232</td>\n",
       "      <td>-49.582375</td>\n",
       "      <td>-49.664959</td>\n",
       "      <td>-49.695789</td>\n",
       "      <td>-49.687527</td>\n",
       "      <td>-49.702763</td>\n",
       "      <td>-49.704502</td>\n",
       "      <td>0.540353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arunanshu</td>\n",
       "      <td>-359.157013</td>\n",
       "      <td>136.366379</td>\n",
       "      <td>15.336736</td>\n",
       "      <td>-6.177477</td>\n",
       "      <td>-1.002159</td>\n",
       "      <td>-11.322202</td>\n",
       "      <td>-10.241114</td>\n",
       "      <td>-8.933396</td>\n",
       "      <td>-14.962830</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.878162</td>\n",
       "      <td>-49.499832</td>\n",
       "      <td>-50.128464</td>\n",
       "      <td>-50.226109</td>\n",
       "      <td>-50.330399</td>\n",
       "      <td>-50.397057</td>\n",
       "      <td>-50.485462</td>\n",
       "      <td>-50.518032</td>\n",
       "      <td>-50.578228</td>\n",
       "      <td>0.540744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-437.668182</td>\n",
       "      <td>140.687393</td>\n",
       "      <td>20.285200</td>\n",
       "      <td>5.345737</td>\n",
       "      <td>37.238930</td>\n",
       "      <td>7.116364</td>\n",
       "      <td>-15.066447</td>\n",
       "      <td>-0.308156</td>\n",
       "      <td>0.775279</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.153004</td>\n",
       "      <td>-54.442097</td>\n",
       "      <td>-52.966938</td>\n",
       "      <td>-54.177467</td>\n",
       "      <td>-53.483814</td>\n",
       "      <td>-54.444508</td>\n",
       "      <td>-51.976086</td>\n",
       "      <td>-51.075298</td>\n",
       "      <td>-52.778458</td>\n",
       "      <td>0.936796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-449.798920</td>\n",
       "      <td>83.161926</td>\n",
       "      <td>14.831575</td>\n",
       "      <td>15.308598</td>\n",
       "      <td>32.816296</td>\n",
       "      <td>13.900643</td>\n",
       "      <td>-1.714774</td>\n",
       "      <td>-0.983646</td>\n",
       "      <td>-4.377119</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.619720</td>\n",
       "      <td>-49.312302</td>\n",
       "      <td>-47.790913</td>\n",
       "      <td>-49.173557</td>\n",
       "      <td>-49.138584</td>\n",
       "      <td>-51.341240</td>\n",
       "      <td>-48.446667</td>\n",
       "      <td>-47.292278</td>\n",
       "      <td>-48.953869</td>\n",
       "      <td>0.905650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-478.835052</td>\n",
       "      <td>82.240067</td>\n",
       "      <td>17.422600</td>\n",
       "      <td>25.251034</td>\n",
       "      <td>41.910275</td>\n",
       "      <td>18.777891</td>\n",
       "      <td>-2.398127</td>\n",
       "      <td>-1.575871</td>\n",
       "      <td>0.771020</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.021606</td>\n",
       "      <td>-52.317413</td>\n",
       "      <td>-50.059422</td>\n",
       "      <td>-52.731140</td>\n",
       "      <td>-52.850262</td>\n",
       "      <td>-54.234467</td>\n",
       "      <td>-52.153831</td>\n",
       "      <td>-51.468510</td>\n",
       "      <td>-51.733887</td>\n",
       "      <td>0.954063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-468.360596</td>\n",
       "      <td>72.639534</td>\n",
       "      <td>19.577122</td>\n",
       "      <td>21.420576</td>\n",
       "      <td>37.741058</td>\n",
       "      <td>15.400746</td>\n",
       "      <td>-2.917547</td>\n",
       "      <td>3.897957</td>\n",
       "      <td>3.778859</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.817699</td>\n",
       "      <td>-51.025829</td>\n",
       "      <td>-48.338863</td>\n",
       "      <td>-49.721741</td>\n",
       "      <td>-49.137714</td>\n",
       "      <td>-51.282089</td>\n",
       "      <td>-48.444160</td>\n",
       "      <td>-48.352722</td>\n",
       "      <td>-49.665852</td>\n",
       "      <td>0.942050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>Pratham</td>\n",
       "      <td>-488.891846</td>\n",
       "      <td>113.399849</td>\n",
       "      <td>28.112869</td>\n",
       "      <td>23.015976</td>\n",
       "      <td>46.513409</td>\n",
       "      <td>17.945587</td>\n",
       "      <td>-6.016304</td>\n",
       "      <td>-2.544933</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.068630</td>\n",
       "      <td>-56.126949</td>\n",
       "      <td>-53.122452</td>\n",
       "      <td>-54.311874</td>\n",
       "      <td>-54.267719</td>\n",
       "      <td>-55.702690</td>\n",
       "      <td>-52.628300</td>\n",
       "      <td>-52.511940</td>\n",
       "      <td>-53.038296</td>\n",
       "      <td>0.973527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Names      MFCC_1      MFCC_2     MFCC_3     MFCC_4     MFCC_5  \\\n",
       "0     Arunanshu -398.515503   95.550636   5.952597  -5.154275   5.881031   \n",
       "1     Arunanshu -317.800323  171.617676  19.697014 -20.370554  -5.757511   \n",
       "2     Arunanshu -324.595490  157.516998  22.634710 -20.010984  -9.555398   \n",
       "3     Arunanshu -320.546265  156.666412  17.499743 -14.465985   1.115923   \n",
       "4     Arunanshu -359.157013  136.366379  15.336736  -6.177477  -1.002159   \n",
       "...         ...         ...         ...        ...        ...        ...   \n",
       "1190    Pratham -437.668182  140.687393  20.285200   5.345737  37.238930   \n",
       "1191    Pratham -449.798920   83.161926  14.831575  15.308598  32.816296   \n",
       "1192    Pratham -478.835052   82.240067  17.422600  25.251034  41.910275   \n",
       "1193    Pratham -468.360596   72.639534  19.577122  21.420576  37.741058   \n",
       "1194    Pratham -488.891846  113.399849  28.112869  23.015976  46.513409   \n",
       "\n",
       "         MFCC_6     MFCC_7     MFCC_8     MFCC_9  ...  LogMelFilterbank_22  \\\n",
       "0     -3.027374  -7.761910 -10.212845 -14.519335  ...           -49.774456   \n",
       "1     -5.969464 -11.277127 -18.355204 -21.422365  ...           -47.427387   \n",
       "2     -7.517561 -12.459773 -16.917850 -19.326172  ...           -48.045940   \n",
       "3     -3.048698  -9.033537 -14.968829 -23.260252  ...           -47.934559   \n",
       "4    -11.322202 -10.241114  -8.933396 -14.962830  ...           -47.878162   \n",
       "...         ...        ...        ...        ...  ...                  ...   \n",
       "1190   7.116364 -15.066447  -0.308156   0.775279  ...           -58.153004   \n",
       "1191  13.900643  -1.714774  -0.983646  -4.377119  ...           -51.619720   \n",
       "1192  18.777891  -2.398127  -1.575871   0.771020  ...           -54.021606   \n",
       "1193  15.400746  -2.917547   3.897957   3.778859  ...           -51.817699   \n",
       "1194  17.945587  -6.016304  -2.544933   0.547084  ...           -56.068630   \n",
       "\n",
       "      LogMelFilterbank_23  LogMelFilterbank_24  LogMelFilterbank_25  \\\n",
       "0              -50.957180           -51.288067           -51.290344   \n",
       "1              -48.540958           -49.163948           -49.203705   \n",
       "2              -48.755985           -48.908695           -49.024067   \n",
       "3              -49.155994           -49.536232           -49.582375   \n",
       "4              -49.499832           -50.128464           -50.226109   \n",
       "...                   ...                  ...                  ...   \n",
       "1190           -54.442097           -52.966938           -54.177467   \n",
       "1191           -49.312302           -47.790913           -49.173557   \n",
       "1192           -52.317413           -50.059422           -52.731140   \n",
       "1193           -51.025829           -48.338863           -49.721741   \n",
       "1194           -56.126949           -53.122452           -54.311874   \n",
       "\n",
       "      LogMelFilterbank_26  LogMelFilterbank_27  LogMelFilterbank_28  \\\n",
       "0              -51.292488           -51.294460           -51.296204   \n",
       "1              -49.248993           -49.248413           -49.263485   \n",
       "2              -49.160210           -49.273827           -49.335701   \n",
       "3              -49.664959           -49.695789           -49.687527   \n",
       "4              -50.330399           -50.397057           -50.485462   \n",
       "...                   ...                  ...                  ...   \n",
       "1190           -53.483814           -54.444508           -51.976086   \n",
       "1191           -49.138584           -51.341240           -48.446667   \n",
       "1192           -52.850262           -54.234467           -52.153831   \n",
       "1193           -49.137714           -51.282089           -48.444160   \n",
       "1194           -54.267719           -55.702690           -52.628300   \n",
       "\n",
       "      LogMelFilterbank_29  LogMelFilterbank_30  RASTA-PLP  \n",
       "0              -51.297623           -51.298595   0.642121  \n",
       "1              -49.271469           -49.274387   0.496999  \n",
       "2              -49.433483           -49.478497   0.499368  \n",
       "3              -49.702763           -49.704502   0.540353  \n",
       "4              -50.518032           -50.578228   0.540744  \n",
       "...                   ...                  ...        ...  \n",
       "1190           -51.075298           -52.778458   0.936796  \n",
       "1191           -47.292278           -48.953869   0.905650  \n",
       "1192           -51.468510           -51.733887   0.954063  \n",
       "1193           -48.352722           -49.665852   0.942050  \n",
       "1194           -52.511940           -53.038296   0.973527  \n",
       "\n",
       "[1195 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "\n",
    "# label_encoder object knows \n",
    "# how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Encode labels in column 'species'. \n",
    "df['Names']= label_encoder.fit_transform(df['Names']) \n",
    "\n",
    "df['Names'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import label encoder\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# # Create a DataFrame (replace this with your actual DataFrame)\n",
    "# # df = ...\n",
    "\n",
    "# # Instantiate label_encoder object\n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# # Encode labels in column 'Names'\n",
    "# df['EncodedNames'] = label_encoder.fit_transform(df['Names'])\n",
    "\n",
    "# # Display unique numeric labels assigned to each unique name\n",
    "# unique_names_mapping = dict(zip(df['Names'].unique(), df['EncodedNames'].unique()))\n",
    "# print(\"Mapping of Names to Encoded Labels:\")\n",
    "# print(unique_names_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are your feature and target variable DataFrames\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA for dimensionality reduction to 2D\n",
    "n_components = 23\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "\n",
    "# Transform the test data using the same PCA model\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "\n",
    "# Plot the 2D representation for training data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label in range(24):  # Assuming four classes\n",
    "#     plt.scatter(X_train_pca[y_train == label, 0], X_train_pca[y_train == label, 1], label=f'Class {label}')\n",
    "\n",
    "# plt.title('PCA - Training Data')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the 2D representation for test data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for label in range(24):  # Assuming four classes\n",
    "#     plt.scatter(X_test_pca[y_test == label, 0], X_test_pca[y_test == label, 1], label=f'Class {label}')\n",
    "\n",
    "# plt.title('PCA - Test Data')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is final and useful Best for GMM supervector linear kernel GMM-UBM-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# from sklearn.metrics.pairwise import linear_kernel\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import joblib\n",
    " \n",
    "# # Assuming you have X_train_pca, X_test_pca, y_train, y_test available\n",
    " \n",
    "# # Function to train the UBM\n",
    "# def train_ubm(X_train_pca, n_components=4):\n",
    "#     ubm = GaussianMixture(n_components=n_components, init_params='k-means++', random_state=42)\n",
    "#     ubm.fit(X_train_pca)\n",
    "#     return ubm\n",
    " \n",
    "# # Function to adapt speaker model using GMM-UBM\n",
    "# def adapt_speaker_model(speaker_data, ubm):\n",
    "#     # Bayesian adaptation\n",
    "#     weights = ubm.weights_\n",
    "#     means = ubm.means_\n",
    "#     covariances = ubm.covariances_\n",
    " \n",
    "#     # Reshape the means array to ensure it is treated as a 1D array\n",
    "#     supervector = means.flatten()\n",
    " \n",
    "#     # Adapt the speaker model\n",
    "#     adapted_model = GaussianMixture(n_components=1, init_params='k-means++', random_state=42)\n",
    "#     adapted_model.weights_ = weights\n",
    "#     adapted_model.means_ = np.array([supervector])  # Use the reshaped supervector\n",
    "#     adapted_model.covariances_ = covariances\n",
    " \n",
    "#     # Train the adapted model with speaker data\n",
    "#     adapted_model.fit(speaker_data)\n",
    " \n",
    "#     return adapted_model\n",
    " \n",
    "# # Function to compute the supervector linear kernel\n",
    "# def supervector_linear_kernel(models, X_a, X_b):\n",
    "#     kernel_matrix = np.zeros((X_a.shape[0], X_b.shape[0]))\n",
    "#     for model in models:\n",
    "#         # Extract relevant parameters from the trained GMM\n",
    "#         weights = model.weights_\n",
    "#         means = model.means_\n",
    "#         covariances = model.covariances_\n",
    " \n",
    "#         # Compute the kernel matrix using supervector linear kernel\n",
    "#         for i in range(len(weights)):\n",
    "#             covariances_inv = np.linalg.inv(covariances[i])\n",
    "#             kernel_matrix += weights[i] * np.outer(X_a @ covariances_inv @ means[i].T, X_b @ covariances_inv @ means[i].T)\n",
    " \n",
    "#     return kernel_matrix\n",
    " \n",
    "# # Train the UBM\n",
    "# ubm = train_ubm(X_train_pca)\n",
    " \n",
    "# # Adapt individual speaker models\n",
    "# speaker_models = []\n",
    "# for speaker_label in y_train.unique():\n",
    "#     speaker_data = X_train_pca[y_train == speaker_label]\n",
    "#     adapted_model = adapt_speaker_model(speaker_data, ubm)\n",
    "#     speaker_models.append(adapted_model)\n",
    " \n",
    "# # Compute the kernel matrix for training and testing data\n",
    "# train_kernel_matrix = supervector_linear_kernel(speaker_models, X_train_pca, X_train_pca)\n",
    "# test_kernel_matrix = supervector_linear_kernel(speaker_models, X_test_pca, X_train_pca)\n",
    " \n",
    "# # Train your classifier (e.g., SVM) using the kernel matrix\n",
    "# svm_classifier = SVC(kernel='precomputed')\n",
    "# svm_classifier.fit(train_kernel_matrix, y_train)\n",
    "\n",
    "# # # Save the SVM classifier\n",
    "# svm_classifier_file = os.path.join('model/', 'svm_classifier_model.joblib')\n",
    "# joblib.dump(svm_classifier, svm_classifier_file)\n",
    " \n",
    "# # Predict speaker labels for test data\n",
    "# predicted_labels = svm_classifier.predict(test_kernel_matrix)\n",
    " \n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(y_test, predicted_labels)\n",
    "# print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        61\n",
      "           1       1.00      1.00      1.00        64\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00       239\n",
      "   macro avg       1.00      1.00      1.00       239\n",
      "weighted avg       1.00      1.00      1.00       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "param_grid = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10]}\n",
    "grid_search = GridSearchCV(SVC(decision_function_shape='ovr', random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "svm_classifier_file = os.path.join('model/', 'svm.joblib')\n",
    "joblib.dump(best_svm, svm_classifier_file)\n",
    "\n",
    "y_pred = best_svm.predict(X_test_pca)\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display more detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Factor Analysis\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Assuming you have X_train_pca, X_test_pca, y_train, y_test available\n",
    "\n",
    "# Function to train the UBM\n",
    "def train_ubm(X_train_pca, n_components=4):\n",
    "    ubm = GaussianMixture(n_components=n_components, init_params='k-means++', random_state=42)\n",
    "    ubm.fit(X_train_pca)\n",
    "    return ubm\n",
    "\n",
    "# Function to adapt speaker model using Factor Analysis\n",
    "def adapt_speaker_model(speaker_data, ubm):\n",
    "    # Apply Factor Analysis to the speaker data\n",
    "    factor_analysis = FactorAnalysis(n_components=4, random_state=42)\n",
    "    adapted_data = factor_analysis.fit_transform(speaker_data)\n",
    "\n",
    "    # Train a GMM on the adapted data\n",
    "    adapted_model = GaussianMixture(n_components=1, init_params='k-means++', random_state=42)\n",
    "    adapted_model.fit(adapted_data)\n",
    "\n",
    "    return adapted_model, factor_analysis\n",
    "\n",
    "# Function to compute the Factor Analysis kernel\n",
    "def factor_analysis_kernel(models, X_a, X_b):\n",
    "    kernel_matrix = np.zeros((X_a.shape[0], X_b.shape[0]))\n",
    "    #print(X_a.shape[0],\"::\",X_b.shape[0])\n",
    "    for model, factor_analysis in models:\n",
    "        # Apply Factor Analysis to the data\n",
    "        X_a_transformed = factor_analysis.transform(X_a)\n",
    "        X_b_transformed = factor_analysis.transform(X_b)\n",
    "\n",
    "        # Compute the kernel matrix using Factor Analysis\n",
    "        kernel_matrix += linear_kernel(X_a_transformed, X_b_transformed)\n",
    "\n",
    "    return kernel_matrix\n",
    "\n",
    "# Train the UBM\n",
    "ubm = train_ubm(X_train_pca)\n",
    "\n",
    "# Adapt individual speaker models\n",
    "speaker_models = []\n",
    "for speaker_label in y_train.unique():\n",
    "    speaker_data = X_train_pca[y_train == speaker_label]\n",
    "    adapted_model, factor_analysis = adapt_speaker_model(speaker_data, ubm)\n",
    "    speaker_models.append((adapted_model, factor_analysis))\n",
    "\n",
    "# Compute the kernel matrix for training and testing data\n",
    "train_kernel_matrix = factor_analysis_kernel(speaker_models, X_train_pca, X_train_pca)\n",
    "test_kernel_matrix = factor_analysis_kernel(speaker_models, X_test_pca, X_train_pca)\n",
    "\n",
    "# Train your classifier (e.g., SVM) using the kernel matrix\n",
    "svm_classifier = SVC(kernel='precomputed')\n",
    "svm_classifier.fit(train_kernel_matrix, y_train)\n",
    "\n",
    "svm_classifier_file = os.path.join('model/', 'svm_factor_analysis.joblib')\n",
    "joblib.dump(svm_classifier, svm_classifier_file)\n",
    "\n",
    "# Predict speaker labels for test data\n",
    "predicted_labels = svm_classifier.predict(test_kernel_matrix)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 956)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_kernel_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# from sklearn.metrics.pairwise import linear_kernel\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import joblib\n",
    "# import os\n",
    "\n",
    "# # Assuming you have X_train_pca, X_test_pca, y_train, y_test available\n",
    "\n",
    "# # Function to train the UBM\n",
    "# def train_ubm(X_train_pca, n_components=4):\n",
    "#     ubm = GaussianMixture(n_components=n_components, init_params='k-means++', random_state=42)\n",
    "#     ubm.fit(X_train_pca)\n",
    "#     return ubm\n",
    "\n",
    "# # Function to adapt speaker model using GMM-UBM\n",
    "# def adapt_speaker_model(speaker_data, ubm):\n",
    "#     # Bayesian adaptation\n",
    "#     weights = ubm.weights_\n",
    "#     means = ubm.means_\n",
    "#     covariances = ubm.covariances_\n",
    "\n",
    "#     # Reshape the means array to ensure it is treated as a 1D array\n",
    "#     supervector = means.flatten()\n",
    "\n",
    "#     # Adapt the speaker model\n",
    "#     adapted_model = GaussianMixture(n_components=1, init_params='k-means++', random_state=42)\n",
    "#     adapted_model.weights_ = weights\n",
    "#     adapted_model.means_ = np.array([supervector])  # Use the reshaped supervector\n",
    "#     adapted_model.covariances_ = covariances\n",
    "\n",
    "#     # Train the adapted model with speaker data\n",
    "#     adapted_model.fit(speaker_data)\n",
    "\n",
    "#     return adapted_model\n",
    "\n",
    "# # Function to compute the supervector linear kernel\n",
    "# def supervector_linear_kernel(models, X_a, X_b):\n",
    "#     kernel_matrix = np.zeros((X_a.shape[0], X_b.shape[0]))\n",
    "#     for model in models:\n",
    "#         weights = model.weights_\n",
    "#         means = model.means_\n",
    "#         covariances = model.covariances_\n",
    "\n",
    "#         for i in range(len(weights)):\n",
    "#             covariances_inv = np.linalg.inv(covariances[i])\n",
    "\n",
    "#             # Check if the number of features matches\n",
    "#             if X_a.shape[1] == X_b.shape[1]:\n",
    "#                 print(f\"Shapes: X_a={X_a.shape}, X_b={X_b.shape}\")\n",
    "#                 kernel_matrix += weights[i] * np.outer(X_a @ covariances_inv @ means[i].T, X_b @ covariances_inv @ means[i].T)\n",
    "#             else:\n",
    "#                 raise ValueError(\"Number of features in X_a and X_b must be the same.\")\n",
    "\n",
    "#     return kernel_matrix\n",
    "\n",
    "# # Train the UBM\n",
    "# ubm = train_ubm(X_train_pca)\n",
    "\n",
    "# # Adapt individual speaker models\n",
    "# speaker_models = []\n",
    "# for speaker_label in y_train.unique():\n",
    "#     speaker_data = X_train_pca[y_train == speaker_label]\n",
    "#     adapted_model = adapt_speaker_model(speaker_data, ubm)\n",
    "#     speaker_models.append(adapted_model)\n",
    "\n",
    "# # Create a 'model/' directory if it doesn't exist\n",
    "# model_folder = 'model/'\n",
    "# os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# # Save the UBM and speaker models\n",
    "# ubm_file = os.path.join(model_folder, 'ubm_model.joblib')\n",
    "# joblib.dump(ubm, ubm_file)\n",
    "\n",
    "# for i, speaker_model in enumerate(speaker_models):\n",
    "#     speaker_model_file = os.path.join(model_folder, f'speaker_model_{i}.joblib')\n",
    "#     joblib.dump(speaker_model, speaker_model_file)\n",
    "\n",
    "# # Compute the kernel matrix for training and testing data\n",
    "# train_kernel_matrix = supervector_linear_kernel(speaker_models, X_train_pca, X_train_pca)\n",
    "# test_kernel_matrix = supervector_linear_kernel(speaker_models, X_test_pca, X_train_pca)\n",
    "\n",
    "# # Train your classifier (e.g., SVM) using the kernel matrix\n",
    "# svm_classifier = SVC(kernel='precomputed')\n",
    "# svm_classifier.fit(train_kernel_matrix, y_train)\n",
    "\n",
    "# # Save the SVM classifier\n",
    "# svm_classifier_file = os.path.join(model_folder, 'svm_classifier_model.joblib')\n",
    "# joblib.dump(svm_classifier, svm_classifier_file)\n",
    "\n",
    "# # Predict speaker labels for test data\n",
    "# predicted_labels = svm_classifier.predict(test_kernel_matrix)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(y_test, predicted_labels)\n",
    "# print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply Bark scale\n",
    "def apply_bark_scale(power_spectrum):\n",
    "    # Perform Bark scale transformation on the power spectrum\n",
    "    # You need to implement the specific Bark scale transformation\n",
    "    # For simplicity, let's use a linear transformation as a placeholder\n",
    "    bark_scale_spectrum = np.sqrt(power_spectrum)\n",
    "    return bark_scale_spectrum\n",
    "\n",
    "# Function for critical-band analysis\n",
    "\n",
    "\n",
    "def apply_critical_band_analysis(bark_scale_spectrum):\n",
    "    \"\"\"\n",
    "    Apply critical-band analysis to the Bark scale spectrum.\n",
    "\n",
    "    Parameters:\n",
    "    - bark_scale_spectrum: numpy array, the input Bark scale spectrum.\n",
    "\n",
    "    Returns:\n",
    "    - critical_band_result: numpy array, the result after critical-band analysis.\n",
    "    \"\"\"\n",
    "    omega_values = np.arange(-1.3, 2.6, 0.1)\n",
    "    critical_band_result = np.zeros_like(bark_scale_spectrum)\n",
    "\n",
    "    # Apply the critical-band curve to the Bark scale spectrum\n",
    "    for i in range(len(omega_values) - 1):\n",
    "        mask = (omega_values[i] <= bark_scale_spectrum) & (bark_scale_spectrum <= omega_values[i+1])\n",
    "        if omega_values[i] < -0.5:\n",
    "            critical_band_result[mask] = 10**(2.5 * (bark_scale_spectrum[mask] + 0.5))\n",
    "        elif -0.5 < omega_values[i] < 0.5:\n",
    "            critical_band_result[mask] = 1\n",
    "        elif 0.5 <= omega_values[i] <= 2.5:\n",
    "            critical_band_result[mask] = 10**(-1.0 * (bark_scale_spectrum[mask] - 0.5))\n",
    "\n",
    "    return critical_band_result\n",
    "\n",
    "\n",
    "# Function for equal-loudness preemphasis\n",
    "def equal_loudness_preemphasis(bark_scale_spectrum):\n",
    "    # Implement equal-loudness preemphasis\n",
    "    # You might need to adjust the parameters according to your needs\n",
    "    # For simplicity, let's use a linear transformation as a placeholder\n",
    "    return bark_scale_spectrum\n",
    "\n",
    "# Function for power-law intensity transformation\n",
    "def power_law_intensity_transformation(bark_scale_spectrum):\n",
    "    # Apply power-law transformation (y = x^(1/3))\n",
    "    return bark_scale_spectrum**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasta_plp_feature_extraction(signal, sr):\n",
    "    # Perform RASTA-PLP feature extraction\n",
    "    # Add the RASTA-PLP steps here\n",
    "    \n",
    "    # Set frame size to 20 ms\n",
    "    frame_size_ms = 20\n",
    "    frame_size_samples = int((frame_size_ms / 1000) * sr)\n",
    "\n",
    "    # Set hop length to half of the frame size (50% overlap)\n",
    "    hop_length = frame_size_samples // 2\n",
    "\n",
    "    # Manually perform framing and windowing\n",
    "    num_frames = 1 + (len(signal) - frame_size_samples) // hop_length\n",
    "    frames = np.stack([signal[i * hop_length:i * hop_length + frame_size_samples] * np.hamming(frame_size_samples) for i in range(num_frames)])\n",
    "\n",
    "    # Continue with the remaining RASTA-PLP steps\n",
    "    power_spectrum = np.abs(np.fft.fft(frames, axis=0))**2\n",
    "    bark_scale_spectrum = apply_bark_scale(power_spectrum)\n",
    "    critical_band_result = apply_critical_band_analysis(bark_scale_spectrum)\n",
    "    preemphasis_result = equal_loudness_preemphasis(critical_band_result)\n",
    "    intensity_transformed = power_law_intensity_transformation(preemphasis_result)\n",
    "    \n",
    "    # For simplicity, let's use the mean as a summary statistic for each feature\n",
    "    rasta_plp_features = np.mean(intensity_transformed, axis=1)\n",
    "    \n",
    "    return rasta_plp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # collect audio files for test\n",
    "# import sounddevice as sd\n",
    "# from scipy.io.wavfile import write\n",
    "# import wavio as wv\n",
    "\n",
    "# name = \"Unknown\"\n",
    "# freq = 44100\n",
    "# duration = 5\n",
    "\n",
    "# # words = ['Environment', 'Archives', 'Pronounciation', 'Hour', 'Wednesday', 'Violence', 'Tomb', \n",
    "# #          'Suite', 'Iron', 'Reciept', 'Chores'] \n",
    "\n",
    "# for i in range(7):\n",
    "#     file_name = \"testVoice/\" + name + str(i+1)+ '.wav'\n",
    "#     print(\"Recording file \" + file_name)\n",
    "#     # print(f'{word} - {i+1}')\n",
    "#     recording = sd.rec(int(duration * freq), samplerate=freq, channels=2)\n",
    "#     sd.wait()\n",
    "#     write(file_name, freq, recording)\n",
    "#     print(\"Recorded file \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import librosa\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# # Directory containing the .wav files\n",
    "# directory = \"testVoice/\"\n",
    "\n",
    "# # Create an empty DataFrame\n",
    "# columns = [\"Names\"] + [f\"MFCC_{i+1}\" for i in range(13)] + [\"Chroma\", \"SpectralContrast\", \"Tonnetz\", \"ZeroCrossingRate\", \"RMSEnergy\"] + [f\"LogMelFilterbank_{i+1}\" for i in range(30)] + [\"RASTA-PLP\"]\n",
    "# df_combined = pd.DataFrame(columns=columns)\n",
    "\n",
    "# # Iterate through each .wav file in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith(\".wav\"):\n",
    "#         # Load the audio file\n",
    "#         file_path = os.path.join(directory, filename)\n",
    "#         audio, sr = librosa.load(file_path, sr=44100)\n",
    "#         sr = int(sr)\n",
    "        \n",
    "#         # Calculate the total number of clips\n",
    "#         clip_duration = 5\n",
    "#         clip_samples = int(sr * clip_duration)\n",
    "#         total_clips = len(audio) // clip_samples\n",
    "\n",
    "#         # Create a temporary DataFrame for the current file\n",
    "#         df_temp = pd.DataFrame(columns=columns)\n",
    "#         df_temp[\"Names\"] = [filename.split(\"_\")[0]] * total_clips\n",
    "\n",
    "#         # Split the audio into clips and extract features for each clip\n",
    "#         for i in range(total_clips):\n",
    "#             clip_start = i * clip_samples\n",
    "#             clip_end = (i + 1) * clip_samples\n",
    "#             clip = audio[clip_start:clip_end]\n",
    "\n",
    "#             # Extract features similar to the Arunanshu code\n",
    "#             mfccs = librosa.feature.mfcc(y=clip, sr=sr, n_mfcc=13, hop_length=512, n_fft=2048)\n",
    "#             mfccs_flattened = mfccs.mean(axis=1)\n",
    "\n",
    "#             chroma = librosa.feature.chroma_stft(y=clip, sr=sr)\n",
    "#             contrast = librosa.feature.spectral_contrast(y=clip, sr=sr)\n",
    "#             tonnetz = librosa.feature.tonnetz(y=clip, sr=sr)\n",
    "#             zero_crossings = librosa.feature.zero_crossing_rate(y=clip)\n",
    "#             rms_energy = librosa.feature.rms(y=clip)\n",
    "#             mel_filterbank_energies = librosa.feature.melspectrogram(y=clip, sr=sr, n_mels=30)\n",
    "#             log_mel_filterbank_energies = librosa.power_to_db(mel_filterbank_energies)\n",
    "#             log_mel_filterbank_energies_flattened = log_mel_filterbank_energies.mean(axis=1).tolist()\n",
    "#             rasta_plp_features = rasta_plp_feature_extraction(clip, sr)\n",
    "\n",
    "#             # Concatenate features into a single row\n",
    "#             row_values = [filename.split(\"_\")[0]] + mfccs_flattened.tolist() + [chroma.mean(), contrast.mean(), tonnetz.mean(), zero_crossings.mean(), rms_energy.mean()] + log_mel_filterbank_energies_flattened + [np.mean(rasta_plp_features.tolist())]\n",
    "\n",
    "#             # Append the row to the temporary DataFrame\n",
    "#             df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
    "\n",
    "#         # Append the temporary DataFrame to the main DataFrame\n",
    "#         df_combined = pd.concat([df_combined, df_temp], ignore_index=True)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined_clean=df_combined.dropna()\n",
    "# df_combined_clean=df_combined_clean.reset_index(drop=True)\n",
    "# df_combined_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# unknown_X = df_combined_clean.iloc[:,1:]\n",
    "\n",
    "# # Normalize the data using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# unknown_X_normalized = scaler.fit_transform(unknown_X)\n",
    "\n",
    "# # Apply PCA for dimensionality reduction to 2D\n",
    "# n_components = 22\n",
    "# pca = PCA(n_components=n_components)\n",
    "\n",
    "# # Fit and transform the training data\n",
    "# unknown_X_pca = pca.fit_transform(unknown_X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 24)"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Load the saved SVM classifier model\n",
    "# svm_classifier_file = 'model/svm_classifier_model.joblib'\n",
    "# svm_classifier = joblib.load(svm_classifier_file)\n",
    "\n",
    "# # Assuming you have new data X_new_pca for prediction\n",
    "# # Note: Make sure to apply the same preprocessing steps to X_new_pca as you did for the training data\n",
    "\n",
    "# # Compute the kernel matrix for the new data and training data\n",
    "# new_data_kernel_matrix = supervector_linear_kernel(speaker_models, unknown_X_pca, X_train_pca)\n",
    "\n",
    "# # Use the trained SVM classifier to predict numeric labels for the new data\n",
    "# predicted_numeric_labels = svm_classifier.predict(new_data_kernel_matrix)\n",
    "\n",
    "# # Map numeric labels to usernames using the inverse of the label encoder\n",
    "# predicted_usernames = label_encoder.inverse_transform(predicted_numeric_labels)\n",
    "\n",
    "# # Print the predicted usernames for the new data\n",
    "# print(\"Predicted Usernames for New Data:\", predicted_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # break file into 5 second clips\n",
    "# # generate df of each clip\n",
    "# # pca generate\n",
    "# # predict\n",
    "\n",
    "# from pydub import AudioSegment\n",
    "# import os\n",
    "\n",
    "# def split_wav_into_clips(input_path, output_folder, clip_duration=5000):\n",
    "#     # Load the WAV file\n",
    "#     audio = AudioSegment.from_wav(input_path)\n",
    "\n",
    "#     # Calculate the total duration of the audio in milliseconds\n",
    "#     total_duration = len(audio)\n",
    "\n",
    "#     # Calculate the number of clips\n",
    "#     num_clips = total_duration // clip_duration\n",
    "\n",
    "#     # Create the output folder if it doesn't exist\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     # Split the audio into 5-second clips and save them\n",
    "#     for i in range(num_clips):\n",
    "#         start_time = i * clip_duration\n",
    "#         end_time = (i + 1) * clip_duration\n",
    "#         clip = audio[start_time:end_time]\n",
    "\n",
    "#         # Save the clip to the output folder\n",
    "#         clip.export(os.path.join(output_folder, f\"clip_{i + 1}.wav\"), format=\"wav\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Replace 'input.wav' with the path to your input WAV file\n",
    "#     input_wav_file = 'D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Test/Arunanshu/ArunLudwig.wav'\n",
    "\n",
    "#     # Replace 'output_folder' with the path to the folder where you want to store the clips\n",
    "#     output_folder = 'D:/Clones/Sunamdha/TVSM-Phoenix/GMM_UBM_SVM/testVoice/breakVoice/'\n",
    "\n",
    "#     # Specify the duration of each clip in milliseconds (5 seconds = 5000 milliseconds)\n",
    "#     clip_duration = 5000\n",
    "\n",
    "#     # Call the function to split the WAV file into clips\n",
    "#     split_wav_into_clips(input_wav_file, output_folder, clip_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def split_wav_into_clips(input_path, output_folder, name, clip_duration=5000):\n",
    "    # Load the WAV file\n",
    "    audio = AudioSegment.from_wav(input_path)\n",
    "\n",
    "    # Calculate the total duration of the audio in milliseconds\n",
    "    total_duration = len(audio)\n",
    "\n",
    "    # Calculate the number of clips\n",
    "    num_clips = total_duration // clip_duration\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Split the audio into 5-second clips and save them\n",
    "    for i in range(num_clips):\n",
    "        start_time = i * clip_duration\n",
    "        end_time = (i + 1) * clip_duration\n",
    "        clip = audio[start_time:end_time]\n",
    "\n",
    "        # Create the file name using the provided name and index\n",
    "        file_name = os.path.join(output_folder, f\"{name}_{i + 1}.wav\")\n",
    "\n",
    "        # Save the clip to the output folder\n",
    "        clip.export(file_name, format=\"wav\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask the user for the name\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # Replace 'input.wav' with the path to your input WAV file\n",
    "    input_wav_file = 'D:/OneDrive - TVS Motor Company Ltd/Pheonix Reqd/TvsInternshipCodes/Phase2/Speaker Recognizer/Complete Dataset/Individual Voices - Test/Hari/HariTCSTest.wav'\n",
    "\n",
    "    # Replace 'output_folder' with the path to the folder where you want to store the clips\n",
    "    output_folder = 'D:/Clones/Sunamdha/TVSM-Phoenix/GMM_UBM_SVM/testVoice/breakVoice/'\n",
    "\n",
    "    # Specify the duration of each clip in milliseconds (5 seconds = 5000 milliseconds)\n",
    "    clip_duration = 5000\n",
    "\n",
    "    # Call the function to split the WAV file into clips\n",
    "    split_wav_into_clips(input_wav_file, output_folder, name, clip_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, df_temp], ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
      "C:\\Users\\govindarajula\\AppData\\Local\\Temp\\ipykernel_13284\\479679330.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>MFCC_1</th>\n",
       "      <th>MFCC_2</th>\n",
       "      <th>MFCC_3</th>\n",
       "      <th>MFCC_4</th>\n",
       "      <th>MFCC_5</th>\n",
       "      <th>MFCC_6</th>\n",
       "      <th>MFCC_7</th>\n",
       "      <th>MFCC_8</th>\n",
       "      <th>MFCC_9</th>\n",
       "      <th>...</th>\n",
       "      <th>LogMelFilterbank_22</th>\n",
       "      <th>LogMelFilterbank_23</th>\n",
       "      <th>LogMelFilterbank_24</th>\n",
       "      <th>LogMelFilterbank_25</th>\n",
       "      <th>LogMelFilterbank_26</th>\n",
       "      <th>LogMelFilterbank_27</th>\n",
       "      <th>LogMelFilterbank_28</th>\n",
       "      <th>LogMelFilterbank_29</th>\n",
       "      <th>LogMelFilterbank_30</th>\n",
       "      <th>RASTA-PLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-494.577515</td>\n",
       "      <td>153.463272</td>\n",
       "      <td>9.014831</td>\n",
       "      <td>0.518382</td>\n",
       "      <td>9.593591</td>\n",
       "      <td>22.710651</td>\n",
       "      <td>16.293756</td>\n",
       "      <td>-4.675636</td>\n",
       "      <td>1.852592</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.371265</td>\n",
       "      <td>-55.627869</td>\n",
       "      <td>-56.856239</td>\n",
       "      <td>-57.481670</td>\n",
       "      <td>-60.688587</td>\n",
       "      <td>-64.247826</td>\n",
       "      <td>-61.896523</td>\n",
       "      <td>-58.913963</td>\n",
       "      <td>-60.184212</td>\n",
       "      <td>0.997227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-494.926849</td>\n",
       "      <td>176.379318</td>\n",
       "      <td>12.734867</td>\n",
       "      <td>-5.285261</td>\n",
       "      <td>14.505545</td>\n",
       "      <td>13.966959</td>\n",
       "      <td>4.064733</td>\n",
       "      <td>-4.564042</td>\n",
       "      <td>5.053759</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.911312</td>\n",
       "      <td>-59.081451</td>\n",
       "      <td>-60.200081</td>\n",
       "      <td>-61.323112</td>\n",
       "      <td>-64.879883</td>\n",
       "      <td>-67.249649</td>\n",
       "      <td>-64.725060</td>\n",
       "      <td>-61.227036</td>\n",
       "      <td>-61.808548</td>\n",
       "      <td>0.992662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-479.282654</td>\n",
       "      <td>172.320770</td>\n",
       "      <td>3.454903</td>\n",
       "      <td>-8.066911</td>\n",
       "      <td>17.710249</td>\n",
       "      <td>17.324589</td>\n",
       "      <td>5.747829</td>\n",
       "      <td>-2.453413</td>\n",
       "      <td>0.646860</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.655869</td>\n",
       "      <td>-58.145981</td>\n",
       "      <td>-59.624596</td>\n",
       "      <td>-60.491840</td>\n",
       "      <td>-63.813217</td>\n",
       "      <td>-65.433289</td>\n",
       "      <td>-64.055725</td>\n",
       "      <td>-60.590076</td>\n",
       "      <td>-61.369415</td>\n",
       "      <td>0.985968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-471.052795</td>\n",
       "      <td>175.334793</td>\n",
       "      <td>0.851508</td>\n",
       "      <td>-7.926263</td>\n",
       "      <td>18.664772</td>\n",
       "      <td>20.796444</td>\n",
       "      <td>7.544037</td>\n",
       "      <td>-4.550434</td>\n",
       "      <td>-3.111531</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.850594</td>\n",
       "      <td>-57.472759</td>\n",
       "      <td>-58.948261</td>\n",
       "      <td>-59.374489</td>\n",
       "      <td>-62.924278</td>\n",
       "      <td>-65.546791</td>\n",
       "      <td>-63.754307</td>\n",
       "      <td>-60.366436</td>\n",
       "      <td>-61.216141</td>\n",
       "      <td>0.988208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-484.244202</td>\n",
       "      <td>166.731445</td>\n",
       "      <td>9.197216</td>\n",
       "      <td>-5.347264</td>\n",
       "      <td>15.025880</td>\n",
       "      <td>15.230400</td>\n",
       "      <td>4.352323</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>2.093692</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.659813</td>\n",
       "      <td>-58.365692</td>\n",
       "      <td>-59.340775</td>\n",
       "      <td>-59.791145</td>\n",
       "      <td>-62.898048</td>\n",
       "      <td>-64.670029</td>\n",
       "      <td>-63.927975</td>\n",
       "      <td>-60.529758</td>\n",
       "      <td>-61.293041</td>\n",
       "      <td>0.980383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-477.677917</td>\n",
       "      <td>146.600006</td>\n",
       "      <td>2.329523</td>\n",
       "      <td>-2.148506</td>\n",
       "      <td>24.097303</td>\n",
       "      <td>22.255646</td>\n",
       "      <td>3.676593</td>\n",
       "      <td>-0.823732</td>\n",
       "      <td>-1.112748</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.527576</td>\n",
       "      <td>-56.652569</td>\n",
       "      <td>-58.177132</td>\n",
       "      <td>-58.739456</td>\n",
       "      <td>-61.122135</td>\n",
       "      <td>-62.731800</td>\n",
       "      <td>-62.819317</td>\n",
       "      <td>-60.319477</td>\n",
       "      <td>-61.209656</td>\n",
       "      <td>0.974718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-469.654633</td>\n",
       "      <td>170.490509</td>\n",
       "      <td>2.938600</td>\n",
       "      <td>-3.348502</td>\n",
       "      <td>13.610350</td>\n",
       "      <td>14.907644</td>\n",
       "      <td>4.609077</td>\n",
       "      <td>-1.528955</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.673878</td>\n",
       "      <td>-56.261257</td>\n",
       "      <td>-57.828323</td>\n",
       "      <td>-58.142200</td>\n",
       "      <td>-61.679043</td>\n",
       "      <td>-64.327225</td>\n",
       "      <td>-63.214619</td>\n",
       "      <td>-60.184776</td>\n",
       "      <td>-61.100292</td>\n",
       "      <td>0.986087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-469.379639</td>\n",
       "      <td>176.008301</td>\n",
       "      <td>-0.664301</td>\n",
       "      <td>-5.448917</td>\n",
       "      <td>19.826439</td>\n",
       "      <td>17.016272</td>\n",
       "      <td>1.862653</td>\n",
       "      <td>-5.028743</td>\n",
       "      <td>2.080207</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.284657</td>\n",
       "      <td>-56.720634</td>\n",
       "      <td>-58.313271</td>\n",
       "      <td>-59.149826</td>\n",
       "      <td>-62.629215</td>\n",
       "      <td>-65.468201</td>\n",
       "      <td>-63.577621</td>\n",
       "      <td>-60.317257</td>\n",
       "      <td>-61.159901</td>\n",
       "      <td>0.988424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-493.446777</td>\n",
       "      <td>148.161621</td>\n",
       "      <td>23.757629</td>\n",
       "      <td>-0.841610</td>\n",
       "      <td>12.787059</td>\n",
       "      <td>11.800694</td>\n",
       "      <td>2.203752</td>\n",
       "      <td>5.134097</td>\n",
       "      <td>9.065962</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.838528</td>\n",
       "      <td>-57.997334</td>\n",
       "      <td>-59.600845</td>\n",
       "      <td>-60.079590</td>\n",
       "      <td>-61.526749</td>\n",
       "      <td>-62.140079</td>\n",
       "      <td>-62.188126</td>\n",
       "      <td>-60.749062</td>\n",
       "      <td>-61.342480</td>\n",
       "      <td>0.971983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-508.386444</td>\n",
       "      <td>151.176193</td>\n",
       "      <td>13.125417</td>\n",
       "      <td>-2.312781</td>\n",
       "      <td>13.357423</td>\n",
       "      <td>14.362348</td>\n",
       "      <td>4.682873</td>\n",
       "      <td>3.328497</td>\n",
       "      <td>7.347738</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.017521</td>\n",
       "      <td>-58.634235</td>\n",
       "      <td>-59.572861</td>\n",
       "      <td>-60.402218</td>\n",
       "      <td>-63.795723</td>\n",
       "      <td>-65.861290</td>\n",
       "      <td>-64.044395</td>\n",
       "      <td>-60.792179</td>\n",
       "      <td>-61.461952</td>\n",
       "      <td>0.984409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-468.239166</td>\n",
       "      <td>182.244141</td>\n",
       "      <td>-1.325032</td>\n",
       "      <td>-6.649748</td>\n",
       "      <td>15.131243</td>\n",
       "      <td>14.995859</td>\n",
       "      <td>5.408113</td>\n",
       "      <td>-5.691434</td>\n",
       "      <td>1.650857</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.818508</td>\n",
       "      <td>-56.955811</td>\n",
       "      <td>-58.344429</td>\n",
       "      <td>-59.318409</td>\n",
       "      <td>-63.034023</td>\n",
       "      <td>-65.959251</td>\n",
       "      <td>-63.636040</td>\n",
       "      <td>-60.453106</td>\n",
       "      <td>-61.231194</td>\n",
       "      <td>0.980567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-490.648651</td>\n",
       "      <td>171.039001</td>\n",
       "      <td>21.176123</td>\n",
       "      <td>-6.891419</td>\n",
       "      <td>5.102792</td>\n",
       "      <td>18.519104</td>\n",
       "      <td>13.126620</td>\n",
       "      <td>-2.621220</td>\n",
       "      <td>-2.899350</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.711075</td>\n",
       "      <td>-57.712753</td>\n",
       "      <td>-58.892384</td>\n",
       "      <td>-59.532970</td>\n",
       "      <td>-62.855507</td>\n",
       "      <td>-65.517586</td>\n",
       "      <td>-63.721153</td>\n",
       "      <td>-60.456314</td>\n",
       "      <td>-61.165443</td>\n",
       "      <td>0.994852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-480.051666</td>\n",
       "      <td>158.258789</td>\n",
       "      <td>-0.581400</td>\n",
       "      <td>-2.060962</td>\n",
       "      <td>27.113274</td>\n",
       "      <td>24.991503</td>\n",
       "      <td>4.470406</td>\n",
       "      <td>-4.803124</td>\n",
       "      <td>0.139036</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.012218</td>\n",
       "      <td>-56.941246</td>\n",
       "      <td>-58.422337</td>\n",
       "      <td>-59.369019</td>\n",
       "      <td>-62.555656</td>\n",
       "      <td>-64.740952</td>\n",
       "      <td>-63.588196</td>\n",
       "      <td>-60.322498</td>\n",
       "      <td>-61.119049</td>\n",
       "      <td>0.990288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-492.030243</td>\n",
       "      <td>169.587692</td>\n",
       "      <td>4.627095</td>\n",
       "      <td>-3.808527</td>\n",
       "      <td>21.436874</td>\n",
       "      <td>18.129608</td>\n",
       "      <td>4.898386</td>\n",
       "      <td>-3.406305</td>\n",
       "      <td>4.199694</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.325378</td>\n",
       "      <td>-58.055347</td>\n",
       "      <td>-60.044056</td>\n",
       "      <td>-61.233631</td>\n",
       "      <td>-64.758575</td>\n",
       "      <td>-66.975632</td>\n",
       "      <td>-64.559982</td>\n",
       "      <td>-61.068520</td>\n",
       "      <td>-61.739857</td>\n",
       "      <td>0.993071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-485.153351</td>\n",
       "      <td>171.721664</td>\n",
       "      <td>1.562712</td>\n",
       "      <td>-7.000338</td>\n",
       "      <td>21.965319</td>\n",
       "      <td>21.785604</td>\n",
       "      <td>6.966463</td>\n",
       "      <td>-3.658114</td>\n",
       "      <td>1.073767</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.421375</td>\n",
       "      <td>-58.271187</td>\n",
       "      <td>-59.731823</td>\n",
       "      <td>-60.470936</td>\n",
       "      <td>-63.772110</td>\n",
       "      <td>-66.048119</td>\n",
       "      <td>-64.308983</td>\n",
       "      <td>-60.840740</td>\n",
       "      <td>-61.578014</td>\n",
       "      <td>0.978918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-464.909729</td>\n",
       "      <td>176.743835</td>\n",
       "      <td>-0.979009</td>\n",
       "      <td>-4.334069</td>\n",
       "      <td>17.296522</td>\n",
       "      <td>16.413109</td>\n",
       "      <td>3.388142</td>\n",
       "      <td>-4.522738</td>\n",
       "      <td>1.447766</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.158062</td>\n",
       "      <td>-56.353565</td>\n",
       "      <td>-58.213604</td>\n",
       "      <td>-58.670967</td>\n",
       "      <td>-62.473446</td>\n",
       "      <td>-65.225830</td>\n",
       "      <td>-63.526188</td>\n",
       "      <td>-60.235363</td>\n",
       "      <td>-61.175491</td>\n",
       "      <td>0.981797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-502.603546</td>\n",
       "      <td>169.880615</td>\n",
       "      <td>10.515617</td>\n",
       "      <td>-7.398181</td>\n",
       "      <td>16.430222</td>\n",
       "      <td>16.939690</td>\n",
       "      <td>5.864199</td>\n",
       "      <td>-4.046898</td>\n",
       "      <td>3.795183</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.502792</td>\n",
       "      <td>-59.131798</td>\n",
       "      <td>-60.449757</td>\n",
       "      <td>-61.655479</td>\n",
       "      <td>-65.148727</td>\n",
       "      <td>-67.460648</td>\n",
       "      <td>-64.682732</td>\n",
       "      <td>-61.108414</td>\n",
       "      <td>-61.725258</td>\n",
       "      <td>0.992830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-499.949280</td>\n",
       "      <td>159.758270</td>\n",
       "      <td>21.625462</td>\n",
       "      <td>-10.525053</td>\n",
       "      <td>9.549920</td>\n",
       "      <td>22.093311</td>\n",
       "      <td>10.443289</td>\n",
       "      <td>-3.258510</td>\n",
       "      <td>-2.684537</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.170399</td>\n",
       "      <td>-58.883251</td>\n",
       "      <td>-59.809727</td>\n",
       "      <td>-60.583649</td>\n",
       "      <td>-62.815315</td>\n",
       "      <td>-63.699169</td>\n",
       "      <td>-63.577972</td>\n",
       "      <td>-60.790970</td>\n",
       "      <td>-61.418758</td>\n",
       "      <td>0.988958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-498.863770</td>\n",
       "      <td>162.399246</td>\n",
       "      <td>10.632709</td>\n",
       "      <td>-6.313897</td>\n",
       "      <td>12.830760</td>\n",
       "      <td>23.620214</td>\n",
       "      <td>12.972027</td>\n",
       "      <td>-6.123119</td>\n",
       "      <td>-3.343121</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.667843</td>\n",
       "      <td>-57.944839</td>\n",
       "      <td>-59.393932</td>\n",
       "      <td>-60.264900</td>\n",
       "      <td>-63.827065</td>\n",
       "      <td>-66.817940</td>\n",
       "      <td>-64.474884</td>\n",
       "      <td>-61.113323</td>\n",
       "      <td>-61.728146</td>\n",
       "      <td>0.989879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-487.199524</td>\n",
       "      <td>161.748734</td>\n",
       "      <td>7.178193</td>\n",
       "      <td>-3.036436</td>\n",
       "      <td>13.096792</td>\n",
       "      <td>19.004562</td>\n",
       "      <td>8.778114</td>\n",
       "      <td>-5.548720</td>\n",
       "      <td>-1.701404</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.678799</td>\n",
       "      <td>-57.020332</td>\n",
       "      <td>-58.212914</td>\n",
       "      <td>-59.127926</td>\n",
       "      <td>-62.613472</td>\n",
       "      <td>-65.157379</td>\n",
       "      <td>-63.743103</td>\n",
       "      <td>-60.574219</td>\n",
       "      <td>-61.331711</td>\n",
       "      <td>0.991792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-507.209137</td>\n",
       "      <td>147.395233</td>\n",
       "      <td>7.200534</td>\n",
       "      <td>2.872270</td>\n",
       "      <td>15.626785</td>\n",
       "      <td>19.458698</td>\n",
       "      <td>8.873104</td>\n",
       "      <td>-3.236726</td>\n",
       "      <td>5.301742</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.540749</td>\n",
       "      <td>-56.832577</td>\n",
       "      <td>-58.022079</td>\n",
       "      <td>-58.040840</td>\n",
       "      <td>-61.439205</td>\n",
       "      <td>-65.046860</td>\n",
       "      <td>-62.792324</td>\n",
       "      <td>-59.771675</td>\n",
       "      <td>-60.750015</td>\n",
       "      <td>0.997683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-488.700775</td>\n",
       "      <td>176.950546</td>\n",
       "      <td>7.975835</td>\n",
       "      <td>-3.617903</td>\n",
       "      <td>13.927716</td>\n",
       "      <td>14.632675</td>\n",
       "      <td>5.916562</td>\n",
       "      <td>-3.266651</td>\n",
       "      <td>8.643927</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.969990</td>\n",
       "      <td>-58.148033</td>\n",
       "      <td>-59.379326</td>\n",
       "      <td>-60.133881</td>\n",
       "      <td>-63.521179</td>\n",
       "      <td>-66.675873</td>\n",
       "      <td>-64.207573</td>\n",
       "      <td>-60.849686</td>\n",
       "      <td>-61.660370</td>\n",
       "      <td>0.992943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-480.129028</td>\n",
       "      <td>173.866257</td>\n",
       "      <td>-1.234414</td>\n",
       "      <td>-6.443914</td>\n",
       "      <td>19.632391</td>\n",
       "      <td>21.522032</td>\n",
       "      <td>7.660783</td>\n",
       "      <td>-7.850930</td>\n",
       "      <td>0.993036</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.107666</td>\n",
       "      <td>-57.668522</td>\n",
       "      <td>-58.973309</td>\n",
       "      <td>-59.852093</td>\n",
       "      <td>-63.471973</td>\n",
       "      <td>-66.490448</td>\n",
       "      <td>-64.030304</td>\n",
       "      <td>-60.668133</td>\n",
       "      <td>-61.410961</td>\n",
       "      <td>0.992848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-487.634338</td>\n",
       "      <td>162.585083</td>\n",
       "      <td>0.355896</td>\n",
       "      <td>-1.698611</td>\n",
       "      <td>21.561535</td>\n",
       "      <td>20.707205</td>\n",
       "      <td>5.534382</td>\n",
       "      <td>-4.762535</td>\n",
       "      <td>2.034961</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.047405</td>\n",
       "      <td>-57.638977</td>\n",
       "      <td>-58.521317</td>\n",
       "      <td>-59.137074</td>\n",
       "      <td>-62.752563</td>\n",
       "      <td>-65.230576</td>\n",
       "      <td>-63.919254</td>\n",
       "      <td>-60.492451</td>\n",
       "      <td>-61.278210</td>\n",
       "      <td>0.990422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Names      MFCC_1      MFCC_2     MFCC_3     MFCC_4     MFCC_5  \\\n",
       "0   Unknown -494.577515  153.463272   9.014831   0.518382   9.593591   \n",
       "1   Unknown -494.926849  176.379318  12.734867  -5.285261  14.505545   \n",
       "2   Unknown -479.282654  172.320770   3.454903  -8.066911  17.710249   \n",
       "3   Unknown -471.052795  175.334793   0.851508  -7.926263  18.664772   \n",
       "4   Unknown -484.244202  166.731445   9.197216  -5.347264  15.025880   \n",
       "5   Unknown -477.677917  146.600006   2.329523  -2.148506  24.097303   \n",
       "6   Unknown -469.654633  170.490509   2.938600  -3.348502  13.610350   \n",
       "7   Unknown -469.379639  176.008301  -0.664301  -5.448917  19.826439   \n",
       "8   Unknown -493.446777  148.161621  23.757629  -0.841610  12.787059   \n",
       "9   Unknown -508.386444  151.176193  13.125417  -2.312781  13.357423   \n",
       "10  Unknown -468.239166  182.244141  -1.325032  -6.649748  15.131243   \n",
       "11  Unknown -490.648651  171.039001  21.176123  -6.891419   5.102792   \n",
       "12  Unknown -480.051666  158.258789  -0.581400  -2.060962  27.113274   \n",
       "13  Unknown -492.030243  169.587692   4.627095  -3.808527  21.436874   \n",
       "14  Unknown -485.153351  171.721664   1.562712  -7.000338  21.965319   \n",
       "15  Unknown -464.909729  176.743835  -0.979009  -4.334069  17.296522   \n",
       "16  Unknown -502.603546  169.880615  10.515617  -7.398181  16.430222   \n",
       "17  Unknown -499.949280  159.758270  21.625462 -10.525053   9.549920   \n",
       "18  Unknown -498.863770  162.399246  10.632709  -6.313897  12.830760   \n",
       "19  Unknown -487.199524  161.748734   7.178193  -3.036436  13.096792   \n",
       "20  Unknown -507.209137  147.395233   7.200534   2.872270  15.626785   \n",
       "21  Unknown -488.700775  176.950546   7.975835  -3.617903  13.927716   \n",
       "22  Unknown -480.129028  173.866257  -1.234414  -6.443914  19.632391   \n",
       "23  Unknown -487.634338  162.585083   0.355896  -1.698611  21.561535   \n",
       "\n",
       "       MFCC_6     MFCC_7    MFCC_8    MFCC_9  ...  LogMelFilterbank_22  \\\n",
       "0   22.710651  16.293756 -4.675636  1.852592  ...           -54.371265   \n",
       "1   13.966959   4.064733 -4.564042  5.053759  ...           -57.911312   \n",
       "2   17.324589   5.747829 -2.453413  0.646860  ...           -56.655869   \n",
       "3   20.796444   7.544037 -4.550434 -3.111531  ...           -55.850594   \n",
       "4   15.230400   4.352323  0.033410  2.093692  ...           -56.659813   \n",
       "5   22.255646   3.676593 -0.823732 -1.112748  ...           -55.527576   \n",
       "6   14.907644   4.609077 -1.528955  0.010105  ...           -54.673878   \n",
       "7   17.016272   1.862653 -5.028743  2.080207  ...           -56.284657   \n",
       "8   11.800694   2.203752  5.134097  9.065962  ...           -57.838528   \n",
       "9   14.362348   4.682873  3.328497  7.347738  ...           -58.017521   \n",
       "10  14.995859   5.408113 -5.691434  1.650857  ...           -55.818508   \n",
       "11  18.519104  13.126620 -2.621220 -2.899350  ...           -56.711075   \n",
       "12  24.991503   4.470406 -4.803124  0.139036  ...           -56.012218   \n",
       "13  18.129608   4.898386 -3.406305  4.199694  ...           -57.325378   \n",
       "14  21.785604   6.966463 -3.658114  1.073767  ...           -57.421375   \n",
       "15  16.413109   3.388142 -4.522738  1.447766  ...           -55.158062   \n",
       "16  16.939690   5.864199 -4.046898  3.795183  ...           -58.502792   \n",
       "17  22.093311  10.443289 -3.258510 -2.684537  ...           -58.170399   \n",
       "18  23.620214  12.972027 -6.123119 -3.343121  ...           -56.667843   \n",
       "19  19.004562   8.778114 -5.548720 -1.701404  ...           -55.678799   \n",
       "20  19.458698   8.873104 -3.236726  5.301742  ...           -55.540749   \n",
       "21  14.632675   5.916562 -3.266651  8.643927  ...           -56.969990   \n",
       "22  21.522032   7.660783 -7.850930  0.993036  ...           -56.107666   \n",
       "23  20.707205   5.534382 -4.762535  2.034961  ...           -56.047405   \n",
       "\n",
       "    LogMelFilterbank_23  LogMelFilterbank_24  LogMelFilterbank_25  \\\n",
       "0            -55.627869           -56.856239           -57.481670   \n",
       "1            -59.081451           -60.200081           -61.323112   \n",
       "2            -58.145981           -59.624596           -60.491840   \n",
       "3            -57.472759           -58.948261           -59.374489   \n",
       "4            -58.365692           -59.340775           -59.791145   \n",
       "5            -56.652569           -58.177132           -58.739456   \n",
       "6            -56.261257           -57.828323           -58.142200   \n",
       "7            -56.720634           -58.313271           -59.149826   \n",
       "8            -57.997334           -59.600845           -60.079590   \n",
       "9            -58.634235           -59.572861           -60.402218   \n",
       "10           -56.955811           -58.344429           -59.318409   \n",
       "11           -57.712753           -58.892384           -59.532970   \n",
       "12           -56.941246           -58.422337           -59.369019   \n",
       "13           -58.055347           -60.044056           -61.233631   \n",
       "14           -58.271187           -59.731823           -60.470936   \n",
       "15           -56.353565           -58.213604           -58.670967   \n",
       "16           -59.131798           -60.449757           -61.655479   \n",
       "17           -58.883251           -59.809727           -60.583649   \n",
       "18           -57.944839           -59.393932           -60.264900   \n",
       "19           -57.020332           -58.212914           -59.127926   \n",
       "20           -56.832577           -58.022079           -58.040840   \n",
       "21           -58.148033           -59.379326           -60.133881   \n",
       "22           -57.668522           -58.973309           -59.852093   \n",
       "23           -57.638977           -58.521317           -59.137074   \n",
       "\n",
       "    LogMelFilterbank_26  LogMelFilterbank_27  LogMelFilterbank_28  \\\n",
       "0            -60.688587           -64.247826           -61.896523   \n",
       "1            -64.879883           -67.249649           -64.725060   \n",
       "2            -63.813217           -65.433289           -64.055725   \n",
       "3            -62.924278           -65.546791           -63.754307   \n",
       "4            -62.898048           -64.670029           -63.927975   \n",
       "5            -61.122135           -62.731800           -62.819317   \n",
       "6            -61.679043           -64.327225           -63.214619   \n",
       "7            -62.629215           -65.468201           -63.577621   \n",
       "8            -61.526749           -62.140079           -62.188126   \n",
       "9            -63.795723           -65.861290           -64.044395   \n",
       "10           -63.034023           -65.959251           -63.636040   \n",
       "11           -62.855507           -65.517586           -63.721153   \n",
       "12           -62.555656           -64.740952           -63.588196   \n",
       "13           -64.758575           -66.975632           -64.559982   \n",
       "14           -63.772110           -66.048119           -64.308983   \n",
       "15           -62.473446           -65.225830           -63.526188   \n",
       "16           -65.148727           -67.460648           -64.682732   \n",
       "17           -62.815315           -63.699169           -63.577972   \n",
       "18           -63.827065           -66.817940           -64.474884   \n",
       "19           -62.613472           -65.157379           -63.743103   \n",
       "20           -61.439205           -65.046860           -62.792324   \n",
       "21           -63.521179           -66.675873           -64.207573   \n",
       "22           -63.471973           -66.490448           -64.030304   \n",
       "23           -62.752563           -65.230576           -63.919254   \n",
       "\n",
       "    LogMelFilterbank_29  LogMelFilterbank_30  RASTA-PLP  \n",
       "0            -58.913963           -60.184212   0.997227  \n",
       "1            -61.227036           -61.808548   0.992662  \n",
       "2            -60.590076           -61.369415   0.985968  \n",
       "3            -60.366436           -61.216141   0.988208  \n",
       "4            -60.529758           -61.293041   0.980383  \n",
       "5            -60.319477           -61.209656   0.974718  \n",
       "6            -60.184776           -61.100292   0.986087  \n",
       "7            -60.317257           -61.159901   0.988424  \n",
       "8            -60.749062           -61.342480   0.971983  \n",
       "9            -60.792179           -61.461952   0.984409  \n",
       "10           -60.453106           -61.231194   0.980567  \n",
       "11           -60.456314           -61.165443   0.994852  \n",
       "12           -60.322498           -61.119049   0.990288  \n",
       "13           -61.068520           -61.739857   0.993071  \n",
       "14           -60.840740           -61.578014   0.978918  \n",
       "15           -60.235363           -61.175491   0.981797  \n",
       "16           -61.108414           -61.725258   0.992830  \n",
       "17           -60.790970           -61.418758   0.988958  \n",
       "18           -61.113323           -61.728146   0.989879  \n",
       "19           -60.574219           -61.331711   0.991792  \n",
       "20           -59.771675           -60.750015   0.997683  \n",
       "21           -60.849686           -61.660370   0.992943  \n",
       "22           -60.668133           -61.410961   0.992848  \n",
       "23           -60.492451           -61.278210   0.990422  \n",
       "\n",
       "[24 rows x 50 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Directory containing the .wav files\n",
    "directory = \"D:/Clones/Sunamdha/TVSM-Phoenix/GMM_UBM_SVM/testVoice/breakVoice/\"\n",
    "\n",
    "# Create an empty DataFrame\n",
    "columns = [\"Names\"] + [f\"MFCC_{i+1}\" for i in range(13)] + [\"Chroma\", \"SpectralContrast\", \"Tonnetz\", \"ZeroCrossingRate\", \"RMSEnergy\"] + [f\"LogMelFilterbank_{i+1}\" for i in range(30)] + [\"RASTA-PLP\"]\n",
    "df_combined = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Iterate through each .wav file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Load the audio file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        audio, sr = librosa.load(file_path, sr=44100)\n",
    "        sr = int(sr)\n",
    "        \n",
    "        # Calculate the total number of clips\n",
    "        clip_duration = 5\n",
    "        clip_samples = int(sr * clip_duration)\n",
    "        total_clips = len(audio) // clip_samples\n",
    "\n",
    "        # Create a temporary DataFrame for the current file\n",
    "        df_temp = pd.DataFrame(columns=columns)\n",
    "        df_temp[\"Names\"] = [filename.split(\"_\")[0]] * total_clips\n",
    "\n",
    "        # Split the audio into clips and extract features for each clip\n",
    "        for i in range(total_clips):\n",
    "            clip_start = i * clip_samples\n",
    "            clip_end = (i + 1) * clip_samples\n",
    "            clip = audio[clip_start:clip_end]\n",
    "\n",
    "            # Extract features similar to the Arunanshu code\n",
    "            mfccs = librosa.feature.mfcc(y=clip, sr=sr, n_mfcc=13, hop_length=512, n_fft=2048)\n",
    "            mfccs_flattened = mfccs.mean(axis=1)\n",
    "\n",
    "            chroma = librosa.feature.chroma_stft(y=clip, sr=sr)\n",
    "            contrast = librosa.feature.spectral_contrast(y=clip, sr=sr)\n",
    "            tonnetz = librosa.feature.tonnetz(y=clip, sr=sr)\n",
    "            zero_crossings = librosa.feature.zero_crossing_rate(y=clip)\n",
    "            rms_energy = librosa.feature.rms(y=clip)\n",
    "            mel_filterbank_energies = librosa.feature.melspectrogram(y=clip, sr=sr, n_mels=30)\n",
    "            log_mel_filterbank_energies = librosa.power_to_db(mel_filterbank_energies)\n",
    "            log_mel_filterbank_energies_flattened = log_mel_filterbank_energies.mean(axis=1).tolist()\n",
    "            rasta_plp_features = rasta_plp_feature_extraction(clip, sr)\n",
    "\n",
    "            # Concatenate features into a single row\n",
    "            row_values = [filename.split(\"_\")[0]] + mfccs_flattened.tolist() + [chroma.mean(), contrast.mean(), tonnetz.mean(), zero_crossings.mean(), rms_energy.mean()] + log_mel_filterbank_energies_flattened + [np.mean(rasta_plp_features.tolist())]\n",
    "\n",
    "            # Append the row to the temporary DataFrame\n",
    "            df_temp = df_temp._append(pd.Series(row_values, index=df_temp.columns), ignore_index=True)\n",
    "\n",
    "        # Append the temporary DataFrame to the main DataFrame\n",
    "        df_combined = pd.concat([df_combined, df_temp], ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_combined_clean=df_combined.dropna()\n",
    "df_combined_clean=df_combined_clean.reset_index(drop=True)\n",
    "df_combined_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "unknown_X = df_combined_clean.iloc[:,1:]\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "unknown_X_normalized = scaler.fit_transform(unknown_X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction to 2D\n",
    "n_components = 23\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the training data\n",
    "unknown_X_pca = pca.fit_transform(unknown_X_normalized)\n",
    "\n",
    "# unknown_X_kernel_matrix = factor_analysis_kernel(speaker_models, unknown_X_pca, unknown_X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.25101928e+00,  8.02771286e+00, -2.78433073e+00,\n",
       "         2.60968415e+00,  1.61909387e-02, -1.61993935e-01,\n",
       "        -2.38030277e-01,  2.43423998e+00, -2.58002017e-01,\n",
       "         3.35610150e-01, -5.99134928e-01,  4.18670970e-01,\n",
       "        -1.23594893e-01, -5.04632976e-01,  3.29734988e-02,\n",
       "         2.60147030e-01, -2.66855675e-02, -2.83856214e-03,\n",
       "        -4.14702821e-02, -8.35004749e-02, -5.36260928e-02,\n",
       "        -2.32238657e-02, -8.81805725e-03],\n",
       "       [ 5.32939869e-01, -6.21359273e+00, -4.35620184e-01,\n",
       "         1.88079848e-02, -1.20067505e+00, -1.26451326e+00,\n",
       "        -1.10765917e+00,  3.73042479e-01, -1.23505858e+00,\n",
       "         5.40915468e-01,  3.53737182e-01,  1.68886193e-01,\n",
       "         2.69516905e-01,  2.49777737e-01,  1.56681087e-02,\n",
       "         7.24101652e-01, -1.53275090e-01,  1.26029011e-01,\n",
       "         1.15849418e-01,  5.23057710e-02,  1.79498996e-01,\n",
       "        -1.15135036e-01, -9.56023883e-03],\n",
       "       [-2.71672670e+00, -1.48922937e+00,  6.21437784e-01,\n",
       "        -2.24366990e-01, -1.58816232e-01,  2.61696599e+00,\n",
       "         9.10193020e-03,  6.00921661e-01, -4.52521229e-01,\n",
       "        -1.05218959e-01, -1.96011151e-01, -7.75556742e-01,\n",
       "         9.19061736e-01, -3.25133359e-01,  3.43038748e-01,\n",
       "        -1.97302627e-01, -1.47811712e-01,  2.28663480e-01,\n",
       "         1.05438428e-01,  1.38335963e-01, -2.42457306e-01,\n",
       "        -6.18957113e-02, -7.03748759e-02],\n",
       "       [-5.29460761e+00,  7.20167562e-01, -9.73052725e-01,\n",
       "        -2.97883634e-01,  8.17765186e-01,  2.47359466e+00,\n",
       "        -1.93726078e+00, -4.44389234e-02, -4.15644294e-01,\n",
       "        -3.31052512e-01, -6.99250179e-02, -2.78671221e-01,\n",
       "        -3.47915906e-01, -2.04339271e-01,  1.33200324e-01,\n",
       "         3.97771677e-03,  3.92779794e-01, -2.15541766e-01,\n",
       "         2.56867680e-02,  5.57844936e-04,  2.74950926e-01,\n",
       "         5.35924608e-02, -1.27064765e-01],\n",
       "       [-8.23862254e-01, -1.19462195e+00,  2.23677836e+00,\n",
       "         1.32762369e+00, -3.22605113e-02,  1.53928885e+00,\n",
       "        -6.93382519e-01, -1.06242360e+00,  1.63110326e-01,\n",
       "        -6.34548026e-01, -3.31692775e-01, -3.41729858e-01,\n",
       "        -6.80685556e-02, -2.30874856e-01, -2.23680050e-01,\n",
       "         6.31452285e-01,  1.54568470e-01, -2.77859991e-02,\n",
       "        -2.28497848e-01, -2.33062130e-01, -1.72712129e-01,\n",
       "        -7.47503423e-03,  1.62508075e-01],\n",
       "       [ 3.39606710e-01,  5.19887957e+00,  3.41962811e+00,\n",
       "        -3.00508225e+00,  2.89044205e+00,  5.09363451e-01,\n",
       "        -1.02127420e+00, -8.05842997e-01,  8.82700784e-02,\n",
       "         4.67613242e-01,  3.57348807e-01,  8.71156574e-01,\n",
       "         5.61795658e-02,  6.06319152e-03,  1.92924147e-01,\n",
       "         1.28610208e-01, -2.19101655e-01, -1.88874478e-01,\n",
       "        -1.17851855e-02,  2.92779153e-01, -7.71828400e-02,\n",
       "        -3.82522778e-02,  3.94074955e-02],\n",
       "       [-5.42331043e+00,  2.84190413e+00,  1.56138024e+00,\n",
       "         2.63641918e+00, -3.50399281e-01,  4.92089917e-01,\n",
       "        -2.53472109e-01, -7.50460272e-01, -3.35564333e-01,\n",
       "         9.31521063e-01,  7.45073242e-01,  2.68642012e-02,\n",
       "        -7.37158299e-01, -4.84344216e-02,  2.53836599e-02,\n",
       "        -3.55342335e-01, -1.84725571e-01,  4.18689120e-01,\n",
       "        -1.38704443e-01, -2.00235695e-01,  2.98196579e-02,\n",
       "        -4.10291010e-02, -7.46277227e-03],\n",
       "       [-6.39745590e+00,  5.32028692e-01,  4.03466364e-01,\n",
       "         2.70498093e-01, -2.43514487e-01, -2.21748849e+00,\n",
       "        -3.05841279e-01, -1.47095761e-02,  1.05000114e+00,\n",
       "         1.02510678e+00, -5.10019669e-01, -6.82995632e-01,\n",
       "        -4.29502127e-01,  2.46723023e-01, -5.85656489e-02,\n",
       "         1.06534020e-01,  2.92075892e-01, -1.04465226e-01,\n",
       "         3.55416619e-01,  8.41324299e-02, -1.92198841e-01,\n",
       "        -3.45659467e-02, -1.39355608e-02],\n",
       "       [ 5.63277085e+00, -2.02463660e+00,  6.60268589e+00,\n",
       "         2.96175809e+00,  1.88511348e+00, -1.49353775e+00,\n",
       "         1.34750476e-01,  9.81833715e-01, -7.95192367e-01,\n",
       "        -3.99795959e-01,  1.82242087e-01,  8.75739194e-02,\n",
       "         2.05356067e-01,  1.89963783e-01,  3.80012910e-02,\n",
       "        -2.79065174e-01,  3.49257173e-01,  2.60114257e-02,\n",
       "         1.11369959e-01, -5.93146444e-02,  1.11244841e-02,\n",
       "         6.37128367e-02, -7.73976862e-03],\n",
       "       [ 7.65345089e+00, -1.63830024e+00,  3.08611229e+00,\n",
       "        -2.64534060e-01, -1.81901973e+00,  9.14647644e-01,\n",
       "         1.43164564e+00, -8.42648389e-01,  6.31750919e-01,\n",
       "         6.43823324e-01, -7.93387185e-01, -2.60796276e-01,\n",
       "        -2.63962290e-01, -7.02116891e-01, -1.13037677e-01,\n",
       "        -1.73670836e-02, -1.02664550e-01,  2.08925382e-02,\n",
       "         4.36909483e-02,  1.94227901e-01,  2.33662765e-01,\n",
       "         1.34101644e-02,  1.94506543e-04],\n",
       "       [-7.58907152e+00, -2.69433141e-01,  4.90170918e-01,\n",
       "         2.01004185e+00, -7.38245769e-01,  1.21398483e+00,\n",
       "         2.48764964e+00,  8.24937929e-01,  2.63437978e-01,\n",
       "         2.32467732e-01, -2.23023166e-01,  3.64060160e-01,\n",
       "         1.86593790e-01,  8.02083100e-01,  2.91632068e-01,\n",
       "         1.24652566e-01,  7.57699038e-02, -1.58695612e-01,\n",
       "        -3.00976031e-01,  1.30327090e-01,  8.78292088e-02,\n",
       "         1.43413594e-03,  2.36009927e-02],\n",
       "       [ 2.01948126e+00, -1.60885778e+00, -3.45404311e+00,\n",
       "         4.29026134e+00,  7.69456591e-01,  7.92978590e-01,\n",
       "         2.67438013e-01,  9.63708575e-02,  4.32545341e-01,\n",
       "        -3.06715415e-01,  1.26442453e+00, -3.45937928e-01,\n",
       "        -1.16311917e-01, -1.41695917e-01, -3.94140313e-01,\n",
       "        -5.87853998e-02, -1.11365866e-01, -1.51145628e-01,\n",
       "         1.54110007e-01,  2.99090779e-01, -1.47603358e-02,\n",
       "         4.15624557e-02,  7.95206438e-02],\n",
       "       [-1.32139434e+00,  3.06243003e+00, -2.12724259e-01,\n",
       "        -3.73706059e+00,  8.65081457e-01, -2.18274859e+00,\n",
       "         7.53373177e-01,  7.68795071e-01,  6.00457997e-01,\n",
       "        -7.89977051e-01,  5.79390170e-01, -8.04421691e-01,\n",
       "         5.27519791e-02, -2.97364162e-01, -2.74286864e-02,\n",
       "         6.62893273e-03,  2.08222673e-01,  1.87705474e-01,\n",
       "        -2.56326463e-01,  8.41240499e-02,  1.43159859e-01,\n",
       "        -1.22150698e-01,  3.47560241e-02],\n",
       "       [ 3.06282145e-01, -3.17988882e+00, -7.26208437e-02,\n",
       "        -2.56304189e+00, -1.40393470e+00, -6.47966142e-01,\n",
       "         6.86128136e-01,  6.07150754e-01, -1.96825618e-01,\n",
       "         2.11123620e-01,  7.62412732e-01, -1.68659813e-01,\n",
       "        -3.10444720e-01, -4.62800221e-01,  7.30887452e-01,\n",
       "        -3.60715408e-02, -1.67745533e-01, -3.43025795e-01,\n",
       "         3.38020062e-02, -2.61536263e-01, -7.94748418e-02,\n",
       "         9.50873616e-02,  3.78952342e-02],\n",
       "       [-2.10384451e+00, -2.09671483e+00,  5.39168907e-01,\n",
       "        -2.46882075e+00,  1.41694903e+00,  1.35433345e+00,\n",
       "         1.36095868e+00,  8.50495992e-01, -1.80705648e-01,\n",
       "        -7.20233319e-01, -2.60241842e-01,  3.34477435e-01,\n",
       "        -5.51154017e-01,  1.98111185e-01, -6.14813140e-01,\n",
       "        -9.51498708e-02, -2.84787636e-01, -8.50589463e-02,\n",
       "         2.75458640e-01, -2.17185647e-01, -1.01253039e-02,\n",
       "        -1.16066781e-01, -3.69409436e-02],\n",
       "       [-7.14918586e+00,  1.47456511e+00,  2.51677147e-01,\n",
       "         1.50190625e+00, -3.04350830e-01, -1.64770424e+00,\n",
       "         1.81593300e-01, -7.44493005e-01,  1.25030805e+00,\n",
       "        -8.76497415e-01, -4.93632057e-02,  7.30198759e-01,\n",
       "         6.25452646e-01, -4.17147713e-01,  4.75778515e-02,\n",
       "         2.02238118e-01, -2.13768257e-01,  1.43812850e-01,\n",
       "         2.04765108e-01, -1.05729599e-01,  8.91233402e-02,\n",
       "         1.14438508e-01, -6.37177719e-02],\n",
       "       [ 4.04865233e+00, -4.92140915e+00, -7.78370644e-01,\n",
       "        -2.31775886e+00, -9.03377234e-01,  1.22634066e+00,\n",
       "        -1.17010140e+00,  1.00888151e+00,  1.80608662e+00,\n",
       "         6.02110046e-01,  3.80164957e-01,  7.54698010e-01,\n",
       "         2.46976674e-01,  1.61285452e-01, -2.81074495e-01,\n",
       "        -1.71513845e-01,  2.61337120e-01,  1.55379611e-01,\n",
       "        -1.46518958e-01, -8.07616409e-02, -6.86574504e-02,\n",
       "         3.49300053e-02, -2.53154244e-02],\n",
       "       [ 5.65148109e+00, -3.08913397e+00, -2.62415037e+00,\n",
       "         1.26269155e+00,  3.82377831e+00, -7.01219396e-01,\n",
       "        -4.79763546e-01, -6.14608174e-01,  8.54430245e-01,\n",
       "         6.71958238e-02, -6.36102129e-01, -5.93829584e-01,\n",
       "        -3.64627695e-02,  4.87290821e-01,  3.89737785e-01,\n",
       "        -5.26050093e-02, -3.40164021e-01,  1.61920451e-02,\n",
       "        -1.60066120e-01, -1.33917366e-01,  5.85924855e-02,\n",
       "         5.03614371e-03, -4.02721243e-02],\n",
       "       [ 3.15563676e+00, -1.44827681e+00, -3.96832633e+00,\n",
       "        -1.07190277e+00,  1.11667761e+00, -8.95454396e-02,\n",
       "         1.76932462e+00, -1.53462206e+00, -9.36778901e-01,\n",
       "        -1.68014182e-01, -4.18558195e-02,  6.66654543e-01,\n",
       "        -3.51666128e-01, -1.18175927e-01,  2.36384003e-01,\n",
       "         1.43603531e-01,  4.30278237e-01,  2.48204234e-01,\n",
       "         5.87022075e-02,  7.99227755e-02, -1.47452918e-01,\n",
       "         2.65107855e-02, -4.45829241e-02],\n",
       "       [ 9.01455575e-01,  2.19730562e+00, -1.82059083e+00,\n",
       "         4.15577344e-01, -1.52463561e-01, -6.46276241e-01,\n",
       "         4.88682099e-01, -1.43643074e+00, -5.74073551e-01,\n",
       "         7.56530063e-01,  8.94778357e-02,  1.28898537e-02,\n",
       "         1.00715312e+00, -1.31006851e-01, -3.80713856e-01,\n",
       "        -3.48531461e-01,  1.48834203e-01, -3.27099552e-01,\n",
       "        -4.53812006e-02, -2.45464620e-01,  4.61190280e-02,\n",
       "        -1.03776950e-01, -5.84062683e-03],\n",
       "       [ 7.69935573e+00,  6.56585518e+00,  1.22072383e-01,\n",
       "        -5.69563998e-01, -3.33491913e+00,  7.85512108e-01,\n",
       "        -3.55330401e-01, -7.58315391e-01,  2.88284670e-01,\n",
       "        -7.96241181e-01,  2.82043305e-01, -2.50287180e-01,\n",
       "        -2.40576584e-02,  9.25599457e-01,  2.35148646e-01,\n",
       "         1.13378977e-02, -1.10379321e-02,  2.58621179e-02,\n",
       "         2.00999006e-01, -5.54044002e-02,  7.81426739e-03,\n",
       "        -2.16149004e-02, -1.46929977e-02],\n",
       "       [-9.54581495e-01, -3.30751090e+00, -2.10678471e-01,\n",
       "         1.34435936e+00, -2.38156703e+00, -1.85741829e+00,\n",
       "        -1.29056470e+00, -3.26138876e-01, -3.24779456e-01,\n",
       "        -9.28169304e-01, -5.09434642e-01,  4.72582924e-01,\n",
       "        -3.97653226e-01, -1.41225773e-01, -4.44916378e-03,\n",
       "        -4.31684433e-01, -1.18399500e-01, -1.70419344e-01,\n",
       "        -2.80117173e-01,  2.04058702e-01, -1.29136379e-01,\n",
       "        -9.14150023e-02, -4.90116996e-02],\n",
       "       [-3.08084016e+00, -6.56604601e-02, -2.19011043e+00,\n",
       "        -1.85756989e+00, -1.39018224e-01, -1.52458789e-01,\n",
       "        -8.41399529e-01,  3.22031277e-01, -7.24800927e-01,\n",
       "        -5.21056345e-03, -7.49742683e-01,  1.34360598e-01,\n",
       "         1.42910368e-01,  1.77724390e-01,  2.68614760e-02,\n",
       "        -4.56080149e-01, -1.89792852e-02,  1.61385554e-01,\n",
       "         1.58139192e-01,  4.56451390e-02,  1.20382896e-01,\n",
       "         9.46349135e-02,  2.43426803e-01],\n",
       "       [-3.37251712e-01,  1.92641798e+00,  1.90040532e-01,\n",
       "        -2.27204320e+00, -4.38892867e-01, -8.56229596e-01,\n",
       "         1.23434200e-01,  6.64307758e-02, -9.98736440e-01,\n",
       "         2.47656572e-01, -2.63806384e-02, -5.40188218e-01,\n",
       "         4.59996568e-02,  2.80326196e-01, -6.41516030e-01,\n",
       "         1.56214972e-01, -2.12611290e-01,  1.61234476e-02,\n",
       "        -2.33584602e-01,  7.06048830e-02, -9.42934757e-02,\n",
       "         2.32251533e-01, -9.59792239e-02]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 23 features, but SVC is expecting 956 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m svm_classifier_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/svm_factor_analysis.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m svm_classifier \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(svm_classifier_file)\n\u001b[1;32m----> 7\u001b[0m \u001b[43msvm_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43munknown_X_pca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Assuming you have new data X_new_pca for prediction\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Note: Make sure to apply the same preprocessing steps to X_new_pca as you did for the training data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# # Map numeric labels to usernames using the inverse of the label encoder\u001b[39;00m\n\u001b[0;32m     20\u001b[0m predicted_usernames \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(svm_classifier\u001b[38;5;241m.\u001b[39mpredict(unknown_X_pca))\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\svm\\_base.py:814\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    812\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 814\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\svm\\_base.py:429\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\svm\\_base.py:607\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m--> 607\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m    617\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\Clones\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 23 features, but SVC is expecting 956 features as input."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "# Load the saved SVM classifier model\n",
    "svm_classifier_file = 'model/svm_factor_analysis.joblib'\n",
    "svm_classifier = joblib.load(svm_classifier_file)\n",
    "svm_classifier.predict(unknown_X_pca)\n",
    "\n",
    "\n",
    "# Assuming you have new data X_new_pca for prediction\n",
    "# Note: Make sure to apply the same preprocessing steps to X_new_pca as you did for the training data\n",
    "\n",
    "# # Compute the kernel matrix for the new data and training data\n",
    "# new_data_kernel_matrix = supervector_linear_kernel(speaker_models, unknown_X_pca, X_train_pca)\n",
    "\n",
    "# # Use the trained SVM classifier to predict numeric labels for the new data\n",
    "# predicted_numeric_labels = svm_classifier.predict(new_data_kernel_matrix)\n",
    "\n",
    "# # Map numeric labels to usernames using the inverse of the label encoder\n",
    "predicted_usernames = label_encoder.inverse_transform(svm_classifier.predict(unknown_X_pca))\n",
    "\n",
    "# # Print the predicted usernames for the new data\n",
    "print(\"Predicted Usernames for New Data:\", predicted_usernames)\n",
    "string_counts = Counter(predicted_usernames)\n",
    "print(string_counts)\n",
    "string_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
