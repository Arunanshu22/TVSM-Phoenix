{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segments: 24\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def break_audio_into_segments(audio_file, segment_length_ms=60000):\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    segment_count = len(audio) // segment_length_ms\n",
    "    segments = []\n",
    "    for i in range(segment_count):\n",
    "        start_time = i * segment_length_ms\n",
    "        end_time = start_time + segment_length_ms\n",
    "        segment = audio[start_time:end_time]\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"Sound Recordings/Abhishek_PLP.wav\"  # Replace with the path to your audio file\n",
    "segments = break_audio_into_segments(audio_file)\n",
    "print(\"Number of segments:\", len(segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arun Vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "torchvision is not available - cannot save figures\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'WindowsPath' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m verification_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arun_segment, abhishek_segment \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(arun_segments, abhishek_segments):\n\u001b[1;32m---> 25\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mverify_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43marun_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabhishek_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     verification_results\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Count True and False verifications\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mverify_pair\u001b[1;34m(file1, file2)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_pair\u001b[39m(file1, file2):\n\u001b[1;32m---> 11\u001b[0m     score, _ \u001b[38;5;241m=\u001b[39m \u001b[43mverification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\inference\\speaker.py:108\u001b[0m, in \u001b[0;36mSpeakerRecognition.verify_files\u001b[1;34m(self, path_x, path_y, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_files\u001b[39m(\u001b[38;5;28mself\u001b[39m, path_x, path_y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Speaker verification with cosine distance\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Returns the score and the decision (0 different speakers,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m        speaker and 0 otherwise.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     waveform_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     waveform_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_audio(path_y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Fake batches:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\inference\\interfaces.py:281\u001b[0m, in \u001b[0;36mPretrained.load_audio\u001b[1;34m(self, path, savedir)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an audio file with this model's input spec\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mWhen using a speech model, it is important to use the same type of data,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03mThe path can be a local path, a web url, or a link to a huggingface repo.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    280\u001b[0m source, fl \u001b[38;5;241m=\u001b[39m split_path(path)\n\u001b[1;32m--> 281\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msavedir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m signal, sr \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mstr\u001b[39m(path), channels_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_normalizer(signal, sr)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:121\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(filename, source, savedir, overwrite, save_filename, use_auth_token, revision, huggingface_cache_dir)\u001b[0m\n\u001b[0;32m    119\u001b[0m     fetch_from, source \u001b[38;5;241m=\u001b[39m source\n\u001b[0;32m    120\u001b[0m sourcefile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 121\u001b[0m destination \u001b[38;5;241m=\u001b[39m \u001b[43msavedir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msave_filename\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m destination\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n\u001b[0;32m    123\u001b[0m     MSG \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Using existing file/symlink in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(destination)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'WindowsPath' and 'list'"
     ]
    }
   ],
   "source": [
    "# Arun vs Abhishek - \n",
    "import itertools\n",
    "import pandas as pd\n",
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "\n",
    "# Initialize SpeakerRecognition model\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "# Function to verify a pair of audio files\n",
    "def verify_pair(file1, file2):\n",
    "    score, _ = verification.verify_files(file1, file2)\n",
    "    return score\n",
    "\n",
    "# Assuming you have lists of audio file paths for both speakers\n",
    "arun_files = [\"Sound Recordings/arun_jfa.wav\"]  # Assuming file names are like arun_0.wav, arun_1.wav, ...\n",
    "abhishek_files = [\"Sound Recordings/Abhishek_PLP.wav\"]  # Similar for Abhishek\n",
    "\n",
    "# Break each 25-min audio file into 1-min segments\n",
    "arun_segments = [break_audio_into_segments(file) for file in arun_files]\n",
    "abhishek_segments = [break_audio_into_segments(file) for file in abhishek_files]\n",
    "\n",
    "# Compute all combinations of segments and verify each pair\n",
    "verification_results = []\n",
    "for arun_segment, abhishek_segment in itertools.product(arun_segments, abhishek_segments):\n",
    "    score = verify_pair(arun_segment, abhishek_segment)\n",
    "    verification_results.append(score)\n",
    "\n",
    "# Count True and False verifications\n",
    "true_count = sum(score > 0.5 for score in verification_results)\n",
    "false_count = len(verification_results) - true_count\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = true_count / (true_count + false_count)\n",
    "\n",
    "# Store accuracy in a DataFrame\n",
    "accuracy_df = pd.DataFrame({'Users': [\"Arun Vs Abhishek\"], 'Accuracy': [accuracy]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arun_segment_0.wav vs abhishek_segment_0.wav = tensor([0.3918])\n",
      "arun_segment_0.wav vs abhishek_segment_1.wav = tensor([0.3705])\n",
      "arun_segment_0.wav vs abhishek_segment_2.wav = tensor([0.3909])\n",
      "arun_segment_0.wav vs abhishek_segment_3.wav = tensor([0.3696])\n",
      "arun_segment_0.wav vs abhishek_segment_4.wav = tensor([0.3834])\n",
      "arun_segment_1.wav vs abhishek_segment_0.wav = tensor([0.2835])\n",
      "arun_segment_1.wav vs abhishek_segment_1.wav = tensor([0.2696])\n",
      "arun_segment_1.wav vs abhishek_segment_2.wav = tensor([0.2893])\n",
      "arun_segment_1.wav vs abhishek_segment_3.wav = tensor([0.2737])\n",
      "arun_segment_1.wav vs abhishek_segment_4.wav = tensor([0.2755])\n",
      "arun_segment_2.wav vs abhishek_segment_0.wav = tensor([0.3928])\n",
      "arun_segment_2.wav vs abhishek_segment_1.wav = tensor([0.3608])\n",
      "arun_segment_2.wav vs abhishek_segment_2.wav = tensor([0.3683])\n",
      "arun_segment_2.wav vs abhishek_segment_3.wav = tensor([0.3632])\n",
      "arun_segment_2.wav vs abhishek_segment_4.wav = tensor([0.3759])\n",
      "arun_segment_3.wav vs abhishek_segment_0.wav = tensor([0.3376])\n",
      "arun_segment_3.wav vs abhishek_segment_1.wav = tensor([0.3132])\n",
      "arun_segment_3.wav vs abhishek_segment_2.wav = tensor([0.3207])\n",
      "arun_segment_3.wav vs abhishek_segment_3.wav = tensor([0.3108])\n",
      "arun_segment_3.wav vs abhishek_segment_4.wav = tensor([0.3232])\n",
      "arun_segment_4.wav vs abhishek_segment_0.wav = tensor([0.3445])\n",
      "arun_segment_4.wav vs abhishek_segment_1.wav = tensor([0.3095])\n",
      "arun_segment_4.wav vs abhishek_segment_2.wav = tensor([0.3171])\n",
      "arun_segment_4.wav vs abhishek_segment_3.wav = tensor([0.3128])\n",
      "arun_segment_4.wav vs abhishek_segment_4.wav = tensor([0.3222])\n",
      "              Users      Accuracy\n",
      "0  Arun Vs Abhishek  [tensor(0.)]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 145] The directory is not empty: 'temp_segments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(segment_file)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Remove temporary directory\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 145] The directory is not empty: 'temp_segments'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# Initialize SpeakerRecognition model\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "# Function to verify a pair of audio files\n",
    "def verify_pair(file1, file2):\n",
    "    score, _ = verification.verify_files(file1, file2)  # Pass file paths directly\n",
    "    return score\n",
    "\n",
    "# Function to break audio file into segments\n",
    "def break_audio_into_segments(audio_file, segment_length_ms=60000):\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    segment_count = len(audio) // segment_length_ms\n",
    "    segments = []\n",
    "    for i in range(segment_count):\n",
    "        start_time = i * segment_length_ms\n",
    "        end_time = start_time + segment_length_ms\n",
    "        segment = audio[start_time:end_time]\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "# File paths for Arun and Abhishek\n",
    "arun_file = \"Sound Recordings/aruntestarticle.wav\"\n",
    "abhishek_file = \"Sound Recordings/abhishektestarticle.wav\"\n",
    "\n",
    "# Break each 25-minute audio file into 1-minute segments\n",
    "arun_segments = break_audio_into_segments(arun_file)\n",
    "abhishek_segments = break_audio_into_segments(abhishek_file)\n",
    "\n",
    "# Create temporary directory to store segment files\n",
    "temp_dir = \"temp_segments\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Save audio segments as temporary files\n",
    "arun_segment_files = []\n",
    "abhishek_segment_files = []\n",
    "for i, segment in enumerate(arun_segments):\n",
    "    segment_file = os.path.join(temp_dir, f\"arun_segment_{i}.wav\")\n",
    "    segment.export(segment_file, format=\"wav\")\n",
    "    arun_segment_files.append(segment_file)\n",
    "\n",
    "for i, segment in enumerate(abhishek_segments):\n",
    "    segment_file = os.path.join(temp_dir, f\"abhishek_segment_{i}.wav\")\n",
    "    segment.export(segment_file, format=\"wav\")\n",
    "    abhishek_segment_files.append(segment_file)\n",
    "\n",
    "# Compute all combinations of segments and verify each pair\n",
    "verification_results = []\n",
    "for arun_segment_file, abhishek_segment_file in itertools.product(arun_segment_files, abhishek_segment_files):\n",
    "    score = verify_pair(arun_segment_file, abhishek_segment_file)  # Compare segment files\n",
    "    verification_results.append(score)\n",
    "    print(f'{os.path.basename(arun_segment_file)} vs {os.path.basename(abhishek_segment_file)} = {score}')\n",
    "\n",
    "# Count True and False verifications\n",
    "true_count = sum(score > 0.5 for score in verification_results)\n",
    "false_count = len(verification_results) - true_count\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = true_count / (true_count + false_count)\n",
    "\n",
    "# Store accuracy in a DataFrame\n",
    "df = pd.DataFrame({'Users': [\"Arun Vs Abhishek\"], 'Accuracy': [accuracy]})\n",
    "print(df)\n",
    "\n",
    "# Cleanup: Remove temporary segment files\n",
    "for segment_file in arun_segment_files + abhishek_segment_files:\n",
    "    os.remove(segment_file)\n",
    "\n",
    "# Remove temporary directory\n",
    "os.rmdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pydub.audio_segment.AudioSegment at 0x29ec6c04590>,\n",
       " <pydub.audio_segment.AudioSegment at 0x29ec6c044d0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def break_audio_into_segments(audio_file, segment_length_ms=300000):\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    segment1 = audio[:segment_length_ms]  # First 5 minutes\n",
    "    segment2 = audio[segment_length_ms:]  # Remaining 15 minutes\n",
    "    \n",
    "    # Save the first 5-minute segment to a new file\n",
    "    output_file_5min = os.path.splitext(audio_file)[0] + \"_5min.wav\"\n",
    "    segment1.export(output_file_5min, format=\"wav\")\n",
    "    \n",
    "    return segment1, segment2\n",
    "\n",
    "break_audio_into_segments(\"Sound Recordings/khushboo.wav\", segment_length_ms=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\anirbantestarticle.wav_0.wav = tensor([0.3137])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\anirbantestarticle.wav_1.wav = tensor([0.3561])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\anirbantestarticle.wav_2.wav = tensor([0.3204])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\anirbantestarticle.wav_3.wav = tensor([0.3129])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\anirbantestarticle.wav_4.wav = tensor([0.3357])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\anirbantestarticle.wav_0.wav = tensor([0.3080])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\anirbantestarticle.wav_1.wav = tensor([0.3532])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\anirbantestarticle.wav_2.wav = tensor([0.3155])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\anirbantestarticle.wav_3.wav = tensor([0.3112])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\anirbantestarticle.wav_4.wav = tensor([0.3279])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\anirbantestarticle.wav_0.wav = tensor([0.2878])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\anirbantestarticle.wav_1.wav = tensor([0.3414])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\anirbantestarticle.wav_2.wav = tensor([0.3053])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\anirbantestarticle.wav_3.wav = tensor([0.2910])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\anirbantestarticle.wav_4.wav = tensor([0.3073])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\anirbantestarticle.wav_0.wav = tensor([0.3090])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\anirbantestarticle.wav_1.wav = tensor([0.3600])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\anirbantestarticle.wav_2.wav = tensor([0.3249])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\anirbantestarticle.wav_3.wav = tensor([0.3131])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\anirbantestarticle.wav_4.wav = tensor([0.3283])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\anirbantestarticle.wav_0.wav = tensor([0.3223])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\anirbantestarticle.wav_1.wav = tensor([0.3759])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\anirbantestarticle.wav_2.wav = tensor([0.3350])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\anirbantestarticle.wav_3.wav = tensor([0.3237])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\anirbantestarticle.wav_4.wav = tensor([0.3408])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.3918])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.2835])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.3928])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.3376])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.3445])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.3705])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.2696])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.3608])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.3132])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.3095])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.3909])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.2893])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.3683])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.3207])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.3171])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.3696])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.2737])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.3632])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.3108])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.3128])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.3834])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.2755])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.3759])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.3232])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.3222])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1304])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1015])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1091])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.1114])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.0846])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1203])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.0807])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.0937])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.0976])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.0644])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1220])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.0899])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.0997])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.0965])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.0655])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1183])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.0885])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.0983])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.0979])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.0610])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1303])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.0945])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1072])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.1057])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.0696])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.1136])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1378])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1643])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1561])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.1386])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.1128])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1393])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1592])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1564])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.1396])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.0847])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1085])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1311])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1312])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.1144])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.0870])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1083])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1361])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1356])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.1148])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.0961])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1179])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1447])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1436])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.1292])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.1803])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2006])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.1573])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.1859])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.1865])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2105])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.1631])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.1989])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.1903])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2200])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.1694])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.1922])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.1677])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.1927])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.1410])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.1680])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.1923])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2209])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.1700])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.1923])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1280])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1411])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1238])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1065])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1138])\n",
      "temp_segments\\abhishektestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1233])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1362])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1460])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1378])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1165])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1225])\n",
      "temp_segments\\abhishektestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1366])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1430])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1479])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1506])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1257])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1269])\n",
      "temp_segments\\abhishektestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1374])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1404])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1488])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1452])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1261])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1258])\n",
      "temp_segments\\abhishektestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1384])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1396])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1499])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1489])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1155])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1205])\n",
      "temp_segments\\abhishektestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1319])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.1240])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.1317])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.1889])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.1637])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.2021])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.1770])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.1957])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.2418])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.1982])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.2423])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.1438])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.1892])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.2236])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.1765])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.2253])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.1521])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.1970])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.2374])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.1917])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.2351])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_0.wav = tensor([0.1566])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_1.wav = tensor([0.1954])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_2.wav = tensor([0.2467])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_3.wav = tensor([0.2021])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\aruntestarticle.wav_4.wav = tensor([0.2492])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1534])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1670])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1685])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.2000])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.1926])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1294])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1452])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1566])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.1810])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.1607])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1301])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1481])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1573])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.1756])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.1564])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1028])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1097])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1283])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.1514])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.1355])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1223])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1308])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1494])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.1683])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.1521])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.1782])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1572])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1718])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1822])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.2006])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.1856])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1557])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1836])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.2043])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.2230])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.1706])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1371])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1671])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1913])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.2104])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.1876])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1637])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.1788])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.1972])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.2229])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_0.wav = tensor([0.2140])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_1.wav = tensor([0.1872])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_2.wav = tensor([0.2052])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_3.wav = tensor([0.2272])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\khushboo_5min.wav_4.wav = tensor([0.2467])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.2348])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2046])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.1806])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.1947])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.2919])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2709])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.2425])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.2621])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.2609])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2490])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.2179])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.2298])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.2612])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2382])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.2124])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.2327])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_0.wav = tensor([0.2523])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_1.wav = tensor([0.2238])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_2.wav = tensor([0.1991])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\shivam_gmm.wav_3.wav = tensor([0.2175])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.0870])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.0799])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1048])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.0777])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.0721])\n",
      "temp_segments\\anirbantestarticle.wav_0.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1086])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1343])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1332])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1503])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1311])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1251])\n",
      "temp_segments\\anirbantestarticle.wav_1.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1529])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1396])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1526])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1557])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1412])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1397])\n",
      "temp_segments\\anirbantestarticle.wav_2.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1659])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1103])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1214])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1259])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1061])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1026])\n",
      "temp_segments\\anirbantestarticle.wav_3.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1318])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_0.wav = tensor([0.1285])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_1.wav = tensor([0.1301])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_2.wav = tensor([0.1382])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_3.wav = tensor([0.1198])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_4.wav = tensor([0.1193])\n",
      "temp_segments\\anirbantestarticle.wav_4.wav vs temp_segments\\sunamdhatestarticle.wav_5.wav = tensor([0.1493])\n",
      "temp_segments\\aruntestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.2606])\n",
      "temp_segments\\aruntestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.2412])\n",
      "temp_segments\\aruntestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.2729])\n",
      "temp_segments\\aruntestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.2794])\n",
      "temp_segments\\aruntestarticle.wav_0.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.2539])\n",
      "temp_segments\\aruntestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.2442])\n",
      "temp_segments\\aruntestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.2200])\n",
      "temp_segments\\aruntestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.2748])\n",
      "temp_segments\\aruntestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.2779])\n",
      "temp_segments\\aruntestarticle.wav_1.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.2567])\n",
      "temp_segments\\aruntestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1919])\n",
      "temp_segments\\aruntestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1749])\n",
      "temp_segments\\aruntestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.2184])\n",
      "temp_segments\\aruntestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.2277])\n",
      "temp_segments\\aruntestarticle.wav_2.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.1958])\n",
      "temp_segments\\aruntestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_0.wav = tensor([0.1428])\n",
      "temp_segments\\aruntestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_1.wav = tensor([0.1375])\n",
      "temp_segments\\aruntestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_2.wav = tensor([0.1765])\n",
      "temp_segments\\aruntestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_3.wav = tensor([0.1850])\n",
      "temp_segments\\aruntestarticle.wav_3.wav vs temp_segments\\divyabharthi_5min.wav_4.wav = tensor([0.1557])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m verification_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment_file1, segment_file2 \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(segment_files1, segment_files2):\n\u001b[1;32m---> 66\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mverify_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment_file1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_file2\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compare segment files\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     verification_results\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment_file1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment_file2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m, in \u001b[0;36mverify_pair\u001b[1;34m(file1, file2)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_pair\u001b[39m(file1, file2):\n\u001b[1;32m---> 12\u001b[0m     score, _ \u001b[38;5;241m=\u001b[39m \u001b[43mverification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile2\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass file paths directly\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\inference\\speaker.py:114\u001b[0m, in \u001b[0;36mSpeakerRecognition.verify_files\u001b[1;34m(self, path_x, path_y, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m waveform_y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Verify:\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m score, decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Squeeze:\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score[\u001b[38;5;241m0\u001b[39m], decision[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\inference\\speaker.py:88\u001b[0m, in \u001b[0;36mSpeakerRecognition.verify_batch\u001b[1;34m(self, wavs1, wavs2, wav1_lens, wav2_lens, threshold)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_batch\u001b[39m(\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m, wavs1, wavs2, wav1_lens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, wav2_lens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m     55\u001b[0m ):\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Performs speaker verification with cosine distance.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    It returns the score and the decision (0 different speakers,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m        speaker and 0 otherwise.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     emb1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwavs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav1_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     emb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_batch(wavs2, wav2_lens, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     90\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity(emb1, emb2)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\inference\\classifiers.py:110\u001b[0m, in \u001b[0;36mEncoderClassifier.encode_batch\u001b[1;34m(self, wavs, wav_lens, normalize)\u001b[0m\n\u001b[0;32m    108\u001b[0m feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmods\u001b[38;5;241m.\u001b[39mcompute_features(wavs)\n\u001b[0;32m    109\u001b[0m feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmods\u001b[38;5;241m.\u001b[39mmean_var_norm(feats, wav_lens)\n\u001b[1;32m--> 110\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    112\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mmean_var_norm_emb(\n\u001b[0;32m    113\u001b[0m         embeddings, torch\u001b[38;5;241m.\u001b[39mones(embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    114\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py:496\u001b[0m, in \u001b[0;36mECAPA_TDNN.forward\u001b[1;34m(self, x, lengths)\u001b[0m\n\u001b[0;32m    493\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmfa(x)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# Attentive Statistical Pooling\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masp_bn(x)\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# Final linear transformation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py:270\u001b[0m, in \u001b[0;36mAttentiveStatisticsPooling.forward\u001b[1;34m(self, x, lengths)\u001b[0m\n\u001b[0;32m    267\u001b[0m     attn \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Apply layers\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtdnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# Filter out zero-paddings\u001b[39;00m\n\u001b[0;32m    273\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39mmasked_fill(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\lobes\\models\\ECAPA_TDNN.py:80\u001b[0m, in \u001b[0;36mTDNNBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Processes the input tensor x and returns an output tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\speechbrain\\nnet\\CNN.py:445\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPadding must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding\n\u001b[0;32m    443\u001b[0m     )\n\u001b[1;32m--> 445\u001b[0m wx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munsqueeze:\n\u001b[0;32m    448\u001b[0m     wx \u001b[38;5;241m=\u001b[39m wx\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\EDU\\Internship\\TVSM_SpeechBrain_Explore\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# Initialize SpeakerRecognition model\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "# Function to verify a pair of audio files\n",
    "def verify_pair(file1, file2):\n",
    "    score, _ = verification.verify_files(file1, file2)  # Pass file paths directly\n",
    "    return score\n",
    "\n",
    "# Function to break audio file into segments\n",
    "def break_audio_into_segments(audio_file, segment_length_ms=60000):\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    segment_count = len(audio) // segment_length_ms\n",
    "    segments = []\n",
    "    for i in range(segment_count):\n",
    "        start_time = i * segment_length_ms\n",
    "        end_time = start_time + segment_length_ms\n",
    "        segment = audio[start_time:end_time]\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "# Directory containing audio files\n",
    "audio_directory = \"Sound Recordings/5MinTests\"\n",
    "\n",
    "# Get list of all WAV files in the directory\n",
    "wav_files = [f for f in os.listdir(audio_directory) if f.endswith(\".wav\")]\n",
    "\n",
    "# Create temporary directory to store segment files\n",
    "temp_dir = \"temp_segments\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Store accuracy results\n",
    "accuracy_results = []\n",
    "\n",
    "# Iterate over combinations of WAV files\n",
    "for file1, file2 in itertools.combinations(wav_files, 2):\n",
    "    # File paths for comparison\n",
    "    file1_path = os.path.join(audio_directory, file1)\n",
    "    file2_path = os.path.join(audio_directory, file2)\n",
    "    \n",
    "    # Break each 25-minute audio file into 1-minute segments\n",
    "    segments_file1 = break_audio_into_segments(file1_path)\n",
    "    segments_file2 = break_audio_into_segments(file2_path)\n",
    "\n",
    "    # Save audio segments as temporary files\n",
    "    segment_files1 = []\n",
    "    segment_files2 = []\n",
    "    for i, segment in enumerate(segments_file1):\n",
    "        segment_file = os.path.join(temp_dir, f\"{file1}_{i}.wav\")\n",
    "        segment.export(segment_file, format=\"wav\")\n",
    "        segment_files1.append(segment_file)\n",
    "\n",
    "    for i, segment in enumerate(segments_file2):\n",
    "        segment_file = os.path.join(temp_dir, f\"{file2}_{i}.wav\")\n",
    "        segment.export(segment_file, format=\"wav\")\n",
    "        segment_files2.append(segment_file)\n",
    "\n",
    "    # Compute all combinations of segments and verify each pair\n",
    "    verification_results = []\n",
    "    for segment_file1, segment_file2 in itertools.product(segment_files1, segment_files2):\n",
    "        score = verify_pair(segment_file1, segment_file2)  # Compare segment files\n",
    "        verification_results.append(score)\n",
    "        print(f'{segment_file1} vs {segment_file2} = {score}')\n",
    "\n",
    "    # Calculate accuracy\n",
    "    true_count = sum(score > 0.5 for score in verification_results)\n",
    "    false_count = len(verification_results) - true_count\n",
    "    accuracy = true_count / (true_count + false_count)\n",
    "\n",
    "    # Store accuracy result\n",
    "    accuracy_results.append({'Users': f\"{file1} vs {file2}\", 'Accuracy': accuracy})\n",
    "\n",
    "    # Cleanup: Remove temporary segment files\n",
    "    for segment_file in segment_files1 + segment_files2:\n",
    "        os.remove(segment_file)\n",
    "\n",
    "# Remove temporary directory (if it's empty)\n",
    "try:\n",
    "    os.rmdir(temp_dir)\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Create DataFrame from accuracy results\n",
    "df_acc = pd.DataFrame(accuracy_results)\n",
    "print(df_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_acc\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_acc' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TVSM_SpeechBrain_Explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
