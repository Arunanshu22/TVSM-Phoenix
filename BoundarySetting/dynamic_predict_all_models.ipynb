{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "# dynamic predict\n",
    "# collect 15 second file - \n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(filename, duration=15, rate=48000, chunk=1024, channels=2, format=pyaudio.paInt16):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=format, channels=channels,\n",
    "                        rate=rate, input=True,\n",
    "                        frames_per_buffer=chunk)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    print(\"Finished recording.\")\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    \n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(audio.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"recorded_audio.wav\"\n",
    "    record_audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break clip into \"DynamicTesting/\"\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def split_audio(filename, output_folder, segment_length=1000):\n",
    "    audio = AudioSegment.from_wav(filename)\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for i, start_time in enumerate(range(0, len(audio), segment_length)):\n",
    "        end_time = start_time + segment_length\n",
    "        segment = audio[start_time:end_time]\n",
    "        segment.export(os.path.join(output_folder, f\"clip_{i+1}.wav\"), format=\"wav\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"recorded_audio.wav\"  # Replace with your recorded audio file\n",
    "    output_folder = \"DynamicTesting/Unknown\"\n",
    "    split_audio(filename, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess - \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa.display\n",
    "\n",
    "# Set the parent directory for speaker folders\n",
    "parent_dir = \"DynamicTesting\"\n",
    "\n",
    "# List of speaker folders\n",
    "speaker_folders = [\n",
    "    \"Unknown\"\n",
    "]\n",
    "\n",
    "def extract_features(parent_dir, speaker_folders):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i, speaker_folder in enumerate(speaker_folders):\n",
    "        speaker_folder_path = os.path.join(parent_dir, speaker_folder)\n",
    "\n",
    "        for filename in os.listdir(speaker_folder_path):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                file_path = os.path.join(speaker_folder_path, filename)\n",
    "                audio, sr = librosa.load(file_path, sr=48000, duration=1)\n",
    "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=90)\n",
    "                \n",
    "                # Normalize MFCC features\n",
    "                mfccs = StandardScaler().fit_transform(mfccs)\n",
    "                \n",
    "                features.append(mfccs.T)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract features and labels\n",
    "X, y = extract_features(parent_dir, speaker_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 534ms/step\n",
      "Predictions for model AbhishekVsNonAbhishek.joblib:\n",
      "['NonAbhishek' 'NonAbhishek' 'NonAbhishek' 'NonAbhishek' 'NonAbhishek'\n",
      " 'NonAbhishek' 'NonAbhishek' 'NonAbhishek' 'NonAbhishek' 'NonAbhishek'\n",
      " 'NonAbhishek' 'NonAbhishek' 'NonAbhishek' 'NonAbhishek' 'NonAbhishek']\n",
      "Counts of each unique element:\n",
      "{'NonAbhishek': 15}\n",
      "\n",
      "\n",
      "1/1 [==============================] - 1s 500ms/step\n",
      "Predictions for model AnirbanVsNonAnirban.joblib:\n",
      "['NonAnirban' 'NonAnirban' 'NonAnirban' 'NonAnirban' 'NonAnirban'\n",
      " 'NonAnirban' 'NonAnirban' 'NonAnirban' 'NonAnirban' 'NonAnirban'\n",
      " 'NonAnirban' 'NonAnirban' 'NonAnirban' 'NonAnirban' 'NonAnirban']\n",
      "Counts of each unique element:\n",
      "{'NonAnirban': 15}\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 500ms/step\n",
      "Predictions for model ArunVsNonArun.joblib:\n",
      "['NonArun' 'NonArun' 'NonArun' 'NonArun' 'NonArun' 'NonArun' 'NonArun'\n",
      " 'NonArun' 'NonArun' 'NonArun' 'NonArun' 'NonArun' 'NonArun' 'NonArun'\n",
      " 'NonArun']\n",
      "Counts of each unique element:\n",
      "{'NonArun': 15}\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 499ms/step\n",
      "Predictions for model ShivamVsNonShivam.joblib:\n",
      "['Shivam' 'Shivam' 'Shivam' 'Shivam' 'Shivam' 'Shivam' 'Shivam' 'Shivam'\n",
      " 'Shivam' 'Shivam' 'Shivam' 'Shivam' 'Shivam' 'Shivam' 'Shivam']\n",
      "Counts of each unique element:\n",
      "{'Shivam': 15}\n",
      "\n",
      "\n",
      "1/1 [==============================] - 1s 542ms/step\n",
      "Predictions for model SunamdhaVsNonSunamdha.joblib:\n",
      "['Sunamdha' 'NonSunamdha' 'NonSunamdha' 'NonSunamdha' 'NonSunamdha'\n",
      " 'NonSunamdha' 'NonSunamdha' 'NonSunamdha' 'NonSunamdha' 'NonSunamdha'\n",
      " 'NonSunamdha' 'NonSunamdha' 'NonSunamdha' 'NonSunamdha' 'NonSunamdha']\n",
      "Counts of each unique element:\n",
      "{'NonSunamdha': 14, 'Sunamdha': 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store predictions and counts for each model\n",
    "predictions_counts = {}\n",
    "\n",
    "# Iterate over each model in the models folder\n",
    "models_folder = \"models\"\n",
    "for model_file in os.listdir(models_folder):\n",
    "    if model_file.endswith(\".joblib\"):\n",
    "        name = model_file.split(\"VsNon\")[0]\n",
    "        user_speaking = name\n",
    "        non_user_speaking = \"Non\" + name\n",
    "        actual_speakers = [user_speaking,non_user_speaking]\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.classes_ = np.array(actual_speakers)\n",
    "\n",
    "        # Load the model\n",
    "        model = joblib.load(os.path.join(models_folder, model_file))\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_probabilities = model.predict(X)\n",
    "        y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "        y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "        \n",
    "        # Count the occurrences of each unique element\n",
    "        unique_elements, counts = np.unique(y_pred_decoded, return_counts=True)\n",
    "        predictions_counts[model_file] = dict(zip(unique_elements, counts))\n",
    "        \n",
    "        # Print the predictions\n",
    "        print(f\"Predictions for model {model_file}:\")\n",
    "        print(y_pred_decoded)\n",
    "        print(\"Counts of each unique element:\")\n",
    "        print(predictions_counts[model_file])\n",
    "        print(\"\\n\")\n",
    "\n",
    "# You can access the predictions and counts for each model from the predictions_counts dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdjustedPythonVirtEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
