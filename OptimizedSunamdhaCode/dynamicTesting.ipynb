{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect 15 seconds of audio\n",
    "# break them into 1 second and store them in \"testFiles/\"\n",
    "# Apply all preprocessing\n",
    "# Load the model \n",
    "# Predict each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "# collect 15 second file - \n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(filename, duration=15, rate=48000, chunk=1024, channels=2, format=pyaudio.paInt16):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=format, channels=channels,\n",
    "                        rate=rate, input=True,\n",
    "                        frames_per_buffer=chunk)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    print(\"Finished recording.\")\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    \n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(audio.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"recorded_audio.wav\"\n",
    "    record_audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: 48000\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "def get_sampling_rate(filename):\n",
    "    with wave.open(filename, 'rb') as wf:\n",
    "        sr = wf.getframerate()\n",
    "    return sr\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"testing/Unknown/clip_4.wav\"  # Replace with your audio file path\n",
    "    sr = get_sampling_rate(filename)\n",
    "    print(\"Sampling rate:\", sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break clip into \"testing/\"\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def split_audio(filename, output_folder, segment_length=1000):\n",
    "    audio = AudioSegment.from_wav(filename)\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for i, start_time in enumerate(range(0, len(audio), segment_length)):\n",
    "        end_time = start_time + segment_length\n",
    "        segment = audio[start_time:end_time]\n",
    "        segment.export(os.path.join(output_folder, f\"clip_{i+1}.wav\"), format=\"wav\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"recorded_audio.wav\"  # Replace with your recorded audio file\n",
    "    output_folder = \"testing/Unknown/\"\n",
    "    split_audio(filename, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess - \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa.display\n",
    "\n",
    "# Set the parent directory for speaker folders\n",
    "parent_dir = \"testing\"\n",
    "\n",
    "# List of speaker folders\n",
    "speaker_folders = [\n",
    "    \"Unknown\"\n",
    "]\n",
    "\n",
    "def extract_features(parent_dir, speaker_folders):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i, speaker_folder in enumerate(speaker_folders):\n",
    "        speaker_folder_path = os.path.join(parent_dir, speaker_folder)\n",
    "\n",
    "        for filename in os.listdir(speaker_folder_path):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                file_path = os.path.join(speaker_folder_path, filename)\n",
    "                audio, sr = librosa.load(file_path, sr=48000, duration=1)\n",
    "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=90)\n",
    "                \n",
    "                # Normalize MFCC features\n",
    "                mfccs = StandardScaler().fit_transform(mfccs)\n",
    "                \n",
    "                features.append(mfccs.T)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract features and labels\n",
    "X, y = extract_features(parent_dir, speaker_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 94, 90)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_speakers = [\n",
    "    \"Abhishek\",\n",
    "    \"Anirban\",\n",
    "    \"Arunanshu\",\n",
    "    \"Shivam\",\n",
    "    \"Sunamdha\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels with explicit classes\n",
    "label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y)\n",
    "label_encoder.classes_ = np.array(actual_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Sunamdha', 'Sunamdha', 'Sunamdha', 'Sunamdha', 'Sunamdha',\n",
       "       'Sunamdha', 'Sunamdha', 'Sunamdha', 'Sunamdha', 'Sunamdha',\n",
       "       'Sunamdha', 'Sunamdha', 'Sunamdha', 'Sunamdha', 'Sunamdha'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "# import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model = joblib.load('Five_speaker_model_mfcc_17mindata.joblib')  # Update with your actual model file\n",
    "y_pred_probabilities = model.predict(X)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "y_pred\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "y_pred_decoded\n",
    "# # Evaluate the model on the test set\n",
    "# y_pred_probabilities = model.predict(X_test)\n",
    "# y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# # Decode labels back to original format\n",
    "# y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "# y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# # Create a confusion matrix\n",
    "# conf_matrix = confusion_matrix(y_test_decoded, y_pred_decoded, labels=speaker_folders)\n",
    "\n",
    "# # Calculate acc   uracy\n",
    "# accuracy = accuracy_score(y_test_decoded, y_pred_decoded)\n",
    "# print(f\"Test Evaluation Accuracy: {accuracy}\")\n",
    "\n",
    "# # Calculate F1 score\n",
    "# f1 = f1_score(y_test_decoded, y_pred_decoded, labels=speaker_folders, average='weighted')\n",
    "# print(f\"Weighted F1 Score: {f1}\")\n",
    "\n",
    "# # Plot the confusion matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=speaker_folders, yticklabels=speaker_folders)\n",
    "\n",
    "# # Rotate x-axis labels by 45 degrees\n",
    "# plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
