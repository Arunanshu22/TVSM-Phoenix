{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83588e4d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-14T08:38:59.414129Z",
     "iopub.status.busy": "2024-02-14T08:38:59.413725Z",
     "iopub.status.idle": "2024-02-14T08:39:07.148272Z",
     "shell.execute_reply": "2024-02-14T08:39:07.147045Z"
    },
    "papermill": {
     "duration": 7.756167,
     "end_time": "2024-02-14T08:39:07.152785",
     "exception": false,
     "start_time": "2024-02-14T08:38:59.396618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9146dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:39:07.246688Z",
     "iopub.status.busy": "2024-02-14T08:39:07.246137Z",
     "iopub.status.idle": "2024-02-14T08:39:20.717227Z",
     "shell.execute_reply": "2024-02-14T08:39:20.716268Z"
    },
    "papermill": {
     "duration": 13.521635,
     "end_time": "2024-02-14T08:39:20.719929",
     "exception": false,
     "start_time": "2024-02-14T08:39:07.198294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab6e6ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:39:20.812130Z",
     "iopub.status.busy": "2024-02-14T08:39:20.811415Z",
     "iopub.status.idle": "2024-02-14T08:40:04.103130Z",
     "shell.execute_reply": "2024-02-14T08:40:04.101971Z"
    },
    "papermill": {
     "duration": 43.340732,
     "end_time": "2024-02-14T08:40:04.105608",
     "exception": false,
     "start_time": "2024-02-14T08:39:20.764876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#/kaggle/input/articleandtwentytwofivenewdata/archive\n",
    "#!cp -r \"../input/articleandtwentytwofivenewdata/archive\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167b0909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:04.195279Z",
     "iopub.status.busy": "2024-02-14T08:40:04.194879Z",
     "iopub.status.idle": "2024-02-14T08:40:04.200238Z",
     "shell.execute_reply": "2024-02-14T08:40:04.199480Z"
    },
    "papermill": {
     "duration": 0.054029,
     "end_time": "2024-02-14T08:40:04.202236",
     "exception": false,
     "start_time": "2024-02-14T08:40:04.148207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_directory = \"archive/16000_pcm_speeches\"\n",
    "audio_folder = \"audio\"\n",
    "noise_folder = \"noise\"\n",
    "\n",
    "audio_path = os.path.join(data_directory, audio_folder)\n",
    "noise_path = os.path.join(data_directory, noise_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54592895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:04.291635Z",
     "iopub.status.busy": "2024-02-14T08:40:04.291275Z",
     "iopub.status.idle": "2024-02-14T08:40:04.298635Z",
     "shell.execute_reply": "2024-02-14T08:40:04.297915Z"
    },
    "papermill": {
     "duration": 0.055851,
     "end_time": "2024-02-14T08:40:04.301248",
     "exception": false,
     "start_time": "2024-02-14T08:40:04.245397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'archive/16000_pcm_speeches\\\\audio'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcbe36e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:04.392587Z",
     "iopub.status.busy": "2024-02-14T08:40:04.392210Z",
     "iopub.status.idle": "2024-02-14T08:40:04.396676Z",
     "shell.execute_reply": "2024-02-14T08:40:04.395917Z"
    },
    "papermill": {
     "duration": 0.052328,
     "end_time": "2024-02-14T08:40:04.398636",
     "exception": false,
     "start_time": "2024-02-14T08:40:04.346308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_split = 0.1\n",
    "\n",
    "shuffle_seed = 43\n",
    "\n",
    "sample_rate = 16000\n",
    "\n",
    "scale = 0.5\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e78fb7",
   "metadata": {
    "papermill": {
     "duration": 0.043125,
     "end_time": "2024-02-14T08:40:04.485518",
     "exception": false,
     "start_time": "2024-02-14T08:40:04.442393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f14a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:04.576567Z",
     "iopub.status.busy": "2024-02-14T08:40:04.575843Z",
     "iopub.status.idle": "2024-02-14T08:40:04.818618Z",
     "shell.execute_reply": "2024-02-14T08:40:04.817412Z"
    },
    "papermill": {
     "duration": 0.291798,
     "end_time": "2024-02-14T08:40:04.821448",
     "exception": false,
     "start_time": "2024-02-14T08:40:04.529650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for folder in os.listdir(data_directory):\n",
    "#     if os.path.isdir(os.path.join(data_directory, folder)):\n",
    "#         if folder in [audio_folder, noise_folder]:\n",
    "            \n",
    "#             continue\n",
    "#         elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            \n",
    "#             shutil.move(\n",
    "#                 os.path.join(data_directory, folder),\n",
    "#                 os.path.join(noise_path, folder),\n",
    "#             )\n",
    "#         else:\n",
    "#             shutil.move(\n",
    "#                 os.path.join(data_directory, folder),\n",
    "#                 os.path.join(audio_path, folder),\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6a26ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:04.910685Z",
     "iopub.status.busy": "2024-02-14T08:40:04.909981Z",
     "iopub.status.idle": "2024-02-14T08:40:04.915855Z",
     "shell.execute_reply": "2024-02-14T08:40:04.915139Z"
    },
    "papermill": {
     "duration": 0.052563,
     "end_time": "2024-02-14T08:40:04.917981",
     "exception": false,
     "start_time": "2024-02-14T08:40:04.865418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise_paths = []\n",
    "for subdir in os.listdir(noise_path):\n",
    "    subdir_path = Path(noise_path) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eab5f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:05.006388Z",
     "iopub.status.busy": "2024-02-14T08:40:05.005980Z",
     "iopub.status.idle": "2024-02-14T08:40:05.011617Z",
     "shell.execute_reply": "2024-02-14T08:40:05.010892Z"
    },
    "papermill": {
     "duration": 0.052715,
     "end_time": "2024-02-14T08:40:05.013725",
     "exception": false,
     "start_time": "2024-02-14T08:40:04.961010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archive\\\\16000_pcm_speeches\\\\noise\\\\other\\\\exercise_bike.wav',\n",
       " 'archive\\\\16000_pcm_speeches\\\\noise\\\\other\\\\pink_noise.wav',\n",
       " 'archive\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\10convert.com_Audience-Claps_daSG5fwdA7o.wav',\n",
       " 'archive\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\doing_the_dishes.wav',\n",
       " 'archive\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\dude_miaowing.wav',\n",
       " 'archive\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\running_tap.wav']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb6b096a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:05.106083Z",
     "iopub.status.busy": "2024-02-14T08:40:05.105379Z",
     "iopub.status.idle": "2024-02-14T08:40:05.110175Z",
     "shell.execute_reply": "2024-02-14T08:40:05.109250Z"
    },
    "papermill": {
     "duration": 0.053177,
     "end_time": "2024-02-14T08:40:05.112340",
     "exception": false,
     "start_time": "2024-02-14T08:40:05.059163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = (\n",
    "    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n",
    "    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n",
    "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
    "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
    "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
    "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
    "    \"-i $file -ar 16000 temp.wav; \"\n",
    "    \"mv temp.wav $file; \"\n",
    "    \"fi; done; done\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "280b6705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:05.219981Z",
     "iopub.status.busy": "2024-02-14T08:40:05.219247Z",
     "iopub.status.idle": "2024-02-14T08:40:07.213462Z",
     "shell.execute_reply": "2024-02-14T08:40:07.212190Z"
    },
    "papermill": {
     "duration": 2.057624,
     "end_time": "2024-02-14T08:40:07.216113",
     "exception": false,
     "start_time": "2024-02-14T08:40:05.158489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate for archive\\16000_pcm_speeches\\noise\\other\\exercise_bike.wav is incorrect\n",
      "Sampling rate for archive\\16000_pcm_speeches\\noise\\other\\pink_noise.wav is incorrect\n",
      "Sampling rate for archive\\16000_pcm_speeches\\noise\\_background_noise_\\10convert.com_Audience-Claps_daSG5fwdA7o.wav is incorrect\n",
      "Sampling rate for archive\\16000_pcm_speeches\\noise\\_background_noise_\\doing_the_dishes.wav is incorrect\n",
      "Sampling rate for archive\\16000_pcm_speeches\\noise\\_background_noise_\\dude_miaowing.wav is incorrect\n",
      "Sampling rate for archive\\16000_pcm_speeches\\noise\\_background_noise_\\running_tap.wav is incorrect\n"
     ]
    }
   ],
   "source": [
    "os.system(command)\n",
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == sample_rate:\n",
    "        slices = int(sample.shape[0] / sample_rate)\n",
    "        sample = tf.split(sample[: slices * sample_rate], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for\",path, \"is incorrect\")\n",
    "        return None\n",
    "\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3004d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.304358Z",
     "iopub.status.busy": "2024-02-14T08:40:07.304007Z",
     "iopub.status.idle": "2024-02-14T08:40:07.309618Z",
     "shell.execute_reply": "2024-02-14T08:40:07.308481Z"
    },
    "papermill": {
     "duration": 0.051842,
     "end_time": "2024-02-14T08:40:07.311610",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.259768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622bd3c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.398911Z",
     "iopub.status.busy": "2024-02-14T08:40:07.398538Z",
     "iopub.status.idle": "2024-02-14T08:40:07.403962Z",
     "shell.execute_reply": "2024-02-14T08:40:07.402928Z"
    },
    "papermill": {
     "duration": 0.05208,
     "end_time": "2024-02-14T08:40:07.406058",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.353978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_to_audio(path):\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fddf034f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.496035Z",
     "iopub.status.busy": "2024-02-14T08:40:07.494858Z",
     "iopub.status.idle": "2024-02-14T08:40:07.502315Z",
     "shell.execute_reply": "2024-02-14T08:40:07.501514Z"
    },
    "papermill": {
     "duration": 0.055026,
     "end_time": "2024-02-14T08:40:07.504394",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.449368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_noise(audio, noises=None, scale=0.5):\n",
    "    if noises is not None:\n",
    "        tf_rnd = tf.random.uniform(\n",
    "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
    "        )\n",
    "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
    "\n",
    "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
    "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
    "\n",
    "        audio = audio + noise * prop * scale\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88d39620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.592756Z",
     "iopub.status.busy": "2024-02-14T08:40:07.591746Z",
     "iopub.status.idle": "2024-02-14T08:40:07.598273Z",
     "shell.execute_reply": "2024-02-14T08:40:07.597268Z"
    },
    "papermill": {
     "duration": 0.052911,
     "end_time": "2024-02-14T08:40:07.600383",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.547472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def audio_to_fft(audio):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(\n",
    "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
    "    )\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9cafd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.686742Z",
     "iopub.status.busy": "2024-02-14T08:40:07.685695Z",
     "iopub.status.idle": "2024-02-14T08:40:07.714061Z",
     "shell.execute_reply": "2024-02-14T08:40:07.713189Z"
    },
    "papermill": {
     "duration": 0.075319,
     "end_time": "2024-02-14T08:40:07.716435",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.641116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhishek', 'Arunanshu', 'Shivam', 'Sunamdha']\n",
      "Speaker: Abhishek\n",
      "Speaker: Arunanshu\n",
      "Speaker: Shivam\n",
      "Speaker: Sunamdha\n"
     ]
    }
   ],
   "source": [
    "class_names = os.listdir(audio_path)\n",
    "print(class_names,)\n",
    "\n",
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Speaker:\",(name))\n",
    "    dir_path = Path(audio_path) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aa24da0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.802431Z",
     "iopub.status.busy": "2024-02-14T08:40:07.801330Z",
     "iopub.status.idle": "2024-02-14T08:40:07.808409Z",
     "shell.execute_reply": "2024-02-14T08:40:07.807680Z"
    },
    "papermill": {
     "duration": 0.052072,
     "end_time": "2024-02-14T08:40:07.810437",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.758365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(audio_paths)\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6dc08c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.901519Z",
     "iopub.status.busy": "2024-02-14T08:40:07.900792Z",
     "iopub.status.idle": "2024-02-14T08:40:07.905854Z",
     "shell.execute_reply": "2024-02-14T08:40:07.905176Z"
    },
    "papermill": {
     "duration": 0.055403,
     "end_time": "2024-02-14T08:40:07.907846",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.852443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into training and validation\n",
    "num_val_samples = int(valid_split * len(audio_paths))\n",
    "train_audio_paths = audio_paths[:-num_val_samples]\n",
    "train_labels = labels[:-num_val_samples]\n",
    "\n",
    "\n",
    "valid_audio_paths = audio_paths[-num_val_samples:]\n",
    "valid_labels = labels[-num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc6a1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:07.994116Z",
     "iopub.status.busy": "2024-02-14T08:40:07.993452Z",
     "iopub.status.idle": "2024-02-14T08:40:08.170566Z",
     "shell.execute_reply": "2024-02-14T08:40:08.169668Z"
    },
    "papermill": {
     "duration": 0.223378,
     "end_time": "2024-02-14T08:40:08.173512",
     "exception": false,
     "start_time": "2024-02-14T08:40:07.950134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create datasets, one for training and the other for validation\n",
    "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
    "train_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20e673c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:08.261535Z",
     "iopub.status.busy": "2024-02-14T08:40:08.260797Z",
     "iopub.status.idle": "2024-02-14T08:40:08.632752Z",
     "shell.execute_reply": "2024-02-14T08:40:08.631574Z"
    },
    "papermill": {
     "duration": 0.419251,
     "end_time": "2024-02-14T08:40:08.635367",
     "exception": false,
     "start_time": "2024-02-14T08:40:08.216116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add noise to the training set\n",
    "# train_ds = train_ds.map(\n",
    "#     lambda x, y: (add_noise(x, noises, scale=scale), y),\n",
    "#     num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2931efeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:08.724760Z",
     "iopub.status.busy": "2024-02-14T08:40:08.723701Z",
     "iopub.status.idle": "2024-02-14T08:40:08.729788Z",
     "shell.execute_reply": "2024-02-14T08:40:08.729099Z"
    },
    "papermill": {
     "duration": 0.052486,
     "end_time": "2024-02-14T08:40:08.731676",
     "exception": false,
     "start_time": "2024-02-14T08:40:08.679190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 8000, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "313b5c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:08.875931Z",
     "iopub.status.busy": "2024-02-14T08:40:08.875222Z",
     "iopub.status.idle": "2024-02-14T08:40:09.028930Z",
     "shell.execute_reply": "2024-02-14T08:40:09.027619Z"
    },
    "papermill": {
     "duration": 0.201467,
     "end_time": "2024-02-14T08:40:09.031808",
     "exception": false,
     "start_time": "2024-02-14T08:40:08.830341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3312b98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:09.122036Z",
     "iopub.status.busy": "2024-02-14T08:40:09.121360Z",
     "iopub.status.idle": "2024-02-14T08:40:10.208892Z",
     "shell.execute_reply": "2024-02-14T08:40:10.208011Z"
    },
    "papermill": {
     "duration": 1.134329,
     "end_time": "2024-02-14T08:40:10.211418",
     "exception": false,
     "start_time": "2024-02-14T08:40:09.077089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n",
    "#     s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n",
    "    \n",
    "#     for i in range(conv_num - 1):\n",
    "#         x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "#         x = keras.layers.Activation(activation)(x)\n",
    "#         #x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    \n",
    "#     x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "#     x = keras.layers.Add()([x, s])\n",
    "#     x = keras.layers.Activation(activation)(x)\n",
    "#     #x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "#     return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "# def build_model(input_shape, num_classes, dropout_rate=0.2):\n",
    "#     inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n",
    "    \n",
    "#     x = residual_block(inputs, 16, 2)\n",
    "#     x = residual_block(inputs, 32, 2)\n",
    "#     x = residual_block(inputs, 64, 3)\n",
    "#     #x = residual_block(inputs, 128, 3)\n",
    "#     x = residual_block(inputs, 128, 3)\n",
    "#     x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "#     x = keras.layers.Flatten()(x)\n",
    "#     x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "#     x = Dropout(dropout_rate)(x)\n",
    "#     x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "#     x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "#     outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n",
    "    \n",
    "#     return keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "\n",
    "# dropout_rate = 0.2\n",
    "# model = build_model((sample_rate // 2, 1), len(class_names), dropout_rate=dropout_rate)\n",
    "\n",
    "# model.summary()\n",
    "# def lr_schedule(epoch):\n",
    "#     initial_learning_rate = 0.001\n",
    "#     decay = 0.9\n",
    "#     lr = initial_learning_rate * decay ** epoch\n",
    "#     return lr\n",
    "\n",
    "# lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "# model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "\n",
    "# model_save_filename = \"/kaggle/working/archive/model/fivespeakertwentytofivemodel.joblib\"\n",
    "\n",
    "# earlystopping_cb = keras.callbacks.EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# #mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"loss\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a637d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maddula.sai\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maddula.sai\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maddula.sai\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From c:\\Users\\maddula.sai\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maddula.sai\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "34/34 [==============================] - 183s 4s/step - loss: 1.0239 - accuracy: 0.8984 - val_loss: 0.8038 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - 136s 4s/step - loss: 0.6706 - accuracy: 0.9904 - val_loss: 0.6363 - val_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - 223s 6s/step - loss: 0.5959 - accuracy: 0.9923 - val_loss: 0.5612 - val_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - 227s 5s/step - loss: 0.5335 - accuracy: 0.9914 - val_loss: 0.5003 - val_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - 180s 4s/step - loss: 0.4711 - accuracy: 0.9925 - val_loss: 0.4531 - val_accuracy: 0.9895 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - 137s 4s/step - loss: 0.4199 - accuracy: 0.9946 - val_loss: 0.4153 - val_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - 208s 5s/step - loss: 0.3782 - accuracy: 0.9942 - val_loss: 0.3567 - val_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - 192s 4s/step - loss: 0.3372 - accuracy: 0.9967 - val_loss: 0.3273 - val_accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - 132s 4s/step - loss: 0.3013 - accuracy: 0.9972 - val_loss: 0.3688 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - 159s 4s/step - loss: 0.2848 - accuracy: 0.9930 - val_loss: 0.2827 - val_accuracy: 0.9895 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - 157s 4s/step - loss: 0.2477 - accuracy: 0.9960 - val_loss: 0.3064 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - 230s 6s/step - loss: 0.2292 - accuracy: 0.9953 - val_loss: 0.2177 - val_accuracy: 0.9937 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - 228s 5s/step - loss: 0.2136 - accuracy: 0.9935 - val_loss: 0.2027 - val_accuracy: 0.9979 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - 156s 4s/step - loss: 0.1985 - accuracy: 0.9930 - val_loss: 0.1820 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - 149s 4s/step - loss: 0.1791 - accuracy: 0.9949 - val_loss: 0.1688 - val_accuracy: 0.9979 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dropout, Conv1D, Activation, Add, MaxPool1D, AveragePooling1D, Flatten, Dense, Input, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "def residual_block(x, filters, conv_num=3, activation=\"relu\", use_batch_norm=False, l2_reg=0.01):\n",
    "    s = Conv1D(filters, 1, padding=\"same\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "\n",
    "    for i in range(conv_num - 1):\n",
    "        x = Conv1D(filters, 3, padding=\"same\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "        if use_batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "        x = Activation(activation)(x)\n",
    "        # x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = Conv1D(filters, 3, padding=\"same\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Add()([x, s])\n",
    "    x = Activation(activation)(x)\n",
    "    # x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return MaxPool1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "def build_model(input_shape, num_classes, dropout_rate=0.2, use_batch_norm=False, l2_reg=0.01):\n",
    "    inputs = Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = residual_block(inputs, 16, 2, use_batch_norm=use_batch_norm, l2_reg=l2_reg)\n",
    "    x = residual_block(x, 32, 2, use_batch_norm=use_batch_norm, l2_reg=l2_reg)\n",
    "    x = residual_block(x, 64, 3, use_batch_norm=use_batch_norm, l2_reg=l2_reg)\n",
    "    # x = residual_block(inputs, 128, 3)\n",
    "    x = residual_block(x, 128, 3, use_batch_norm=use_batch_norm, l2_reg=l2_reg)\n",
    "    x = AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Data loading and preprocessing\n",
    "# Replace X_train, X_test, y_train, y_test with your actual data\n",
    "\n",
    "# Initialize the model\n",
    "dropout_rate = 0.2\n",
    "use_batch_norm = True\n",
    "l2_reg = 0.001  # Regularization strength\n",
    "model = build_model((sample_rate // 2, 1), len(class_names), dropout_rate=dropout_rate, use_batch_norm=use_batch_norm, l2_reg=l2_reg)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "#model_save_filename = \"/kaggle/working/archive/model/fivespeakertwentytofivemodel.h5\"\n",
    "#mdl_checkpoint_cb = ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)\n",
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=epochs, batch_size=32, validation_data=(valid_ds), callbacks=[early_stopping_cb,  reduce_lr_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93f50fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T08:40:10.308566Z",
     "iopub.status.busy": "2024-02-14T08:40:10.308137Z",
     "iopub.status.idle": "2024-02-14T09:58:39.463609Z",
     "shell.execute_reply": "2024-02-14T09:58:39.460930Z"
    },
    "papermill": {
     "duration": 4709.297109,
     "end_time": "2024-02-14T09:58:39.556554",
     "exception": false,
     "start_time": "2024-02-14T08:40:10.259445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=valid_ds,\n",
    "#     callbacks=[earlystopping_cb],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82f11667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:58:39.768062Z",
     "iopub.status.busy": "2024-02-14T09:58:39.767125Z",
     "iopub.status.idle": "2024-02-14T09:58:46.837927Z",
     "shell.execute_reply": "2024-02-14T09:58:46.836798Z"
    },
    "papermill": {
     "duration": 7.187361,
     "end_time": "2024-02-14T09:58:46.840619",
     "exception": false,
     "start_time": "2024-02-14T09:58:39.653258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UPlocal_four_speaker_model.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model using joblib\n",
    "model_save_filename=\"UPlocal_four_speaker_model.joblib\"\n",
    "joblib.dump(model, model_save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed0f23f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:58:47.034839Z",
     "iopub.status.busy": "2024-02-14T09:58:47.034369Z",
     "iopub.status.idle": "2024-02-14T09:59:00.592128Z",
     "shell.execute_reply": "2024-02-14T09:59:00.591244Z"
    },
    "papermill": {
     "duration": 13.658489,
     "end_time": "2024-02-14T09:59:00.594281",
     "exception": false,
     "start_time": "2024-02-14T09:58:46.935792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 12s 365ms/step - loss: 0.1688 - accuracy: 0.9979\n",
      "Accuracy of model: [0.16879761219024658, 0.99790358543396]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model:\",model.evaluate(valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f756d3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:00.791137Z",
     "iopub.status.busy": "2024-02-14T09:59:00.790396Z",
     "iopub.status.idle": "2024-02-14T09:59:04.212952Z",
     "shell.execute_reply": "2024-02-14T09:59:04.212047Z"
    },
    "papermill": {
     "duration": 3.523557,
     "end_time": "2024-02-14T09:59:04.215670",
     "exception": false,
     "start_time": "2024-02-14T09:59:00.692113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 103ms/step\n",
      "Speaker:\u001b[92m Abhishek\u001b[0m\tPredicted:\u001b[92m Abhishek\u001b[0m\n",
      "Welcome\n",
      "The speaker is Abhishek\n",
      "Speaker:\u001b[92m Shivam\u001b[0m\tPredicted:\u001b[92m Shivam\u001b[0m\n",
      "Welcome\n",
      "The speaker is Shivam\n",
      "Speaker:\u001b[92m Arunanshu\u001b[0m\tPredicted:\u001b[92m Arunanshu\u001b[0m\n",
      "Welcome\n",
      "The speaker is Arunanshu\n",
      "Speaker:\u001b[92m Arunanshu\u001b[0m\tPredicted:\u001b[92m Arunanshu\u001b[0m\n",
      "Welcome\n",
      "The speaker is Arunanshu\n",
      "Speaker:\u001b[92m Sunamdha\u001b[0m\tPredicted:\u001b[92m Sunamdha\u001b[0m\n",
      "Welcome\n",
      "The speaker is Sunamdha\n",
      "Speaker:\u001b[92m Sunamdha\u001b[0m\tPredicted:\u001b[92m Sunamdha\u001b[0m\n",
      "Welcome\n",
      "The speaker is Sunamdha\n",
      "Speaker:\u001b[92m Sunamdha\u001b[0m\tPredicted:\u001b[92m Sunamdha\u001b[0m\n",
      "Welcome\n",
      "The speaker is Sunamdha\n",
      "Speaker:\u001b[92m Sunamdha\u001b[0m\tPredicted:\u001b[92m Sunamdha\u001b[0m\n",
      "Welcome\n",
      "The speaker is Sunamdha\n",
      "Speaker:\u001b[92m Abhishek\u001b[0m\tPredicted:\u001b[92m Abhishek\u001b[0m\n",
      "Welcome\n",
      "The speaker is Abhishek\n",
      "Speaker:\u001b[92m Arunanshu\u001b[0m\tPredicted:\u001b[92m Arunanshu\u001b[0m\n",
      "Welcome\n",
      "The speaker is Arunanshu\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_TO_DISPLAY = 10\n",
    "\n",
    "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "test_ds = test_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "# test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
    "\n",
    "for audios, labels in test_ds.take(1):\n",
    "    ffts = audio_to_fft(audios)\n",
    "    y_pred = model.predict(ffts)\n",
    "    rnd = np.random.randint(0, batch_size, SAMPLES_TO_DISPLAY)\n",
    "    audios = audios.numpy()[rnd, :, :]\n",
    "    labels = labels.numpy()[rnd]\n",
    "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    for index in range(SAMPLES_TO_DISPLAY):\n",
    "        print(\n",
    "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
    "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
    "                class_names[labels[index]],\n",
    "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
    "                class_names[y_pred[index]],\n",
    "            )\n",
    "        )\n",
    "        if labels[index] ==y_pred[index]:\n",
    "            print(\"Welcome\")\n",
    "        else:\n",
    "            print(\"Sorry\")\n",
    "        print(\"The speaker is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273fdb08",
   "metadata": {
    "papermill": {
     "duration": 0.099003,
     "end_time": "2024-02-14T09:59:04.411211",
     "exception": false,
     "start_time": "2024-02-14T09:59:04.312208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8169522",
   "metadata": {
    "papermill": {
     "duration": 0.097695,
     "end_time": "2024-02-14T09:59:04.605826",
     "exception": false,
     "start_time": "2024-02-14T09:59:04.508131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c014f2be",
   "metadata": {
    "papermill": {
     "duration": 0.098249,
     "end_time": "2024-02-14T09:59:04.802484",
     "exception": false,
     "start_time": "2024-02-14T09:59:04.704235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "265b1b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:05.003100Z",
     "iopub.status.busy": "2024-02-14T09:59:05.002337Z",
     "iopub.status.idle": "2024-02-14T09:59:05.007722Z",
     "shell.execute_reply": "2024-02-14T09:59:05.006856Z"
    },
    "papermill": {
     "duration": 0.107795,
     "end_time": "2024-02-14T09:59:05.009880",
     "exception": false,
     "start_time": "2024-02-14T09:59:04.902085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#/kaggle/input/articleandtwentytwofivenewdata/archive/Article/16000_pcm_speeches\n",
    "\n",
    "data_directory = \"archive/Article/16000_pcm_speeches\"\n",
    "audio_folder = \"audio\"\n",
    "noise_folder = \"noise\"\n",
    "\n",
    "audio_path = os.path.join(data_directory, audio_folder)\n",
    "noise_path = os.path.join(data_directory, noise_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef1b0099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:05.232305Z",
     "iopub.status.busy": "2024-02-14T09:59:05.231845Z",
     "iopub.status.idle": "2024-02-14T09:59:05.238735Z",
     "shell.execute_reply": "2024-02-14T09:59:05.237688Z"
    },
    "papermill": {
     "duration": 0.130651,
     "end_time": "2024-02-14T09:59:05.240971",
     "exception": false,
     "start_time": "2024-02-14T09:59:05.110320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'archive/Article/16000_pcm_speeches\\\\audio'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57a67263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:05.440074Z",
     "iopub.status.busy": "2024-02-14T09:59:05.439676Z",
     "iopub.status.idle": "2024-02-14T09:59:05.530877Z",
     "shell.execute_reply": "2024-02-14T09:59:05.530054Z"
    },
    "papermill": {
     "duration": 0.191705,
     "end_time": "2024-02-14T09:59:05.533215",
     "exception": false,
     "start_time": "2024-02-14T09:59:05.341510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for folder in os.listdir(data_directory):\n",
    "#     if os.path.isdir(os.path.join(data_directory, folder)):\n",
    "#         if folder in [audio_folder, noise_folder]:\n",
    "            \n",
    "#             continue\n",
    "#         elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            \n",
    "#             shutil.move(\n",
    "#                 os.path.join(data_directory, folder),\n",
    "#                 os.path.join(noise_path, folder),\n",
    "#             )\n",
    "#         else:\n",
    "#             shutil.move(\n",
    "#                 os.path.join(data_directory, folder),\n",
    "#                 os.path.join(audio_path, folder),\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dec4f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:05.732882Z",
     "iopub.status.busy": "2024-02-14T09:59:05.731772Z",
     "iopub.status.idle": "2024-02-14T09:59:05.740460Z",
     "shell.execute_reply": "2024-02-14T09:59:05.739659Z"
    },
    "papermill": {
     "duration": 0.112758,
     "end_time": "2024-02-14T09:59:05.742993",
     "exception": false,
     "start_time": "2024-02-14T09:59:05.630235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise_paths = []\n",
    "for subdir in os.listdir(noise_path):\n",
    "    subdir_path = Path(noise_path) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33dd892b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:05.946545Z",
     "iopub.status.busy": "2024-02-14T09:59:05.945804Z",
     "iopub.status.idle": "2024-02-14T09:59:05.951935Z",
     "shell.execute_reply": "2024-02-14T09:59:05.951153Z"
    },
    "papermill": {
     "duration": 0.107615,
     "end_time": "2024-02-14T09:59:05.953756",
     "exception": false,
     "start_time": "2024-02-14T09:59:05.846141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archive\\\\Article\\\\16000_pcm_speeches\\\\noise\\\\other\\\\exercise_bike.wav',\n",
       " 'archive\\\\Article\\\\16000_pcm_speeches\\\\noise\\\\other\\\\pink_noise.wav',\n",
       " 'archive\\\\Article\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\10convert.com_Audience-Claps_daSG5fwdA7o.wav',\n",
       " 'archive\\\\Article\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\doing_the_dishes.wav',\n",
       " 'archive\\\\Article\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\dude_miaowing.wav',\n",
       " 'archive\\\\Article\\\\16000_pcm_speeches\\\\noise\\\\_background_noise_\\\\running_tap.wav']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "440f6926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:06.151051Z",
     "iopub.status.busy": "2024-02-14T09:59:06.150435Z",
     "iopub.status.idle": "2024-02-14T09:59:06.154881Z",
     "shell.execute_reply": "2024-02-14T09:59:06.154145Z"
    },
    "papermill": {
     "duration": 0.106658,
     "end_time": "2024-02-14T09:59:06.156882",
     "exception": false,
     "start_time": "2024-02-14T09:59:06.050224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = (\n",
    "    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n",
    "    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n",
    "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
    "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
    "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
    "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
    "    \"-i $file -ar 16000 temp.wav; \"\n",
    "    \"mv temp.wav $file; \"\n",
    "    \"fi; done; done\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8253482e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:06.354766Z",
     "iopub.status.busy": "2024-02-14T09:59:06.354201Z",
     "iopub.status.idle": "2024-02-14T09:59:07.696778Z",
     "shell.execute_reply": "2024-02-14T09:59:07.695788Z"
    },
    "papermill": {
     "duration": 1.444267,
     "end_time": "2024-02-14T09:59:07.699472",
     "exception": false,
     "start_time": "2024-02-14T09:59:06.255205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate for archive\\Article\\16000_pcm_speeches\\noise\\other\\exercise_bike.wav is incorrect\n",
      "Sampling rate for archive\\Article\\16000_pcm_speeches\\noise\\other\\pink_noise.wav is incorrect\n",
      "Sampling rate for archive\\Article\\16000_pcm_speeches\\noise\\_background_noise_\\10convert.com_Audience-Claps_daSG5fwdA7o.wav is incorrect\n",
      "Sampling rate for archive\\Article\\16000_pcm_speeches\\noise\\_background_noise_\\doing_the_dishes.wav is incorrect\n",
      "Sampling rate for archive\\Article\\16000_pcm_speeches\\noise\\_background_noise_\\dude_miaowing.wav is incorrect\n",
      "Sampling rate for archive\\Article\\16000_pcm_speeches\\noise\\_background_noise_\\running_tap.wav is incorrect\n"
     ]
    }
   ],
   "source": [
    "os.system(command)\n",
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == sample_rate:\n",
    "        slices = int(sample.shape[0] / sample_rate)\n",
    "        sample = tf.split(sample[: slices * sample_rate], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for\",path, \"is incorrect\")\n",
    "        return None\n",
    "\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8d32a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:07.894720Z",
     "iopub.status.busy": "2024-02-14T09:59:07.894017Z",
     "iopub.status.idle": "2024-02-14T09:59:07.909401Z",
     "shell.execute_reply": "2024-02-14T09:59:07.908207Z"
    },
    "papermill": {
     "duration": 0.114138,
     "end_time": "2024-02-14T09:59:07.911658",
     "exception": false,
     "start_time": "2024-02-14T09:59:07.797520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhishek', 'Arunanshu', 'Shivam', 'Sunamdha']\n",
      "Speaker: Abhishek\n",
      "Speaker: Arunanshu\n",
      "Speaker: Shivam\n",
      "Speaker: Sunamdha\n"
     ]
    }
   ],
   "source": [
    "class_names = os.listdir(audio_path)\n",
    "print(class_names,)\n",
    "\n",
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Speaker:\",(name))\n",
    "    dir_path = Path(audio_path) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94e123f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:08.113255Z",
     "iopub.status.busy": "2024-02-14T09:59:08.112363Z",
     "iopub.status.idle": "2024-02-14T09:59:08.118630Z",
     "shell.execute_reply": "2024-02-14T09:59:08.117913Z"
    },
    "papermill": {
     "duration": 0.109285,
     "end_time": "2024-02-14T09:59:08.120609",
     "exception": false,
     "start_time": "2024-02-14T09:59:08.011324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shuffle to generate random data\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(audio_paths)\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cbe5b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:08.317429Z",
     "iopub.status.busy": "2024-02-14T09:59:08.316676Z",
     "iopub.status.idle": "2024-02-14T09:59:08.321878Z",
     "shell.execute_reply": "2024-02-14T09:59:08.321158Z"
    },
    "papermill": {
     "duration": 0.107687,
     "end_time": "2024-02-14T09:59:08.323771",
     "exception": false,
     "start_time": "2024-02-14T09:59:08.216084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_val_samples = int(valid_split * len(audio_paths))\n",
    "test1_audio_paths = audio_paths[:-num_val_samples]\n",
    "test1_labels = labels[:-num_val_samples]\n",
    "\n",
    "\n",
    "test2_audio_paths = audio_paths[-num_val_samples:]\n",
    "test2_labels = labels[-num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14f5b3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:08.525942Z",
     "iopub.status.busy": "2024-02-14T09:59:08.525222Z",
     "iopub.status.idle": "2024-02-14T09:59:08.574352Z",
     "shell.execute_reply": "2024-02-14T09:59:08.573353Z"
    },
    "papermill": {
     "duration": 0.15378,
     "end_time": "2024-02-14T09:59:08.577035",
     "exception": false,
     "start_time": "2024-02-14T09:59:08.423255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create datasets, one for training and the other for validation\n",
    "test1_ds = paths_and_labels_to_dataset(test1_audio_paths, test1_labels)\n",
    "test1_ds = test1_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "test2_ds = paths_and_labels_to_dataset(test2_audio_paths, test2_labels)\n",
    "test2_ds = test2_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efe35b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:08.776900Z",
     "iopub.status.busy": "2024-02-14T09:59:08.776183Z",
     "iopub.status.idle": "2024-02-14T09:59:08.868129Z",
     "shell.execute_reply": "2024-02-14T09:59:08.866942Z"
    },
    "papermill": {
     "duration": 0.194042,
     "end_time": "2024-02-14T09:59:08.870774",
     "exception": false,
     "start_time": "2024-02-14T09:59:08.676732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add noise to the training set\n",
    "# test1_ds = test1_ds.map(\n",
    "#     lambda x, y: (add_noise(x, noises, scale=scale), y),\n",
    "#     num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "test1_ds = test1_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "\n",
    "test1_ds = test1_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test2_ds = test2_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "test2_ds = test2_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5d4beb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T09:59:09.072689Z",
     "iopub.status.busy": "2024-02-14T09:59:09.071937Z",
     "iopub.status.idle": "2024-02-14T10:00:31.093715Z",
     "shell.execute_reply": "2024-02-14T10:00:31.092588Z"
    },
    "papermill": {
     "duration": 82.227808,
     "end_time": "2024-02-14T10:00:31.196929",
     "exception": false,
     "start_time": "2024-02-14T09:59:08.969121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 38s 581ms/step - loss: 0.4290 - accuracy: 0.9502\n",
      "Accuracy of model: [0.4289529323577881, 0.9501748085021973]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model:\",model.evaluate(test1_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9937a82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:31.399845Z",
     "iopub.status.busy": "2024-02-14T10:00:31.399451Z",
     "iopub.status.idle": "2024-02-14T10:00:36.540140Z",
     "shell.execute_reply": "2024-02-14T10:00:36.538966Z"
    },
    "papermill": {
     "duration": 5.245834,
     "end_time": "2024-02-14T10:00:36.543113",
     "exception": false,
     "start_time": "2024-02-14T10:00:31.297279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 141ms/step - loss: 0.4239 - accuracy: 0.9606\n",
      "Accuracy of model: [0.4238627254962921, 0.960629940032959]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model:\",model.evaluate(test2_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3de5734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:36.752643Z",
     "iopub.status.busy": "2024-02-14T10:00:36.751981Z",
     "iopub.status.idle": "2024-02-14T10:00:36.762078Z",
     "shell.execute_reply": "2024-02-14T10:00:36.761203Z"
    },
    "papermill": {
     "duration": 0.116993,
     "end_time": "2024-02-14T10:00:36.764495",
     "exception": false,
     "start_time": "2024-02-14T10:00:36.647502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def paths_to_dataset(audio_paths):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    return tf.data.Dataset.zip((path_ds))\n",
    "\n",
    "def predict(path, labels):\n",
    "    test = paths_and_labels_to_dataset(path, labels)\n",
    "\n",
    "\n",
    "    test = test.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    "    )\n",
    "    test = test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "    # test = test.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
    "\n",
    "    for audios, labels in test.take(1):\n",
    "        ffts = audio_to_fft(audios)\n",
    "        y_pred = model.predict(ffts)\n",
    "        rnd = np.random.randint(0, 1, 1)\n",
    "        audios = audios.numpy()[rnd, :]\n",
    "        labels = labels.numpy()[rnd]\n",
    "        y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    \n",
    "    \n",
    "    for index in range(1):\n",
    "        print(\n",
    "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
    "                \"[92m\" if labels[0].decode('utf-8') == class_names[y_pred[0]] else \"[91m\",\n",
    "                labels[0].decode('utf-8'),\n",
    "                \"[92m\" if labels[0].decode('utf-8') == class_names[y_pred[0]] else \"[91m\",\n",
    "                class_names[y_pred[0]],\n",
    "            )\n",
    "        )\n",
    "        if labels[0].decode('utf-8') ==class_names[y_pred[0]]:\n",
    "            print(\"Welcome\")\n",
    "        else:\n",
    "            print(\"Sorry\")\n",
    "        print(\"The speaker is\" if labels[0].decode('utf-8') == class_names[y_pred[0]] else \"\", class_names[y_pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6683666f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:36.968849Z",
     "iopub.status.busy": "2024-02-14T10:00:36.968134Z",
     "iopub.status.idle": "2024-02-14T10:00:37.109448Z",
     "shell.execute_reply": "2024-02-14T10:00:37.107966Z"
    },
    "papermill": {
     "duration": 0.249492,
     "end_time": "2024-02-14T10:00:37.111961",
     "exception": false,
     "start_time": "2024-02-14T10:00:36.862469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 426ms/step\n",
      "Speaker:\u001b[92m Abhishek\u001b[0m\tPredicted:\u001b[92m Abhishek\u001b[0m\n",
      "Welcome\n",
      "The speaker is Abhishek\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path = [\"archive/Article/16000_pcm_speeches/audio/Abhishek/100.wav\"]\n",
    "labels = [\"Abhishek\"]\n",
    "try:\n",
    "    predict(path, labels)\n",
    "except:\n",
    "    print(\"Error! Check if the file correctly passed or not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de3e0cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:37.318950Z",
     "iopub.status.busy": "2024-02-14T10:00:37.318091Z",
     "iopub.status.idle": "2024-02-14T10:00:37.432046Z",
     "shell.execute_reply": "2024-02-14T10:00:37.431052Z"
    },
    "papermill": {
     "duration": 0.218923,
     "end_time": "2024-02-14T10:00:37.434202",
     "exception": false,
     "start_time": "2024-02-14T10:00:37.215279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error! Check if the file correctly passed or not!\n"
     ]
    }
   ],
   "source": [
    "path = [\"/kaggle/working/archive/kaggletestdata/16000_pcm_speeches/audio/Arunanshu/153.wav\"]\n",
    "labels = [\"unknown\"]\n",
    "try:\n",
    "    predict(path, labels)\n",
    "except:\n",
    "    print(\"Error! Check if the file correctly passed or not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db1388bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:37.637106Z",
     "iopub.status.busy": "2024-02-14T10:00:37.636722Z",
     "iopub.status.idle": "2024-02-14T10:00:37.754787Z",
     "shell.execute_reply": "2024-02-14T10:00:37.753542Z"
    },
    "papermill": {
     "duration": 0.223111,
     "end_time": "2024-02-14T10:00:37.757175",
     "exception": false,
     "start_time": "2024-02-14T10:00:37.534064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error! Check if the file correctly passed or not!\n"
     ]
    }
   ],
   "source": [
    "path = [\"/kaggle/working/archive/kaggletestdata/16000_pcm_speeches/audio/Sunamdha/350.wav\"]\n",
    "labels = [\"unknown\"]\n",
    "try:\n",
    "    predict(path, labels)\n",
    "except:\n",
    "    print(\"Error! Check if the file correctly passed or not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31031865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:37.966919Z",
     "iopub.status.busy": "2024-02-14T10:00:37.966145Z",
     "iopub.status.idle": "2024-02-14T10:00:38.083751Z",
     "shell.execute_reply": "2024-02-14T10:00:38.082342Z"
    },
    "papermill": {
     "duration": 0.226899,
     "end_time": "2024-02-14T10:00:38.086087",
     "exception": false,
     "start_time": "2024-02-14T10:00:37.859188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error! Check if the file correctly passed or not!\n"
     ]
    }
   ],
   "source": [
    "path = [\"/kaggle/working/archive/kaggletestdata/16000_pcm_speeches/audio/Shivam/53.wav\"]\n",
    "labels = [\"unknown\"]\n",
    "try:\n",
    "    predict(path, labels)\n",
    "except:\n",
    "    print(\"Error! Check if the file correctly passed or not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86e429e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:38.295409Z",
     "iopub.status.busy": "2024-02-14T10:00:38.293982Z",
     "iopub.status.idle": "2024-02-14T10:00:38.408352Z",
     "shell.execute_reply": "2024-02-14T10:00:38.406932Z"
    },
    "papermill": {
     "duration": 0.222409,
     "end_time": "2024-02-14T10:00:38.411227",
     "exception": false,
     "start_time": "2024-02-14T10:00:38.188818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error! Check if the file correctly passed or not!\n"
     ]
    }
   ],
   "source": [
    "path = [\"/kaggle/working/archive/kaggletestdata/16000_pcm_speeches/audio/Abhishek/153.wav\"]\n",
    "labels = [\"unknown\"]\n",
    "try:\n",
    "    predict(path, labels)\n",
    "except:\n",
    "    print(\"Error! Check if the file correctly passed or not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d2a00e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:38.619318Z",
     "iopub.status.busy": "2024-02-14T10:00:38.618367Z",
     "iopub.status.idle": "2024-02-14T10:00:38.623274Z",
     "shell.execute_reply": "2024-02-14T10:00:38.622516Z"
    },
    "papermill": {
     "duration": 0.112747,
     "end_time": "2024-02-14T10:00:38.625349",
     "exception": false,
     "start_time": "2024-02-14T10:00:38.512602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.models import load_model\n",
    "\n",
    "# # Load the saved model\n",
    "# saved_model_path = \"/kaggle/input/testingtwentytofivedata/archive/model/model.h5\"\n",
    "# loaded_model = load_model(saved_model_path)\n",
    "\n",
    "# # Assuming you have your test data in test_ds\n",
    "# # Evaluate the model on test data\n",
    "# test_loss, test_accuracy = loaded_model.evaluate(train_ds)\n",
    "\n",
    "# print(\"Test Loss:\", test_loss)\n",
    "# print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1bd7ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:00:38.828758Z",
     "iopub.status.busy": "2024-02-14T10:00:38.828098Z",
     "iopub.status.idle": "2024-02-14T10:03:40.179560Z",
     "shell.execute_reply": "2024-02-14T10:03:40.178376Z"
    },
    "papermill": {
     "duration": 181.558653,
     "end_time": "2024-02-14T10:03:40.285644",
     "exception": false,
     "start_time": "2024-02-14T10:00:38.726991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = joblib.load(\"/kaggle/working/archive/model/fivespeakertwentytofivemodel.joblib\")\n",
    "\n",
    "# # Make predictions on the training dataset\n",
    "# predictions = loaded_model.predict(train_ds)\n",
    "\n",
    "# # Assuming train_ds is a DataFrame, you can print the predictions\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7dcd0ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:03:40.489711Z",
     "iopub.status.busy": "2024-02-14T10:03:40.489352Z",
     "iopub.status.idle": "2024-02-14T10:04:41.173608Z",
     "shell.execute_reply": "2024-02-14T10:04:41.172286Z"
    },
    "papermill": {
     "duration": 60.788614,
     "end_time": "2024-02-14T10:04:41.176229",
     "exception": false,
     "start_time": "2024-02-14T10:03:40.387615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 16s 527ms/step - loss: 0.4290 - accuracy: 0.9502\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load(\"UPlocal_four_speaker_model.joblib\")\n",
    "\n",
    "# Make predictions on the training dataset\n",
    "test_loss, test_accuracy = loaded_model.evaluate(test1_ds)\n",
    "# Assuming train_ds is a DataFrame, you can print the predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db8aeb",
   "metadata": {
    "papermill": {
     "duration": 0.108933,
     "end_time": "2024-02-14T10:04:41.393464",
     "exception": false,
     "start_time": "2024-02-14T10:04:41.284531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4435250,
     "sourceId": 7615791,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4440161,
     "sourceId": 7622538,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5147.690856,
   "end_time": "2024-02-14T10:04:44.196623",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-14T08:38:56.505767",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
